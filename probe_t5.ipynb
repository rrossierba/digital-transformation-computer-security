{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9L0bmfKk_Q-"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAmVjLTRYW5"
      },
      "source": [
        "preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hCfcLCIRRcMR"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hzupOBSRon7",
        "outputId": "869ece25-ed44-491e-e3a6-d8fb9dbc4e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00xoYkRWReqW"
      },
      "source": [
        "download tokenizer and model from hf\n",
        "\n",
        "note: do not download and run both models at the same time, colab has some limitation and it is not guaranteed to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-W51utcr27g"
      },
      "outputs": [],
      "source": [
        "# login with hf\n",
        "from huggingface_hub import login\n",
        "token = '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'\n",
        "login(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6hkR4lH07r2Y"
      },
      "outputs": [],
      "source": [
        "model_id_b=f'google/t5gemma-b-b-ul2'\n",
        "tokenizer_b = AutoTokenizer.from_pretrained(model_id_b)\n",
        "model_b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xh4CfPuSlp2_"
      },
      "outputs": [],
      "source": [
        "model_id_2b=f'google/t5gemma-2b-2b-ul2'\n",
        "tokenizer_2b = AutoTokenizer.from_pretrained(model_id_2b)\n",
        "model_2b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_2b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhoYbqZOVMH8"
      },
      "source": [
        "## extracting the activations from the model\n",
        "\n",
        "We use mean pooling to obtain vector representations of sentences because SentenceBERT has shown that it works better than the CLS token. In our case, there is no CLS token, so this was not even an option. SentenceT5 has confirmed that mean pooling is the strategy that yields the best results for T5-based models when it is necessary to extract the sentence representation.\n",
        "\n",
        "So we use this strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkQE_B8aUUYH",
        "outputId": "0737504f-e591-4c5e-f2cf-970b9ceeb891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13 13\n",
            "torch.Size([1, 7, 768]) torch.Size([1, 1, 768])\n"
          ]
        }
      ],
      "source": [
        "# non batched\n",
        "model_b.eval()\n",
        "\n",
        "text = 'tell me something about the human brain'\n",
        "\n",
        "inputs = tokenizer_b(text, return_tensors=\"pt\").to(model_b.device)\n",
        "\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model_b(\n",
        "        **inputs,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        output_hidden_states=True,\n",
        "    )\n",
        "\n",
        "encoder_hidden_states = torch.stack([e.cpu().squeeze(0) for e in outputs.encoder_hidden_states])\n",
        "decoder_hidden_states = torch.stack([o.cpu().view(-1) for o in outputs.decoder_hidden_states])\n",
        "\n",
        "#print(encoder_hidden_states.shape)\n",
        "#print(decoder_hidden_states.shape)\n",
        "\n",
        "print(len(outputs.encoder_hidden_states), len(outputs.decoder_hidden_states))\n",
        "print(outputs.encoder_hidden_states[0].shape, outputs.decoder_hidden_states[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl49XaoSp7Et"
      },
      "outputs": [],
      "source": [
        "# batched function\n",
        "def extract_activations_df(base_df, model, tokenizer, text_column, BATCH_SIZE=1):\n",
        "  df = base_df.copy()\n",
        "  enc_results = {}\n",
        "  dec_results = {}\n",
        "\n",
        "  # mean pooling considering padding and using attention mask to set to 0 pad token representations\n",
        "  def masked_mean_pooling(hidden_states, attention_mask):\n",
        "      mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "      masked_embeddings = hidden_states * mask_expanded\n",
        "      summed = torch.sum(masked_embeddings, dim=1)\n",
        "      count = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "      return summed / count\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_rows = len(df)\n",
        "\n",
        "  print(f\"Start processing {total_rows} sentences...\")\n",
        "\n",
        "  for i in tqdm(range(0, total_rows, BATCH_SIZE)):\n",
        "      batch_texts = df[text_column][i : i + BATCH_SIZE].tolist()\n",
        "      inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "      current_batch_len = inputs.input_ids.shape[0]\n",
        "      start_token_id = tokenizer.bos_token_id\n",
        "      decoder_input_ids = torch.full((current_batch_len, 1), start_token_id, device=model.device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(\n",
        "              **inputs,\n",
        "              decoder_input_ids=decoder_input_ids,\n",
        "              output_hidden_states=True,\n",
        "          )\n",
        "\n",
        "      # encoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      attention_mask = inputs.attention_mask.cpu()\n",
        "      batch_encoder_states = torch.stack([\n",
        "          masked_mean_pooling(e.cpu(), attention_mask)\n",
        "          for e in outputs.encoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float32).numpy()\n",
        "\n",
        "      # decoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      batch_decoder_states = torch.stack([\n",
        "          o.cpu().squeeze(1) for o in outputs.decoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float32).numpy()\n",
        "\n",
        "      num_enc_layers = batch_encoder_states.shape[1]\n",
        "      num_dec_layers = batch_decoder_states.shape[1]\n",
        "\n",
        "      # saving the activation results into the dictionaries\n",
        "      for layer_idx in range(num_enc_layers):\n",
        "          col_name = f'encoder_layer_{layer_idx+1}'\n",
        "          if col_name not in enc_results: enc_results[col_name] = []\n",
        "          vectors = list(batch_encoder_states[:, layer_idx, :])\n",
        "          enc_results[col_name].extend(vectors)\n",
        "\n",
        "      for layer_idx in range(num_dec_layers):\n",
        "          col_name = f'decoder_layer_{layer_idx+1}'\n",
        "          if col_name not in dec_results: dec_results[col_name] = []\n",
        "\n",
        "          vectors = list(batch_decoder_states[:, layer_idx, :])\n",
        "          dec_results[col_name].extend(vectors)\n",
        "\n",
        "  print(\"Saving in the DataFrame...\")\n",
        "  for col_name, vectors in enc_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  for col_name, vectors in dec_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  print(\"Done! Columns added\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2uhxtHZjvPk"
      },
      "outputs": [],
      "source": [
        "def save_activations_df(df, dataset_name, model_id):\n",
        "  path = f'/content/drive/MyDrive/DTCS_datasets/{dataset_name}_{model_id.split('/')[1]}'\n",
        "  print(f'Saving {dataset_name}_{model_id.split('/')[1]} to GDrive...')\n",
        "  df.to_pickle(path)\n",
        "  print(f'Saved {dataset_name}_{model_id.split(\"/\")[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24jJOMSUTPI5"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mV-dGDMfz0x"
      },
      "source": [
        "## True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KdjyO6T2T9cd",
        "outputId": "7bbd1d6f-18e3-4377-a368-b27d421d815a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 69243  100 69243    0     0   210k      0 --:--:-- --:--:-- --:--:--  211k\n",
            "Archive:  true-false-dataset.zip\n",
            "  inflating: true-false-dataset/publicDataset/animals_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/cities_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/companies_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/elements_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/facts_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/generated_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/inventions_true_false.csv  \n"
          ]
        }
      ],
      "source": [
        "!curl azariaa.com/Content/Datasets/true-false-dataset.zip > true-false-dataset.zip\n",
        "!unzip \"true-false-dataset.zip\" -d \"true-false-dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "collapsed": true,
        "id": "qwY3ruMm7wKu",
        "outputId": "f0fdb2fe-23e3-4858-e610-765f6a79fc60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"tf_df\",\n  \"rows\": 6330,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6309,\n        \"samples\": [\n          \"China Telecom engages in the provision of telecommunication services..\",\n          \"The sparrow uses flying for locomotion.\",\n          \"The Statue of Liberty is located in New York City.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"facts\",\n          \"cities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "tf_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d502e6aa-2966-4f5c-a8c9-aaa641147ad6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The planet Uranus is tilted on its side.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sharks are sea creatures that have a reputatio...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An adult human has 32 teeth.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The smallest continent in the world is Australia.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Amazon River is the largest river in the w...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6325</th>\n",
              "      <td>The capital of South Suda is Juba.</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>JAUBA is a town in the Central Equatorial Stat...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6327</th>\n",
              "      <td>Jauba is located at the junction of the Equato...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6328</th>\n",
              "      <td>JUABA is an administrative unit in the Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>Juaaba is a small town in South sudans Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6330 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d502e6aa-2966-4f5c-a8c9-aaa641147ad6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d502e6aa-2966-4f5c-a8c9-aaa641147ad6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d502e6aa-2966-4f5c-a8c9-aaa641147ad6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4682e5e3-55bb-4512-abf7-3e641249954e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4682e5e3-55bb-4512-abf7-3e641249954e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4682e5e3-55bb-4512-abf7-3e641249954e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_73ab7d9d-8a54-41fa-b9a4-e83a5698d321\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tf_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_73ab7d9d-8a54-41fa-b9a4-e83a5698d321 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tf_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              statement  label       area\n",
              "0              The planet Uranus is tilted on its side.      1      facts\n",
              "1     Sharks are sea creatures that have a reputatio...      1      facts\n",
              "2                          An adult human has 32 teeth.      1      facts\n",
              "3     The smallest continent in the world is Australia.      1      facts\n",
              "4     The Amazon River is the largest river in the w...      1      facts\n",
              "...                                                 ...    ...        ...\n",
              "6325                 The capital of South Suda is Juba.      0  generated\n",
              "6326  JAUBA is a town in the Central Equatorial Stat...      0  generated\n",
              "6327  Jauba is located at the junction of the Equato...      0  generated\n",
              "6328  JUABA is an administrative unit in the Equator...      0  generated\n",
              "6329  Juaaba is a small town in South sudans Equator...      0  generated\n",
              "\n",
              "[6330 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dataframe from the csv files\n",
        "dir_path = '/content/true-false-dataset/publicDataset'\n",
        "datasets_names = os.listdir(dir_path)\n",
        "dfs = []\n",
        "\n",
        "for dataset_name in datasets_names:\n",
        "  path = f'{dir_path}/{dataset_name}'\n",
        "  df = pd.read_csv(path)\n",
        "  df.insert(loc=2, column='area', value=dataset_name.replace('_true_false.csv',''), allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "tf_df = pd.concat(dfs, ignore_index=True)\n",
        "tf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWyQ_2Al3qT"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "uU1emOEbfGpK",
        "outputId": "9b7682c9-1f2f-49a5-baeb-9e1300ba8591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing 6330 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:18<00:00,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_tf_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-309824a3-d428-49fb-a365-a1f7d7dc72cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>area</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The planet Uranus is tilted on its side.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[1.8242188, 0.014973958, 0.30143228, 0.2826606...</td>\n",
              "      <td>[0.056857638, 0.4626736, 0.16932508, -0.357638...</td>\n",
              "      <td>[-0.19216579, 0.4826389, 0.1438802, -0.4792751...</td>\n",
              "      <td>[-0.28027344, 0.14887153, -0.34320748, -0.1949...</td>\n",
              "      <td>[-0.09988064, 0.17556423, -0.5488281, -0.06087...</td>\n",
              "      <td>[0.35253906, 0.00043402778, 0.0029296875, -0.1...</td>\n",
              "      <td>[0.7221137, -0.21473524, -0.08993869, -0.50846...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4765625, 0.39453125, 0.30273438, 0.5273437...</td>\n",
              "      <td>[-0.9296875, 0.51953125, -0.072265625, 0.82421...</td>\n",
              "      <td>[-1.25, 0.015136719, 0.15625, 0.62890625, -1.6...</td>\n",
              "      <td>[-1.203125, 0.53125, -0.18652344, 0.82421875, ...</td>\n",
              "      <td>[0.041015625, 0.048828125, 0.015625, 0.8945312...</td>\n",
              "      <td>[-0.11035156, -0.15820312, -0.45507812, 1.1171...</td>\n",
              "      <td>[-0.43359375, -0.30859375, -1.0, 0.5390625, -1...</td>\n",
              "      <td>[-1.296875, -0.1640625, -1.171875, 0.37109375,...</td>\n",
              "      <td>[-1.2890625, 0.29882812, -0.3828125, 0.1367187...</td>\n",
              "      <td>[28.25, -4.53125, 0.34179688, -0.94140625, 3.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sharks are sea creatures that have a reputatio...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[1.6576773, -0.23715445, -0.41706732, 0.110314...</td>\n",
              "      <td>[0.095853366, 0.023212139, -0.30155122, -0.453...</td>\n",
              "      <td>[-0.048753005, 0.015211839, -0.088604264, -0.4...</td>\n",
              "      <td>[-0.30742937, -0.17337741, -0.37474647, -0.137...</td>\n",
              "      <td>[-0.50946516, -0.27554086, -0.48152044, -0.087...</td>\n",
              "      <td>[-0.22385818, -0.6236478, -0.68073916, -0.0413...</td>\n",
              "      <td>[0.029897837, -0.97273135, -0.77659255, -0.074...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.43554688, 0.3203125, 0.53515625, -0.4...</td>\n",
              "      <td>[-0.953125, 0.5625, -0.040527344, 0.83203125, ...</td>\n",
              "      <td>[-1.2890625, 0.049316406, 0.19335938, 0.625, -...</td>\n",
              "      <td>[-1.234375, 0.55859375, -0.16992188, 0.8242187...</td>\n",
              "      <td>[0.025390625, 0.107421875, 0.056640625, 0.8867...</td>\n",
              "      <td>[-0.123535156, -0.10986328, -0.37890625, 1.117...</td>\n",
              "      <td>[-0.44140625, -0.23046875, -0.96875, 0.5703125...</td>\n",
              "      <td>[-1.2890625, -0.14453125, -1.1953125, 0.449218...</td>\n",
              "      <td>[-1.34375, 0.3515625, -0.37890625, 0.14941406,...</td>\n",
              "      <td>[26.75, -5.125, -0.8046875, -1.7734375, -0.671...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An adult human has 32 teeth.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[1.4643012, -0.42925346, 0.23860677, 0.4300130...</td>\n",
              "      <td>[0.15288629, -0.11577691, -0.13226996, -0.4715...</td>\n",
              "      <td>[-0.0070529515, -0.13682726, 0.06939019, -0.25...</td>\n",
              "      <td>[-0.2250434, -0.19845921, -0.10394965, -0.2877...</td>\n",
              "      <td>[0.0907118, -0.3184679, -0.30837673, -0.218532...</td>\n",
              "      <td>[0.4171007, -0.1802029, -0.044704862, -0.04058...</td>\n",
              "      <td>[0.4921875, -0.17274305, -0.69259983, -0.27365...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.515625, 0.40625, 0.32421875, 0.515625, -0....</td>\n",
              "      <td>[-0.9765625, 0.5390625, -0.036132812, 0.796875...</td>\n",
              "      <td>[-1.3046875, 0.01928711, 0.18359375, 0.6015625...</td>\n",
              "      <td>[-1.2578125, 0.53515625, -0.16894531, 0.804687...</td>\n",
              "      <td>[-0.0234375, 0.061523438, 0.015625, 0.88671875...</td>\n",
              "      <td>[-0.1484375, -0.1484375, -0.42578125, 1.09375,...</td>\n",
              "      <td>[-0.4453125, -0.296875, -0.9765625, 0.5390625,...</td>\n",
              "      <td>[-1.3203125, -0.19238281, -1.2109375, 0.419921...</td>\n",
              "      <td>[-1.421875, 0.3984375, -0.3359375, 0.033203125...</td>\n",
              "      <td>[23.0, -1.3671875, -3.125, 3.8125, -0.76953125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The smallest continent in the world is Australia.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[1.4700521, 0.0687934, 0.18645562, 0.42199367,...</td>\n",
              "      <td>[0.234375, 0.08821615, -0.08292643, -0.1408420...</td>\n",
              "      <td>[0.0703125, 0.09830729, 0.32109916, 0.00260416...</td>\n",
              "      <td>[-0.06287977, -0.2046441, -0.1779514, 0.145073...</td>\n",
              "      <td>[0.092447914, -0.024956597, -0.429579, 0.26736...</td>\n",
              "      <td>[-0.0059136283, -0.42719185, -0.3060981, 0.041...</td>\n",
              "      <td>[0.3373481, -0.5115017, -0.48676217, -0.137641...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.50390625, 0.390625, 0.3125, 0.49804688, -0...</td>\n",
              "      <td>[-0.95703125, 0.5234375, -0.052734375, 0.79687...</td>\n",
              "      <td>[-1.28125, 0.017822266, 0.18066406, 0.58984375...</td>\n",
              "      <td>[-1.234375, 0.5390625, -0.16601562, 0.7890625,...</td>\n",
              "      <td>[0.025390625, 0.06640625, 0.04296875, 0.855468...</td>\n",
              "      <td>[-0.13476562, -0.16015625, -0.38476562, 1.0625...</td>\n",
              "      <td>[-0.4609375, -0.30664062, -0.9765625, 0.507812...</td>\n",
              "      <td>[-1.3125, -0.22265625, -1.2109375, 0.38085938,...</td>\n",
              "      <td>[-1.421875, 0.34765625, -0.41796875, 0.0625, -...</td>\n",
              "      <td>[23.875, -3.890625, 1.15625, 0.22753906, 3.828...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Amazon River is the largest river in the w...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[1.1790866, -0.024188701, -0.20665565, 0.20469...</td>\n",
              "      <td>[0.020695614, 0.22814003, -0.35821062, -0.4532...</td>\n",
              "      <td>[-0.21146335, 0.20551945, -0.05577674, -0.3368...</td>\n",
              "      <td>[-0.34795672, 0.057016227, -0.48948318, 0.0582...</td>\n",
              "      <td>[-0.063777044, 0.27208534, -0.6057692, 0.11204...</td>\n",
              "      <td>[-0.09878305, 0.07016226, -0.4611253, 0.136944...</td>\n",
              "      <td>[0.29454628, 0.104191706, -0.9107572, -0.13690...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4765625, 0.40234375, 0.28515625, 0.5351562...</td>\n",
              "      <td>[-0.9296875, 0.53515625, -0.08251953, 0.832031...</td>\n",
              "      <td>[-1.2578125, 0.042236328, 0.16113281, 0.640625...</td>\n",
              "      <td>[-1.203125, 0.55859375, -0.19921875, 0.8398437...</td>\n",
              "      <td>[0.05078125, 0.091796875, 0.021484375, 0.91015...</td>\n",
              "      <td>[-0.09667969, -0.12109375, -0.42578125, 1.125,...</td>\n",
              "      <td>[-0.42578125, -0.25195312, -0.98046875, 0.5781...</td>\n",
              "      <td>[-1.265625, -0.14550781, -1.1796875, 0.453125,...</td>\n",
              "      <td>[-1.34375, 0.375, -0.3671875, 0.06347656, -1.0...</td>\n",
              "      <td>[29.875, -1.140625, 2.640625, -0.88671875, 1.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6325</th>\n",
              "      <td>The capital of South Suda is Juba.</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[1.6899414, 0.090063475, -0.34589845, 0.427441...</td>\n",
              "      <td>[0.05234375, 0.39042968, -0.37111816, -0.52656...</td>\n",
              "      <td>[-0.42539063, 0.3416992, 0.17148438, -0.596093...</td>\n",
              "      <td>[-0.26484376, 0.24560547, -0.24570313, -0.2957...</td>\n",
              "      <td>[-0.18076172, 0.16953126, -0.13066407, -0.1854...</td>\n",
              "      <td>[-0.23359375, -0.26933593, -0.14326172, -0.254...</td>\n",
              "      <td>[-0.070336916, -0.16132812, -0.7640625, -0.084...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.4140625, 0.2890625, 0.55078125,...</td>\n",
              "      <td>[-0.9453125, 0.5390625, -0.059814453, 0.835937...</td>\n",
              "      <td>[-1.265625, 0.05419922, 0.18554688, 0.6171875,...</td>\n",
              "      <td>[-1.2109375, 0.578125, -0.15625, 0.81640625, -...</td>\n",
              "      <td>[0.052734375, 0.103515625, 0.064453125, 0.8789...</td>\n",
              "      <td>[-0.09277344, -0.09277344, -0.3984375, 1.10156...</td>\n",
              "      <td>[-0.40039062, -0.23339844, -0.953125, 0.542968...</td>\n",
              "      <td>[-1.234375, -0.14355469, -1.1875, 0.37890625, ...</td>\n",
              "      <td>[-1.2421875, 0.36914062, -0.375, -0.0004882812...</td>\n",
              "      <td>[23.75, 2.4375, 2.625, -2.6875, 1.8515625, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>JAUBA is a town in the Central Equatorial Stat...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[2.1651042, -0.20144857, -0.13483073, 0.192757...</td>\n",
              "      <td>[0.11595052, 0.2218099, -0.22102864, -0.216666...</td>\n",
              "      <td>[0.1608724, 0.16777344, 0.119596355, -0.168229...</td>\n",
              "      <td>[0.20273438, -0.024186198, -0.4561198, -0.1901...</td>\n",
              "      <td>[0.32958984, 0.072338864, -0.3652995, -0.05286...</td>\n",
              "      <td>[0.25797525, -0.10279948, -0.06845703, -0.1782...</td>\n",
              "      <td>[0.5825521, -0.08932292, -0.7499349, -0.008658...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.515625, 0.421875, 0.265625, 0.57421875, -0...</td>\n",
              "      <td>[-0.97265625, 0.55859375, -0.08300781, 0.87109...</td>\n",
              "      <td>[-1.3046875, 0.07714844, 0.16503906, 0.65625, ...</td>\n",
              "      <td>[-1.25, 0.6015625, -0.19335938, 0.859375, -1.5...</td>\n",
              "      <td>[0.017578125, 0.115234375, 0.041015625, 0.9179...</td>\n",
              "      <td>[-0.12451172, -0.06738281, -0.45117188, 1.1406...</td>\n",
              "      <td>[-0.4140625, -0.21289062, -1.0078125, 0.59375,...</td>\n",
              "      <td>[-1.2265625, -0.10839844, -1.234375, 0.4277343...</td>\n",
              "      <td>[-1.15625, 0.3984375, -0.44140625, -0.04125976...</td>\n",
              "      <td>[18.625, 1.0859375, 1.3984375, -2.265625, 5.40...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6327</th>\n",
              "      <td>Jauba is located at the junction of the Equato...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[1.718099, -0.55709636, -0.23574218, 0.1610188...</td>\n",
              "      <td>[-0.0020833334, 0.10859375, -0.06705729, -0.31...</td>\n",
              "      <td>[-0.076627605, 0.045052085, 0.48854166, -0.231...</td>\n",
              "      <td>[-0.23190103, 0.011067708, -0.020996094, -0.01...</td>\n",
              "      <td>[-0.08331706, 0.096158855, -0.15289713, 0.2718...</td>\n",
              "      <td>[-0.123046875, -0.3981771, 0.43190104, 0.19238...</td>\n",
              "      <td>[0.47154948, -0.23108724, -0.2914388, 0.312630...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48046875, 0.40625, 0.29101562, 0.5390625, ...</td>\n",
              "      <td>[-0.94140625, 0.53125, -0.072265625, 0.8359375...</td>\n",
              "      <td>[-1.265625, 0.045410156, 0.1640625, 0.6328125,...</td>\n",
              "      <td>[-1.203125, 0.5625, -0.18164062, 0.828125, -1....</td>\n",
              "      <td>[0.048828125, 0.087890625, 0.0390625, 0.894531...</td>\n",
              "      <td>[-0.109375, -0.10839844, -0.41015625, 1.109375...</td>\n",
              "      <td>[-0.42382812, -0.2421875, -0.96875, 0.546875, ...</td>\n",
              "      <td>[-1.2421875, -0.16210938, -1.203125, 0.4472656...</td>\n",
              "      <td>[-1.1875, 0.43554688, -0.3984375, 0.033691406,...</td>\n",
              "      <td>[27.5, 0.29296875, 2.734375, -2.828125, 4.9062...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6328</th>\n",
              "      <td>JUABA is an administrative unit in the Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[1.9664885, 0.03098016, -0.1511102, -0.0199038...</td>\n",
              "      <td>[0.064170435, 0.39941406, -0.09530479, -0.4312...</td>\n",
              "      <td>[-0.041272614, 0.21643709, 0.0989926, -0.45826...</td>\n",
              "      <td>[0.018117804, -0.05448191, -0.2706106, -0.3657...</td>\n",
              "      <td>[0.17895508, 0.056409333, -0.473787, -0.188065...</td>\n",
              "      <td>[0.30062705, -0.25406045, -0.07139186, -0.6759...</td>\n",
              "      <td>[0.7155119, -0.018451892, -0.6802786, -0.43929...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.515625, 0.41992188, 0.25585938, 0.54296875...</td>\n",
              "      <td>[-0.97265625, 0.55078125, -0.09863281, 0.83984...</td>\n",
              "      <td>[-1.3046875, 0.064453125, 0.14746094, 0.625, -...</td>\n",
              "      <td>[-1.25, 0.59375, -0.20410156, 0.8203125, -1.51...</td>\n",
              "      <td>[0.0234375, 0.1171875, 0.033203125, 0.890625, ...</td>\n",
              "      <td>[-0.122558594, -0.072753906, -0.44140625, 1.10...</td>\n",
              "      <td>[-0.40429688, -0.20898438, -0.9921875, 0.56640...</td>\n",
              "      <td>[-1.21875, -0.08105469, -1.21875, 0.40039062, ...</td>\n",
              "      <td>[-1.109375, 0.46875, -0.3671875, -0.031982422,...</td>\n",
              "      <td>[20.0, 1.21875, 1.0546875, -1.96875, 3.984375,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>Juaaba is a small town in South sudans Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[2.2879465, -0.12288993, -0.122558594, 0.21595...</td>\n",
              "      <td>[0.2915039, 0.38071987, -0.14964077, -0.321568...</td>\n",
              "      <td>[0.077427454, 0.3391462, 0.18118723, -0.318394...</td>\n",
              "      <td>[-0.03690011, 0.058175225, -0.18575613, -0.326...</td>\n",
              "      <td>[0.11495536, 0.08844866, -0.45608956, -0.05329...</td>\n",
              "      <td>[0.34001812, -0.2382115, -0.1725551, -0.268554...</td>\n",
              "      <td>[0.5902623, 0.0138811385, -1.1711076, -0.31309...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.46875, 0.40039062, 0.27734375, 0.5546875, ...</td>\n",
              "      <td>[-0.9296875, 0.5390625, -0.07080078, 0.8554687...</td>\n",
              "      <td>[-1.2578125, 0.049560547, 0.15917969, 0.648437...</td>\n",
              "      <td>[-1.2109375, 0.5703125, -0.19335938, 0.84375, ...</td>\n",
              "      <td>[0.041015625, 0.083984375, 0.033203125, 0.9023...</td>\n",
              "      <td>[-0.103515625, -0.09033203, -0.4453125, 1.125,...</td>\n",
              "      <td>[-0.40820312, -0.24316406, -1.0078125, 0.57421...</td>\n",
              "      <td>[-1.2265625, -0.14257812, -1.265625, 0.3925781...</td>\n",
              "      <td>[-1.2578125, 0.3671875, -0.4453125, -0.0380859...</td>\n",
              "      <td>[12.125, -0.19628906, 1.1796875, -3.046875, 3....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6330 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-309824a3-d428-49fb-a365-a1f7d7dc72cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-309824a3-d428-49fb-a365-a1f7d7dc72cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-309824a3-d428-49fb-a365-a1f7d7dc72cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa9fe72e-2da6-46dc-8ed3-2b53edfd2079\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa9fe72e-2da6-46dc-8ed3-2b53edfd2079')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa9fe72e-2da6-46dc-8ed3-2b53edfd2079 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_41c1806d-2357-44b1-b6d6-8ff45a116720\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('activation_tf_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_41c1806d-2357-44b1-b6d6-8ff45a116720 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('activation_tf_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              statement  label       area  \\\n",
              "0              The planet Uranus is tilted on its side.      1      facts   \n",
              "1     Sharks are sea creatures that have a reputatio...      1      facts   \n",
              "2                          An adult human has 32 teeth.      1      facts   \n",
              "3     The smallest continent in the world is Australia.      1      facts   \n",
              "4     The Amazon River is the largest river in the w...      1      facts   \n",
              "...                                                 ...    ...        ...   \n",
              "6325                 The capital of South Suda is Juba.      0  generated   \n",
              "6326  JAUBA is a town in the Central Equatorial Stat...      0  generated   \n",
              "6327  Jauba is located at the junction of the Equato...      0  generated   \n",
              "6328  JUABA is an administrative unit in the Equator...      0  generated   \n",
              "6329  Juaaba is a small town in South sudans Equator...      0  generated   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [1.8242188, 0.014973958, 0.30143228, 0.2826606...   \n",
              "1     [1.6576773, -0.23715445, -0.41706732, 0.110314...   \n",
              "2     [1.4643012, -0.42925346, 0.23860677, 0.4300130...   \n",
              "3     [1.4700521, 0.0687934, 0.18645562, 0.42199367,...   \n",
              "4     [1.1790866, -0.024188701, -0.20665565, 0.20469...   \n",
              "...                                                 ...   \n",
              "6325  [1.6899414, 0.090063475, -0.34589845, 0.427441...   \n",
              "6326  [2.1651042, -0.20144857, -0.13483073, 0.192757...   \n",
              "6327  [1.718099, -0.55709636, -0.23574218, 0.1610188...   \n",
              "6328  [1.9664885, 0.03098016, -0.1511102, -0.0199038...   \n",
              "6329  [2.2879465, -0.12288993, -0.122558594, 0.21595...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [0.056857638, 0.4626736, 0.16932508, -0.357638...   \n",
              "1     [0.095853366, 0.023212139, -0.30155122, -0.453...   \n",
              "2     [0.15288629, -0.11577691, -0.13226996, -0.4715...   \n",
              "3     [0.234375, 0.08821615, -0.08292643, -0.1408420...   \n",
              "4     [0.020695614, 0.22814003, -0.35821062, -0.4532...   \n",
              "...                                                 ...   \n",
              "6325  [0.05234375, 0.39042968, -0.37111816, -0.52656...   \n",
              "6326  [0.11595052, 0.2218099, -0.22102864, -0.216666...   \n",
              "6327  [-0.0020833334, 0.10859375, -0.06705729, -0.31...   \n",
              "6328  [0.064170435, 0.39941406, -0.09530479, -0.4312...   \n",
              "6329  [0.2915039, 0.38071987, -0.14964077, -0.321568...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [-0.19216579, 0.4826389, 0.1438802, -0.4792751...   \n",
              "1     [-0.048753005, 0.015211839, -0.088604264, -0.4...   \n",
              "2     [-0.0070529515, -0.13682726, 0.06939019, -0.25...   \n",
              "3     [0.0703125, 0.09830729, 0.32109916, 0.00260416...   \n",
              "4     [-0.21146335, 0.20551945, -0.05577674, -0.3368...   \n",
              "...                                                 ...   \n",
              "6325  [-0.42539063, 0.3416992, 0.17148438, -0.596093...   \n",
              "6326  [0.1608724, 0.16777344, 0.119596355, -0.168229...   \n",
              "6327  [-0.076627605, 0.045052085, 0.48854166, -0.231...   \n",
              "6328  [-0.041272614, 0.21643709, 0.0989926, -0.45826...   \n",
              "6329  [0.077427454, 0.3391462, 0.18118723, -0.318394...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.28027344, 0.14887153, -0.34320748, -0.1949...   \n",
              "1     [-0.30742937, -0.17337741, -0.37474647, -0.137...   \n",
              "2     [-0.2250434, -0.19845921, -0.10394965, -0.2877...   \n",
              "3     [-0.06287977, -0.2046441, -0.1779514, 0.145073...   \n",
              "4     [-0.34795672, 0.057016227, -0.48948318, 0.0582...   \n",
              "...                                                 ...   \n",
              "6325  [-0.26484376, 0.24560547, -0.24570313, -0.2957...   \n",
              "6326  [0.20273438, -0.024186198, -0.4561198, -0.1901...   \n",
              "6327  [-0.23190103, 0.011067708, -0.020996094, -0.01...   \n",
              "6328  [0.018117804, -0.05448191, -0.2706106, -0.3657...   \n",
              "6329  [-0.03690011, 0.058175225, -0.18575613, -0.326...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.09988064, 0.17556423, -0.5488281, -0.06087...   \n",
              "1     [-0.50946516, -0.27554086, -0.48152044, -0.087...   \n",
              "2     [0.0907118, -0.3184679, -0.30837673, -0.218532...   \n",
              "3     [0.092447914, -0.024956597, -0.429579, 0.26736...   \n",
              "4     [-0.063777044, 0.27208534, -0.6057692, 0.11204...   \n",
              "...                                                 ...   \n",
              "6325  [-0.18076172, 0.16953126, -0.13066407, -0.1854...   \n",
              "6326  [0.32958984, 0.072338864, -0.3652995, -0.05286...   \n",
              "6327  [-0.08331706, 0.096158855, -0.15289713, 0.2718...   \n",
              "6328  [0.17895508, 0.056409333, -0.473787, -0.188065...   \n",
              "6329  [0.11495536, 0.08844866, -0.45608956, -0.05329...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [0.35253906, 0.00043402778, 0.0029296875, -0.1...   \n",
              "1     [-0.22385818, -0.6236478, -0.68073916, -0.0413...   \n",
              "2     [0.4171007, -0.1802029, -0.044704862, -0.04058...   \n",
              "3     [-0.0059136283, -0.42719185, -0.3060981, 0.041...   \n",
              "4     [-0.09878305, 0.07016226, -0.4611253, 0.136944...   \n",
              "...                                                 ...   \n",
              "6325  [-0.23359375, -0.26933593, -0.14326172, -0.254...   \n",
              "6326  [0.25797525, -0.10279948, -0.06845703, -0.1782...   \n",
              "6327  [-0.123046875, -0.3981771, 0.43190104, 0.19238...   \n",
              "6328  [0.30062705, -0.25406045, -0.07139186, -0.6759...   \n",
              "6329  [0.34001812, -0.2382115, -0.1725551, -0.268554...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.7221137, -0.21473524, -0.08993869, -0.50846...  ...   \n",
              "1     [0.029897837, -0.97273135, -0.77659255, -0.074...  ...   \n",
              "2     [0.4921875, -0.17274305, -0.69259983, -0.27365...  ...   \n",
              "3     [0.3373481, -0.5115017, -0.48676217, -0.137641...  ...   \n",
              "4     [0.29454628, 0.104191706, -0.9107572, -0.13690...  ...   \n",
              "...                                                 ...  ...   \n",
              "6325  [-0.070336916, -0.16132812, -0.7640625, -0.084...  ...   \n",
              "6326  [0.5825521, -0.08932292, -0.7499349, -0.008658...  ...   \n",
              "6327  [0.47154948, -0.23108724, -0.2914388, 0.312630...  ...   \n",
              "6328  [0.7155119, -0.018451892, -0.6802786, -0.43929...  ...   \n",
              "6329  [0.5902623, 0.0138811385, -1.1711076, -0.31309...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.4765625, 0.39453125, 0.30273438, 0.5273437...   \n",
              "1     [-0.5, 0.43554688, 0.3203125, 0.53515625, -0.4...   \n",
              "2     [-0.515625, 0.40625, 0.32421875, 0.515625, -0....   \n",
              "3     [-0.50390625, 0.390625, 0.3125, 0.49804688, -0...   \n",
              "4     [-0.4765625, 0.40234375, 0.28515625, 0.5351562...   \n",
              "...                                                 ...   \n",
              "6325  [-0.4921875, 0.4140625, 0.2890625, 0.55078125,...   \n",
              "6326  [-0.515625, 0.421875, 0.265625, 0.57421875, -0...   \n",
              "6327  [-0.48046875, 0.40625, 0.29101562, 0.5390625, ...   \n",
              "6328  [-0.515625, 0.41992188, 0.25585938, 0.54296875...   \n",
              "6329  [-0.46875, 0.40039062, 0.27734375, 0.5546875, ...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.9296875, 0.51953125, -0.072265625, 0.82421...   \n",
              "1     [-0.953125, 0.5625, -0.040527344, 0.83203125, ...   \n",
              "2     [-0.9765625, 0.5390625, -0.036132812, 0.796875...   \n",
              "3     [-0.95703125, 0.5234375, -0.052734375, 0.79687...   \n",
              "4     [-0.9296875, 0.53515625, -0.08251953, 0.832031...   \n",
              "...                                                 ...   \n",
              "6325  [-0.9453125, 0.5390625, -0.059814453, 0.835937...   \n",
              "6326  [-0.97265625, 0.55859375, -0.08300781, 0.87109...   \n",
              "6327  [-0.94140625, 0.53125, -0.072265625, 0.8359375...   \n",
              "6328  [-0.97265625, 0.55078125, -0.09863281, 0.83984...   \n",
              "6329  [-0.9296875, 0.5390625, -0.07080078, 0.8554687...   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.25, 0.015136719, 0.15625, 0.62890625, -1.6...   \n",
              "1     [-1.2890625, 0.049316406, 0.19335938, 0.625, -...   \n",
              "2     [-1.3046875, 0.01928711, 0.18359375, 0.6015625...   \n",
              "3     [-1.28125, 0.017822266, 0.18066406, 0.58984375...   \n",
              "4     [-1.2578125, 0.042236328, 0.16113281, 0.640625...   \n",
              "...                                                 ...   \n",
              "6325  [-1.265625, 0.05419922, 0.18554688, 0.6171875,...   \n",
              "6326  [-1.3046875, 0.07714844, 0.16503906, 0.65625, ...   \n",
              "6327  [-1.265625, 0.045410156, 0.1640625, 0.6328125,...   \n",
              "6328  [-1.3046875, 0.064453125, 0.14746094, 0.625, -...   \n",
              "6329  [-1.2578125, 0.049560547, 0.15917969, 0.648437...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.203125, 0.53125, -0.18652344, 0.82421875, ...   \n",
              "1     [-1.234375, 0.55859375, -0.16992188, 0.8242187...   \n",
              "2     [-1.2578125, 0.53515625, -0.16894531, 0.804687...   \n",
              "3     [-1.234375, 0.5390625, -0.16601562, 0.7890625,...   \n",
              "4     [-1.203125, 0.55859375, -0.19921875, 0.8398437...   \n",
              "...                                                 ...   \n",
              "6325  [-1.2109375, 0.578125, -0.15625, 0.81640625, -...   \n",
              "6326  [-1.25, 0.6015625, -0.19335938, 0.859375, -1.5...   \n",
              "6327  [-1.203125, 0.5625, -0.18164062, 0.828125, -1....   \n",
              "6328  [-1.25, 0.59375, -0.20410156, 0.8203125, -1.51...   \n",
              "6329  [-1.2109375, 0.5703125, -0.19335938, 0.84375, ...   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [0.041015625, 0.048828125, 0.015625, 0.8945312...   \n",
              "1     [0.025390625, 0.107421875, 0.056640625, 0.8867...   \n",
              "2     [-0.0234375, 0.061523438, 0.015625, 0.88671875...   \n",
              "3     [0.025390625, 0.06640625, 0.04296875, 0.855468...   \n",
              "4     [0.05078125, 0.091796875, 0.021484375, 0.91015...   \n",
              "...                                                 ...   \n",
              "6325  [0.052734375, 0.103515625, 0.064453125, 0.8789...   \n",
              "6326  [0.017578125, 0.115234375, 0.041015625, 0.9179...   \n",
              "6327  [0.048828125, 0.087890625, 0.0390625, 0.894531...   \n",
              "6328  [0.0234375, 0.1171875, 0.033203125, 0.890625, ...   \n",
              "6329  [0.041015625, 0.083984375, 0.033203125, 0.9023...   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.11035156, -0.15820312, -0.45507812, 1.1171...   \n",
              "1     [-0.123535156, -0.10986328, -0.37890625, 1.117...   \n",
              "2     [-0.1484375, -0.1484375, -0.42578125, 1.09375,...   \n",
              "3     [-0.13476562, -0.16015625, -0.38476562, 1.0625...   \n",
              "4     [-0.09667969, -0.12109375, -0.42578125, 1.125,...   \n",
              "...                                                 ...   \n",
              "6325  [-0.09277344, -0.09277344, -0.3984375, 1.10156...   \n",
              "6326  [-0.12451172, -0.06738281, -0.45117188, 1.1406...   \n",
              "6327  [-0.109375, -0.10839844, -0.41015625, 1.109375...   \n",
              "6328  [-0.122558594, -0.072753906, -0.44140625, 1.10...   \n",
              "6329  [-0.103515625, -0.09033203, -0.4453125, 1.125,...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.43359375, -0.30859375, -1.0, 0.5390625, -1...   \n",
              "1     [-0.44140625, -0.23046875, -0.96875, 0.5703125...   \n",
              "2     [-0.4453125, -0.296875, -0.9765625, 0.5390625,...   \n",
              "3     [-0.4609375, -0.30664062, -0.9765625, 0.507812...   \n",
              "4     [-0.42578125, -0.25195312, -0.98046875, 0.5781...   \n",
              "...                                                 ...   \n",
              "6325  [-0.40039062, -0.23339844, -0.953125, 0.542968...   \n",
              "6326  [-0.4140625, -0.21289062, -1.0078125, 0.59375,...   \n",
              "6327  [-0.42382812, -0.2421875, -0.96875, 0.546875, ...   \n",
              "6328  [-0.40429688, -0.20898438, -0.9921875, 0.56640...   \n",
              "6329  [-0.40820312, -0.24316406, -1.0078125, 0.57421...   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.296875, -0.1640625, -1.171875, 0.37109375,...   \n",
              "1     [-1.2890625, -0.14453125, -1.1953125, 0.449218...   \n",
              "2     [-1.3203125, -0.19238281, -1.2109375, 0.419921...   \n",
              "3     [-1.3125, -0.22265625, -1.2109375, 0.38085938,...   \n",
              "4     [-1.265625, -0.14550781, -1.1796875, 0.453125,...   \n",
              "...                                                 ...   \n",
              "6325  [-1.234375, -0.14355469, -1.1875, 0.37890625, ...   \n",
              "6326  [-1.2265625, -0.10839844, -1.234375, 0.4277343...   \n",
              "6327  [-1.2421875, -0.16210938, -1.203125, 0.4472656...   \n",
              "6328  [-1.21875, -0.08105469, -1.21875, 0.40039062, ...   \n",
              "6329  [-1.2265625, -0.14257812, -1.265625, 0.3925781...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.2890625, 0.29882812, -0.3828125, 0.1367187...   \n",
              "1     [-1.34375, 0.3515625, -0.37890625, 0.14941406,...   \n",
              "2     [-1.421875, 0.3984375, -0.3359375, 0.033203125...   \n",
              "3     [-1.421875, 0.34765625, -0.41796875, 0.0625, -...   \n",
              "4     [-1.34375, 0.375, -0.3671875, 0.06347656, -1.0...   \n",
              "...                                                 ...   \n",
              "6325  [-1.2421875, 0.36914062, -0.375, -0.0004882812...   \n",
              "6326  [-1.15625, 0.3984375, -0.44140625, -0.04125976...   \n",
              "6327  [-1.1875, 0.43554688, -0.3984375, 0.033691406,...   \n",
              "6328  [-1.109375, 0.46875, -0.3671875, -0.031982422,...   \n",
              "6329  [-1.2578125, 0.3671875, -0.4453125, -0.0380859...   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [28.25, -4.53125, 0.34179688, -0.94140625, 3.4...  \n",
              "1     [26.75, -5.125, -0.8046875, -1.7734375, -0.671...  \n",
              "2     [23.0, -1.3671875, -3.125, 3.8125, -0.76953125...  \n",
              "3     [23.875, -3.890625, 1.15625, 0.22753906, 3.828...  \n",
              "4     [29.875, -1.140625, 2.640625, -0.88671875, 1.9...  \n",
              "...                                                 ...  \n",
              "6325  [23.75, 2.4375, 2.625, -2.6875, 1.8515625, 0.0...  \n",
              "6326  [18.625, 1.0859375, 1.3984375, -2.265625, 5.40...  \n",
              "6327  [27.5, 0.29296875, 2.734375, -2.828125, 4.9062...  \n",
              "6328  [20.0, 1.21875, 1.0546875, -1.96875, 3.984375,...  \n",
              "6329  [12.125, -0.19628906, 1.1796875, -3.046875, 3....  \n",
              "\n",
              "[6330 rows x 29 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df = extract_activations_df(tf_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_tf_df, 'true-false', model_id_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcnkzN3TkKmp"
      },
      "outputs": [],
      "source": [
        "save_activations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hpgU5El7Li"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DpPU1tWl6sk",
        "outputId": "5e14002e-a8af-41d8-cd43-f8c9d718ead1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing 6330 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 396/396 [05:27<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n",
            "Saving true-false_t5gemma-2b-2b-ul2 to GDrive...\n",
            "Saved true-false_t5gemma-2b-2b-ul2\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 16\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df_2b = extract_activations_df(tf_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_tf_df_2b, 'true-false', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "QMsDqX2Unz_R",
        "outputId": "f3377052-217e-4f67-bd3c-66b0a6db5448"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_tf_df_2b"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ce809b45-22e3-463d-a7af-b631d93ffbcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>area</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_18</th>\n",
              "      <th>decoder_layer_19</th>\n",
              "      <th>decoder_layer_20</th>\n",
              "      <th>decoder_layer_21</th>\n",
              "      <th>decoder_layer_22</th>\n",
              "      <th>decoder_layer_23</th>\n",
              "      <th>decoder_layer_24</th>\n",
              "      <th>decoder_layer_25</th>\n",
              "      <th>decoder_layer_26</th>\n",
              "      <th>decoder_layer_27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The planet Uranus is tilted on its side.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[0.9109158, -0.86013454, -0.80803764, 0.016710...</td>\n",
              "      <td>[0.7178819, 0.14713542, -0.4470486, 0.07248264...</td>\n",
              "      <td>[0.5036892, -0.16075304, -0.5388455, -0.543402...</td>\n",
              "      <td>[0.20155165, -0.37565103, -0.090277776, -1.196...</td>\n",
              "      <td>[0.2595486, 0.46126303, -0.3028429, -1.1968316...</td>\n",
              "      <td>[-0.46918404, 0.80251735, -0.31271702, -0.1119...</td>\n",
              "      <td>[0.32443577, 0.4969618, -0.017795138, -1.05642...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.28515625, -0.25195312, -0.36914062, -0.4257...</td>\n",
              "      <td>[0.04296875, -0.19335938, 0.049072266, -0.6796...</td>\n",
              "      <td>[0.41992188, 0.45898438, -0.36914062, 0.128906...</td>\n",
              "      <td>[0.18359375, -0.765625, -0.7890625, -0.6210937...</td>\n",
              "      <td>[-0.20703125, -0.41796875, -0.4609375, -0.6992...</td>\n",
              "      <td>[-2.34375, 0.029296875, 1.0859375, -1.7109375,...</td>\n",
              "      <td>[-2.921875, 1.21875, 1.4609375, -5.15625, 1.21...</td>\n",
              "      <td>[-2.3125, 1.46875, 1.4609375, -5.9375, 1.07031...</td>\n",
              "      <td>[3.859375, 1.78125, 2.9375, -5.53125, 1.960937...</td>\n",
              "      <td>[1.84375, -0.55859375, 0.73046875, -0.71484375...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sharks are sea creatures that have a reputatio...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[0.14000526, -0.9311899, -0.14929257, 0.061598...</td>\n",
              "      <td>[0.15978065, -0.07527043, 0.421875, 0.96484375...</td>\n",
              "      <td>[0.007512019, -0.76171875, 0.5688101, 1.244140...</td>\n",
              "      <td>[0.40414664, -1.0458233, 0.5972806, 0.29710037...</td>\n",
              "      <td>[0.1711238, -0.18389423, -0.13431491, 0.029897...</td>\n",
              "      <td>[0.07932692, 0.096905045, -0.45718148, 0.58263...</td>\n",
              "      <td>[0.4341947, -0.68847656, -0.67277646, -0.39475...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.265625, -0.27929688, -0.4453125, -0.4902343...</td>\n",
              "      <td>[0.05859375, -0.2421875, 0.02734375, -0.695312...</td>\n",
              "      <td>[0.43359375, 0.390625, -0.46289062, 0.12890625...</td>\n",
              "      <td>[0.20703125, -0.82421875, -0.8671875, -0.60156...</td>\n",
              "      <td>[-0.20214844, -0.56640625, -0.51953125, -0.699...</td>\n",
              "      <td>[-2.5, 0.025390625, 0.81640625, -1.6875, 0.25,...</td>\n",
              "      <td>[-2.890625, 1.0859375, 1.203125, -5.1875, 1.23...</td>\n",
              "      <td>[-2.484375, 1.4921875, 1.375, -5.65625, 1.3203...</td>\n",
              "      <td>[4.78125, 1.6875, 1.5, -5.84375, 1.5546875, -0...</td>\n",
              "      <td>[2.5625, -0.45898438, 0.14550781, -1.015625, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An adult human has 32 teeth.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[0.6130642, -0.2621528, 0.11461046, 0.4279514,...</td>\n",
              "      <td>[0.37239584, -0.113715276, 0.43337673, 0.17187...</td>\n",
              "      <td>[-0.037109375, 0.09483507, 0.8364258, 0.393229...</td>\n",
              "      <td>[0.56000435, 0.6281467, 0.6768663, -0.4625651,...</td>\n",
              "      <td>[0.016276041, 0.74609375, 0.55533856, -0.18945...</td>\n",
              "      <td>[-0.3997396, 0.05859375, 0.16666667, 0.6640625...</td>\n",
              "      <td>[0.32074654, -0.44059244, -0.062147353, -0.587...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.26171875, -0.296875, -0.49609375, -0.423828...</td>\n",
              "      <td>[0.03515625, -0.24804688, -0.019897461, -0.695...</td>\n",
              "      <td>[0.4140625, 0.40625, -0.48046875, 0.08984375, ...</td>\n",
              "      <td>[0.19140625, -0.82421875, -0.8671875, -0.71093...</td>\n",
              "      <td>[-0.25390625, -0.5234375, -0.515625, -0.839843...</td>\n",
              "      <td>[-2.40625, 0.24804688, 0.921875, -1.984375, 0....</td>\n",
              "      <td>[-2.796875, 1.4140625, 1.234375, -5.625, 1.554...</td>\n",
              "      <td>[-2.40625, 1.6484375, 1.46875, -6.25, 1.46875,...</td>\n",
              "      <td>[2.625, 2.625, 1.78125, -6.21875, 1.890625, -0...</td>\n",
              "      <td>[2.296875, 0.86328125, 1.1875, -0.85546875, 2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The smallest continent in the world is Australia.</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[0.07595486, -0.17903645, -0.22743055, 0.13628...</td>\n",
              "      <td>[0.47092015, 0.75130206, -0.32834202, -0.41514...</td>\n",
              "      <td>[0.30447048, 0.83029515, -0.29644096, -0.57855...</td>\n",
              "      <td>[0.46679688, 0.25260416, 0.074652776, -1.26540...</td>\n",
              "      <td>[0.5512153, 0.59939235, -0.69140625, -0.457465...</td>\n",
              "      <td>[-0.5390625, 1.1796875, -1.2220052, -0.0125868...</td>\n",
              "      <td>[0.30555555, 1.3854166, -0.9279514, -0.4619140...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.328125, -0.2109375, -0.53515625, -0.546875,...</td>\n",
              "      <td>[0.0859375, -0.1796875, -0.10888672, -0.800781...</td>\n",
              "      <td>[0.484375, 0.44921875, -0.5859375, 0.0, -0.296...</td>\n",
              "      <td>[0.24609375, -0.76953125, -0.9765625, -0.75781...</td>\n",
              "      <td>[-0.234375, -0.5078125, -0.59375, -0.8203125, ...</td>\n",
              "      <td>[-2.625, 0.2265625, 0.8671875, -1.7421875, 0.2...</td>\n",
              "      <td>[-3.140625, 1.359375, 1.234375, -5.25, 1.14843...</td>\n",
              "      <td>[-2.65625, 1.765625, 1.234375, -5.84375, 1.101...</td>\n",
              "      <td>[2.125, 3.453125, 1.90625, -4.84375, 2.65625, ...</td>\n",
              "      <td>[-0.26367188, 0.48242188, 0.81640625, -1.32031...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Amazon River is the largest river in the w...</td>\n",
              "      <td>1</td>\n",
              "      <td>facts</td>\n",
              "      <td>[0.88957334, -0.4628155, 0.68028843, 1.2866586...</td>\n",
              "      <td>[0.68659854, 0.5551758, 0.4826097, 1.0474759, ...</td>\n",
              "      <td>[0.60772234, 0.10832332, 0.094839245, 1.115835...</td>\n",
              "      <td>[1.0803787, 0.2701322, 0.36989182, -0.05709134...</td>\n",
              "      <td>[0.509991, 0.8996394, -0.21048678, 0.5871394, ...</td>\n",
              "      <td>[0.1789363, 1.2509015, -0.58759016, 0.94771636...</td>\n",
              "      <td>[0.74038464, 0.42822266, -0.092998795, -0.0021...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.23828125, -0.29492188, -0.52734375, -0.4218...</td>\n",
              "      <td>[-0.02734375, -0.23828125, -0.053955078, -0.67...</td>\n",
              "      <td>[0.37890625, 0.39648438, -0.50390625, 0.152343...</td>\n",
              "      <td>[0.1328125, -0.83203125, -0.90625, -0.61328125...</td>\n",
              "      <td>[-0.28320312, -0.5234375, -0.5703125, -0.66796...</td>\n",
              "      <td>[-2.59375, 0.09765625, 1.03125, -1.484375, 0.3...</td>\n",
              "      <td>[-3.125, 1.2890625, 1.3125, -5.0625, 1.375, -0...</td>\n",
              "      <td>[-2.4375, 1.5703125, 1.484375, -5.84375, 1.359...</td>\n",
              "      <td>[4.25, 3.21875, 2.96875, -4.78125, 2.3125, 1.0...</td>\n",
              "      <td>[1.6015625, 0.21484375, 2.0, -0.6640625, 2.437...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6325</th>\n",
              "      <td>The capital of South Suda is Juba.</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[0.40429688, -0.35566407, -0.37021485, -0.1209...</td>\n",
              "      <td>[0.5800781, 0.09475098, -0.8785156, 0.28378907...</td>\n",
              "      <td>[0.45546874, -1.2558105, -0.946875, 0.33125, -...</td>\n",
              "      <td>[0.54892576, -1.3199219, -0.265625, -0.1833007...</td>\n",
              "      <td>[0.71845704, -0.67148435, -0.73105466, -0.7600...</td>\n",
              "      <td>[0.34023437, -0.7270508, -0.32539064, -0.17246...</td>\n",
              "      <td>[0.33398438, 0.12109375, 0.38447267, -1.092968...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.234375, -0.35546875, -0.46875, -0.5703125, ...</td>\n",
              "      <td>[0.0, -0.2890625, -0.0034179688, -0.80078125, ...</td>\n",
              "      <td>[0.40234375, 0.36914062, -0.4921875, 0.0390625...</td>\n",
              "      <td>[0.14453125, -0.84375, -0.8828125, -0.7109375,...</td>\n",
              "      <td>[-0.3125, -0.5625, -0.5703125, -0.765625, -1.9...</td>\n",
              "      <td>[-2.5625, 0.06640625, 0.8671875, -1.734375, 0....</td>\n",
              "      <td>[-3.109375, 1.359375, 1.046875, -5.4375, 1.109...</td>\n",
              "      <td>[-2.5625, 1.6171875, 1.15625, -6.0625, 1.14062...</td>\n",
              "      <td>[2.421875, 3.1875, 1.765625, -4.25, 2.015625, ...</td>\n",
              "      <td>[0.53515625, 0.375, 0.6015625, -0.84375, 1.648...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>JAUBA is a town in the Central Equatorial Stat...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[0.37447917, -1.3463541, -0.7164062, 0.5007812...</td>\n",
              "      <td>[0.575, -0.5473633, -0.6655599, 0.4046224, 0.4...</td>\n",
              "      <td>[0.19700521, -0.43645832, -0.33815104, 0.05989...</td>\n",
              "      <td>[0.043554686, -0.569401, 0.228125, -0.20735677...</td>\n",
              "      <td>[-0.17265625, -0.033203125, -0.05266927, -0.13...</td>\n",
              "      <td>[-0.16523437, 0.056184895, -0.13515624, 0.7149...</td>\n",
              "      <td>[-0.23776041, -0.38190106, 0.44335938, -0.7375...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.1484375, -0.421875, -0.53515625, -0.4667968...</td>\n",
              "      <td>[-0.0625, -0.33398438, -0.03466797, -0.8046875...</td>\n",
              "      <td>[0.3515625, 0.3046875, -0.52734375, 0.03125, -...</td>\n",
              "      <td>[0.125, -0.9375, -0.9140625, -0.73046875, -1.7...</td>\n",
              "      <td>[-0.27929688, -0.671875, -0.5859375, -0.804687...</td>\n",
              "      <td>[-2.609375, -0.015625, 0.9921875, -1.65625, 0....</td>\n",
              "      <td>[-3.015625, 1.1484375, 1.03125, -5.28125, 1.15...</td>\n",
              "      <td>[-2.546875, 1.390625, 1.140625, -6.03125, 1.28...</td>\n",
              "      <td>[3.234375, 2.375, 2.6875, -4.5, 2.859375, 2.43...</td>\n",
              "      <td>[0.66015625, -0.6796875, 1.6171875, -0.2578125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6327</th>\n",
              "      <td>Jauba is located at the junction of the Equato...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[1.1541016, -1.3690104, -0.52441406, 0.2944010...</td>\n",
              "      <td>[1.4063314, -0.5888021, -0.7594401, 0.26158854...</td>\n",
              "      <td>[1.4248698, -0.5119141, -1.0794597, -0.2738932...</td>\n",
              "      <td>[0.6610677, -0.67815757, -0.3191406, -0.741666...</td>\n",
              "      <td>[0.39635417, -0.110416666, -0.72415364, -0.782...</td>\n",
              "      <td>[0.5410807, 0.1516927, -0.7972005, -0.04277343...</td>\n",
              "      <td>[0.5263021, 0.44427082, -0.90052086, -1.207812...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.19140625, -0.36914062, -0.44921875, -0.3593...</td>\n",
              "      <td>[-0.01953125, -0.30273438, 0.037109375, -0.667...</td>\n",
              "      <td>[0.375, 0.328125, -0.42773438, 0.1640625, -0.3...</td>\n",
              "      <td>[0.11328125, -0.9140625, -0.83203125, -0.60156...</td>\n",
              "      <td>[-0.2578125, -0.6484375, -0.5625, -0.60546875,...</td>\n",
              "      <td>[-2.5, -0.001953125, 1.015625, -1.5390625, 0.1...</td>\n",
              "      <td>[-3.125, 1.2890625, 1.171875, -5.0625, 1.01562...</td>\n",
              "      <td>[-2.609375, 1.484375, 1.421875, -5.78125, 1.14...</td>\n",
              "      <td>[2.9375, 2.828125, 3.28125, -4.6875, 1.6875, 0...</td>\n",
              "      <td>[0.88671875, -0.41796875, 1.734375, -0.9414062...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6328</th>\n",
              "      <td>JUABA is an administrative unit in the Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[0.8184622, -1.1554276, -0.50945723, -0.191817...</td>\n",
              "      <td>[1.1214535, -0.7328331, -0.35541734, -0.061215...</td>\n",
              "      <td>[1.0067846, -0.55828536, -0.22973633, -0.07092...</td>\n",
              "      <td>[0.3385074, -0.71026933, 0.22805305, -0.584703...</td>\n",
              "      <td>[0.063733555, -0.18678042, 0.46720806, -0.5142...</td>\n",
              "      <td>[-0.17259458, 0.16324013, -0.3051501, 0.241570...</td>\n",
              "      <td>[-0.67516446, -0.27400288, 0.046772204, -0.785...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.44726562, -0.5234375, -0.4667968...</td>\n",
              "      <td>[-0.046875, -0.375, -0.0107421875, -0.78515625...</td>\n",
              "      <td>[0.35546875, 0.26757812, -0.4921875, 0.0234375...</td>\n",
              "      <td>[0.15234375, -0.95703125, -0.89453125, -0.7734...</td>\n",
              "      <td>[-0.26367188, -0.69140625, -0.55078125, -0.835...</td>\n",
              "      <td>[-2.625, 0.01953125, 0.95703125, -1.7421875, 0...</td>\n",
              "      <td>[-3.125, 1.109375, 0.953125, -5.34375, 1.21875...</td>\n",
              "      <td>[-2.796875, 1.296875, 0.8515625, -6.0, 1.38281...</td>\n",
              "      <td>[3.96875, 3.28125, 1.90625, -5.84375, 2.78125,...</td>\n",
              "      <td>[0.8671875, -0.25585938, 0.51171875, -0.40625,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>Juaaba is a small town in South sudans Equator...</td>\n",
              "      <td>0</td>\n",
              "      <td>generated</td>\n",
              "      <td>[-0.076642714, -1.2223772, -1.0078125, -0.0831...</td>\n",
              "      <td>[0.38630024, -0.8507255, -0.62032646, 0.223353...</td>\n",
              "      <td>[-0.20424107, -0.7329799, -0.16029575, 0.00362...</td>\n",
              "      <td>[0.40527344, -0.398856, 0.31933594, -0.4666573...</td>\n",
              "      <td>[0.5853795, 0.39481026, -0.031947546, -0.52664...</td>\n",
              "      <td>[0.7378627, 0.6633301, -0.30754742, 0.51813614...</td>\n",
              "      <td>[0.32142857, 0.71173966, 0.64313614, -0.806919...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.2109375, -0.39257812, -0.44140625, -0.47265...</td>\n",
              "      <td>[0.0, -0.33789062, 0.02734375, -0.7890625, -0....</td>\n",
              "      <td>[0.40234375, 0.3046875, -0.44921875, 0.046875,...</td>\n",
              "      <td>[0.15625, -0.9140625, -0.859375, -0.7265625, -...</td>\n",
              "      <td>[-0.23828125, -0.6171875, -0.578125, -0.78125,...</td>\n",
              "      <td>[-2.546875, 0.0625, 0.953125, -1.5546875, 0.32...</td>\n",
              "      <td>[-3.0625, 1.3046875, 0.99609375, -5.03125, 1.1...</td>\n",
              "      <td>[-2.53125, 1.5390625, 1.0, -5.6875, 1.25, 1.13...</td>\n",
              "      <td>[2.828125, 2.5625, 2.5625, -3.484375, 3.03125,...</td>\n",
              "      <td>[0.671875, -0.20410156, 0.75, 0.23828125, 1.51...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6330 rows × 57 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce809b45-22e3-463d-a7af-b631d93ffbcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce809b45-22e3-463d-a7af-b631d93ffbcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce809b45-22e3-463d-a7af-b631d93ffbcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9abb68bc-c795-4fa6-baf0-d37761714578\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9abb68bc-c795-4fa6-baf0-d37761714578')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9abb68bc-c795-4fa6-baf0-d37761714578 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a5af8389-37eb-4aac-b861-46c473b546b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('activation_tf_df_2b')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a5af8389-37eb-4aac-b861-46c473b546b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('activation_tf_df_2b');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              statement  label       area  \\\n",
              "0              The planet Uranus is tilted on its side.      1      facts   \n",
              "1     Sharks are sea creatures that have a reputatio...      1      facts   \n",
              "2                          An adult human has 32 teeth.      1      facts   \n",
              "3     The smallest continent in the world is Australia.      1      facts   \n",
              "4     The Amazon River is the largest river in the w...      1      facts   \n",
              "...                                                 ...    ...        ...   \n",
              "6325                 The capital of South Suda is Juba.      0  generated   \n",
              "6326  JAUBA is a town in the Central Equatorial Stat...      0  generated   \n",
              "6327  Jauba is located at the junction of the Equato...      0  generated   \n",
              "6328  JUABA is an administrative unit in the Equator...      0  generated   \n",
              "6329  Juaaba is a small town in South sudans Equator...      0  generated   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [0.9109158, -0.86013454, -0.80803764, 0.016710...   \n",
              "1     [0.14000526, -0.9311899, -0.14929257, 0.061598...   \n",
              "2     [0.6130642, -0.2621528, 0.11461046, 0.4279514,...   \n",
              "3     [0.07595486, -0.17903645, -0.22743055, 0.13628...   \n",
              "4     [0.88957334, -0.4628155, 0.68028843, 1.2866586...   \n",
              "...                                                 ...   \n",
              "6325  [0.40429688, -0.35566407, -0.37021485, -0.1209...   \n",
              "6326  [0.37447917, -1.3463541, -0.7164062, 0.5007812...   \n",
              "6327  [1.1541016, -1.3690104, -0.52441406, 0.2944010...   \n",
              "6328  [0.8184622, -1.1554276, -0.50945723, -0.191817...   \n",
              "6329  [-0.076642714, -1.2223772, -1.0078125, -0.0831...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [0.7178819, 0.14713542, -0.4470486, 0.07248264...   \n",
              "1     [0.15978065, -0.07527043, 0.421875, 0.96484375...   \n",
              "2     [0.37239584, -0.113715276, 0.43337673, 0.17187...   \n",
              "3     [0.47092015, 0.75130206, -0.32834202, -0.41514...   \n",
              "4     [0.68659854, 0.5551758, 0.4826097, 1.0474759, ...   \n",
              "...                                                 ...   \n",
              "6325  [0.5800781, 0.09475098, -0.8785156, 0.28378907...   \n",
              "6326  [0.575, -0.5473633, -0.6655599, 0.4046224, 0.4...   \n",
              "6327  [1.4063314, -0.5888021, -0.7594401, 0.26158854...   \n",
              "6328  [1.1214535, -0.7328331, -0.35541734, -0.061215...   \n",
              "6329  [0.38630024, -0.8507255, -0.62032646, 0.223353...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [0.5036892, -0.16075304, -0.5388455, -0.543402...   \n",
              "1     [0.007512019, -0.76171875, 0.5688101, 1.244140...   \n",
              "2     [-0.037109375, 0.09483507, 0.8364258, 0.393229...   \n",
              "3     [0.30447048, 0.83029515, -0.29644096, -0.57855...   \n",
              "4     [0.60772234, 0.10832332, 0.094839245, 1.115835...   \n",
              "...                                                 ...   \n",
              "6325  [0.45546874, -1.2558105, -0.946875, 0.33125, -...   \n",
              "6326  [0.19700521, -0.43645832, -0.33815104, 0.05989...   \n",
              "6327  [1.4248698, -0.5119141, -1.0794597, -0.2738932...   \n",
              "6328  [1.0067846, -0.55828536, -0.22973633, -0.07092...   \n",
              "6329  [-0.20424107, -0.7329799, -0.16029575, 0.00362...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [0.20155165, -0.37565103, -0.090277776, -1.196...   \n",
              "1     [0.40414664, -1.0458233, 0.5972806, 0.29710037...   \n",
              "2     [0.56000435, 0.6281467, 0.6768663, -0.4625651,...   \n",
              "3     [0.46679688, 0.25260416, 0.074652776, -1.26540...   \n",
              "4     [1.0803787, 0.2701322, 0.36989182, -0.05709134...   \n",
              "...                                                 ...   \n",
              "6325  [0.54892576, -1.3199219, -0.265625, -0.1833007...   \n",
              "6326  [0.043554686, -0.569401, 0.228125, -0.20735677...   \n",
              "6327  [0.6610677, -0.67815757, -0.3191406, -0.741666...   \n",
              "6328  [0.3385074, -0.71026933, 0.22805305, -0.584703...   \n",
              "6329  [0.40527344, -0.398856, 0.31933594, -0.4666573...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [0.2595486, 0.46126303, -0.3028429, -1.1968316...   \n",
              "1     [0.1711238, -0.18389423, -0.13431491, 0.029897...   \n",
              "2     [0.016276041, 0.74609375, 0.55533856, -0.18945...   \n",
              "3     [0.5512153, 0.59939235, -0.69140625, -0.457465...   \n",
              "4     [0.509991, 0.8996394, -0.21048678, 0.5871394, ...   \n",
              "...                                                 ...   \n",
              "6325  [0.71845704, -0.67148435, -0.73105466, -0.7600...   \n",
              "6326  [-0.17265625, -0.033203125, -0.05266927, -0.13...   \n",
              "6327  [0.39635417, -0.110416666, -0.72415364, -0.782...   \n",
              "6328  [0.063733555, -0.18678042, 0.46720806, -0.5142...   \n",
              "6329  [0.5853795, 0.39481026, -0.031947546, -0.52664...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [-0.46918404, 0.80251735, -0.31271702, -0.1119...   \n",
              "1     [0.07932692, 0.096905045, -0.45718148, 0.58263...   \n",
              "2     [-0.3997396, 0.05859375, 0.16666667, 0.6640625...   \n",
              "3     [-0.5390625, 1.1796875, -1.2220052, -0.0125868...   \n",
              "4     [0.1789363, 1.2509015, -0.58759016, 0.94771636...   \n",
              "...                                                 ...   \n",
              "6325  [0.34023437, -0.7270508, -0.32539064, -0.17246...   \n",
              "6326  [-0.16523437, 0.056184895, -0.13515624, 0.7149...   \n",
              "6327  [0.5410807, 0.1516927, -0.7972005, -0.04277343...   \n",
              "6328  [-0.17259458, 0.16324013, -0.3051501, 0.241570...   \n",
              "6329  [0.7378627, 0.6633301, -0.30754742, 0.51813614...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.32443577, 0.4969618, -0.017795138, -1.05642...  ...   \n",
              "1     [0.4341947, -0.68847656, -0.67277646, -0.39475...  ...   \n",
              "2     [0.32074654, -0.44059244, -0.062147353, -0.587...  ...   \n",
              "3     [0.30555555, 1.3854166, -0.9279514, -0.4619140...  ...   \n",
              "4     [0.74038464, 0.42822266, -0.092998795, -0.0021...  ...   \n",
              "...                                                 ...  ...   \n",
              "6325  [0.33398438, 0.12109375, 0.38447267, -1.092968...  ...   \n",
              "6326  [-0.23776041, -0.38190106, 0.44335938, -0.7375...  ...   \n",
              "6327  [0.5263021, 0.44427082, -0.90052086, -1.207812...  ...   \n",
              "6328  [-0.67516446, -0.27400288, 0.046772204, -0.785...  ...   \n",
              "6329  [0.32142857, 0.71173966, 0.64313614, -0.806919...  ...   \n",
              "\n",
              "                                       decoder_layer_18  \\\n",
              "0     [0.28515625, -0.25195312, -0.36914062, -0.4257...   \n",
              "1     [0.265625, -0.27929688, -0.4453125, -0.4902343...   \n",
              "2     [0.26171875, -0.296875, -0.49609375, -0.423828...   \n",
              "3     [0.328125, -0.2109375, -0.53515625, -0.546875,...   \n",
              "4     [0.23828125, -0.29492188, -0.52734375, -0.4218...   \n",
              "...                                                 ...   \n",
              "6325  [0.234375, -0.35546875, -0.46875, -0.5703125, ...   \n",
              "6326  [0.1484375, -0.421875, -0.53515625, -0.4667968...   \n",
              "6327  [0.19140625, -0.36914062, -0.44921875, -0.3593...   \n",
              "6328  [0.140625, -0.44726562, -0.5234375, -0.4667968...   \n",
              "6329  [0.2109375, -0.39257812, -0.44140625, -0.47265...   \n",
              "\n",
              "                                       decoder_layer_19  \\\n",
              "0     [0.04296875, -0.19335938, 0.049072266, -0.6796...   \n",
              "1     [0.05859375, -0.2421875, 0.02734375, -0.695312...   \n",
              "2     [0.03515625, -0.24804688, -0.019897461, -0.695...   \n",
              "3     [0.0859375, -0.1796875, -0.10888672, -0.800781...   \n",
              "4     [-0.02734375, -0.23828125, -0.053955078, -0.67...   \n",
              "...                                                 ...   \n",
              "6325  [0.0, -0.2890625, -0.0034179688, -0.80078125, ...   \n",
              "6326  [-0.0625, -0.33398438, -0.03466797, -0.8046875...   \n",
              "6327  [-0.01953125, -0.30273438, 0.037109375, -0.667...   \n",
              "6328  [-0.046875, -0.375, -0.0107421875, -0.78515625...   \n",
              "6329  [0.0, -0.33789062, 0.02734375, -0.7890625, -0....   \n",
              "\n",
              "                                       decoder_layer_20  \\\n",
              "0     [0.41992188, 0.45898438, -0.36914062, 0.128906...   \n",
              "1     [0.43359375, 0.390625, -0.46289062, 0.12890625...   \n",
              "2     [0.4140625, 0.40625, -0.48046875, 0.08984375, ...   \n",
              "3     [0.484375, 0.44921875, -0.5859375, 0.0, -0.296...   \n",
              "4     [0.37890625, 0.39648438, -0.50390625, 0.152343...   \n",
              "...                                                 ...   \n",
              "6325  [0.40234375, 0.36914062, -0.4921875, 0.0390625...   \n",
              "6326  [0.3515625, 0.3046875, -0.52734375, 0.03125, -...   \n",
              "6327  [0.375, 0.328125, -0.42773438, 0.1640625, -0.3...   \n",
              "6328  [0.35546875, 0.26757812, -0.4921875, 0.0234375...   \n",
              "6329  [0.40234375, 0.3046875, -0.44921875, 0.046875,...   \n",
              "\n",
              "                                       decoder_layer_21  \\\n",
              "0     [0.18359375, -0.765625, -0.7890625, -0.6210937...   \n",
              "1     [0.20703125, -0.82421875, -0.8671875, -0.60156...   \n",
              "2     [0.19140625, -0.82421875, -0.8671875, -0.71093...   \n",
              "3     [0.24609375, -0.76953125, -0.9765625, -0.75781...   \n",
              "4     [0.1328125, -0.83203125, -0.90625, -0.61328125...   \n",
              "...                                                 ...   \n",
              "6325  [0.14453125, -0.84375, -0.8828125, -0.7109375,...   \n",
              "6326  [0.125, -0.9375, -0.9140625, -0.73046875, -1.7...   \n",
              "6327  [0.11328125, -0.9140625, -0.83203125, -0.60156...   \n",
              "6328  [0.15234375, -0.95703125, -0.89453125, -0.7734...   \n",
              "6329  [0.15625, -0.9140625, -0.859375, -0.7265625, -...   \n",
              "\n",
              "                                       decoder_layer_22  \\\n",
              "0     [-0.20703125, -0.41796875, -0.4609375, -0.6992...   \n",
              "1     [-0.20214844, -0.56640625, -0.51953125, -0.699...   \n",
              "2     [-0.25390625, -0.5234375, -0.515625, -0.839843...   \n",
              "3     [-0.234375, -0.5078125, -0.59375, -0.8203125, ...   \n",
              "4     [-0.28320312, -0.5234375, -0.5703125, -0.66796...   \n",
              "...                                                 ...   \n",
              "6325  [-0.3125, -0.5625, -0.5703125, -0.765625, -1.9...   \n",
              "6326  [-0.27929688, -0.671875, -0.5859375, -0.804687...   \n",
              "6327  [-0.2578125, -0.6484375, -0.5625, -0.60546875,...   \n",
              "6328  [-0.26367188, -0.69140625, -0.55078125, -0.835...   \n",
              "6329  [-0.23828125, -0.6171875, -0.578125, -0.78125,...   \n",
              "\n",
              "                                       decoder_layer_23  \\\n",
              "0     [-2.34375, 0.029296875, 1.0859375, -1.7109375,...   \n",
              "1     [-2.5, 0.025390625, 0.81640625, -1.6875, 0.25,...   \n",
              "2     [-2.40625, 0.24804688, 0.921875, -1.984375, 0....   \n",
              "3     [-2.625, 0.2265625, 0.8671875, -1.7421875, 0.2...   \n",
              "4     [-2.59375, 0.09765625, 1.03125, -1.484375, 0.3...   \n",
              "...                                                 ...   \n",
              "6325  [-2.5625, 0.06640625, 0.8671875, -1.734375, 0....   \n",
              "6326  [-2.609375, -0.015625, 0.9921875, -1.65625, 0....   \n",
              "6327  [-2.5, -0.001953125, 1.015625, -1.5390625, 0.1...   \n",
              "6328  [-2.625, 0.01953125, 0.95703125, -1.7421875, 0...   \n",
              "6329  [-2.546875, 0.0625, 0.953125, -1.5546875, 0.32...   \n",
              "\n",
              "                                       decoder_layer_24  \\\n",
              "0     [-2.921875, 1.21875, 1.4609375, -5.15625, 1.21...   \n",
              "1     [-2.890625, 1.0859375, 1.203125, -5.1875, 1.23...   \n",
              "2     [-2.796875, 1.4140625, 1.234375, -5.625, 1.554...   \n",
              "3     [-3.140625, 1.359375, 1.234375, -5.25, 1.14843...   \n",
              "4     [-3.125, 1.2890625, 1.3125, -5.0625, 1.375, -0...   \n",
              "...                                                 ...   \n",
              "6325  [-3.109375, 1.359375, 1.046875, -5.4375, 1.109...   \n",
              "6326  [-3.015625, 1.1484375, 1.03125, -5.28125, 1.15...   \n",
              "6327  [-3.125, 1.2890625, 1.171875, -5.0625, 1.01562...   \n",
              "6328  [-3.125, 1.109375, 0.953125, -5.34375, 1.21875...   \n",
              "6329  [-3.0625, 1.3046875, 0.99609375, -5.03125, 1.1...   \n",
              "\n",
              "                                       decoder_layer_25  \\\n",
              "0     [-2.3125, 1.46875, 1.4609375, -5.9375, 1.07031...   \n",
              "1     [-2.484375, 1.4921875, 1.375, -5.65625, 1.3203...   \n",
              "2     [-2.40625, 1.6484375, 1.46875, -6.25, 1.46875,...   \n",
              "3     [-2.65625, 1.765625, 1.234375, -5.84375, 1.101...   \n",
              "4     [-2.4375, 1.5703125, 1.484375, -5.84375, 1.359...   \n",
              "...                                                 ...   \n",
              "6325  [-2.5625, 1.6171875, 1.15625, -6.0625, 1.14062...   \n",
              "6326  [-2.546875, 1.390625, 1.140625, -6.03125, 1.28...   \n",
              "6327  [-2.609375, 1.484375, 1.421875, -5.78125, 1.14...   \n",
              "6328  [-2.796875, 1.296875, 0.8515625, -6.0, 1.38281...   \n",
              "6329  [-2.53125, 1.5390625, 1.0, -5.6875, 1.25, 1.13...   \n",
              "\n",
              "                                       decoder_layer_26  \\\n",
              "0     [3.859375, 1.78125, 2.9375, -5.53125, 1.960937...   \n",
              "1     [4.78125, 1.6875, 1.5, -5.84375, 1.5546875, -0...   \n",
              "2     [2.625, 2.625, 1.78125, -6.21875, 1.890625, -0...   \n",
              "3     [2.125, 3.453125, 1.90625, -4.84375, 2.65625, ...   \n",
              "4     [4.25, 3.21875, 2.96875, -4.78125, 2.3125, 1.0...   \n",
              "...                                                 ...   \n",
              "6325  [2.421875, 3.1875, 1.765625, -4.25, 2.015625, ...   \n",
              "6326  [3.234375, 2.375, 2.6875, -4.5, 2.859375, 2.43...   \n",
              "6327  [2.9375, 2.828125, 3.28125, -4.6875, 1.6875, 0...   \n",
              "6328  [3.96875, 3.28125, 1.90625, -5.84375, 2.78125,...   \n",
              "6329  [2.828125, 2.5625, 2.5625, -3.484375, 3.03125,...   \n",
              "\n",
              "                                       decoder_layer_27  \n",
              "0     [1.84375, -0.55859375, 0.73046875, -0.71484375...  \n",
              "1     [2.5625, -0.45898438, 0.14550781, -1.015625, 1...  \n",
              "2     [2.296875, 0.86328125, 1.1875, -0.85546875, 2....  \n",
              "3     [-0.26367188, 0.48242188, 0.81640625, -1.32031...  \n",
              "4     [1.6015625, 0.21484375, 2.0, -0.6640625, 2.437...  \n",
              "...                                                 ...  \n",
              "6325  [0.53515625, 0.375, 0.6015625, -0.84375, 1.648...  \n",
              "6326  [0.66015625, -0.6796875, 1.6171875, -0.2578125...  \n",
              "6327  [0.88671875, -0.41796875, 1.734375, -0.9414062...  \n",
              "6328  [0.8671875, -0.25585938, 0.51171875, -0.40625,...  \n",
              "6329  [0.671875, -0.20410156, 0.75, 0.23828125, 1.51...  \n",
              "\n",
              "[6330 rows x 57 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "activation_tf_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9XwUt5DhKLs"
      },
      "source": [
        "## CoLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_CCk8YEhK_v",
        "outputId": "3a6fcfad-965f-4244-e2a3-08270519aa99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-22 17:44:18--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
            "Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255330 (249K) [application/x-zip-compressed]\n",
            "Saving to: ‘cola_public_1.1.zip’\n",
            "\n",
            "cola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-11-22 17:44:18 (13.9 MB/s) - ‘cola_public_1.1.zip’ saved [255330/255330]\n",
            "\n",
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
        "!unzip cola_public_1.1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BoH9HrtvhfKo",
        "outputId": "a550b708-b3fc-4b54-bcd9-b1ff73bbdff4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"cola_df\",\n  \"rows\": 9594,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"in_domain_dev\",\n          \"out_of_domain_dev\",\n          \"in_domain_train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9553,\n        \"samples\": [\n          \"He figured out that.\",\n          \"The captain sank the boat.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "cola_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-733a7d61-fb59-4630-9e99-78aa2585e34c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The sailors rode the breeze clear of the rocks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The weights made the rope stretch over the pul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The mechanical doll wriggled itself loose.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If you had eaten more, you would want less.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>0</td>\n",
              "      <td>As you eat the most, you want the least.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-733a7d61-fb59-4630-9e99-78aa2585e34c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-733a7d61-fb59-4630-9e99-78aa2585e34c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-733a7d61-fb59-4630-9e99-78aa2585e34c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-91a114d3-885a-4cfb-aa3b-557e749860e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91a114d3-885a-4cfb-aa3b-557e749860e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-91a114d3-885a-4cfb-aa3b-557e749860e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_97765dad-c196-4d7e-8a99-01d0cac5d96c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cola_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_97765dad-c196-4d7e-8a99-01d0cac5d96c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cola_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               source  label  \\\n",
              "0       in_domain_dev      1   \n",
              "1       in_domain_dev      1   \n",
              "2       in_domain_dev      1   \n",
              "3       in_domain_dev      1   \n",
              "4       in_domain_dev      0   \n",
              "...               ...    ...   \n",
              "9589  in_domain_train      0   \n",
              "9590  in_domain_train      0   \n",
              "9591  in_domain_train      1   \n",
              "9592  in_domain_train      1   \n",
              "9593  in_domain_train      1   \n",
              "\n",
              "                                               sentence  \n",
              "0       The sailors rode the breeze clear of the rocks.  \n",
              "1     The weights made the rope stretch over the pul...  \n",
              "2            The mechanical doll wriggled itself loose.  \n",
              "3           If you had eaten more, you would want less.  \n",
              "4              As you eat the most, you want the least.  \n",
              "...                                                 ...  \n",
              "9589                   Poseidon appears to own a dragon  \n",
              "9590                     Digitize is my happiest memory  \n",
              "9591                     It is easy to slay the Gorgon.  \n",
              "9592       I had the strangest feeling that I knew you.  \n",
              "9593                What all did you get for Christmas?  \n",
              "\n",
              "[9594 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = '/content/cola_public/raw/'\n",
        "cola_files = os.listdir(path) # contiene ['out_of_domain_dev.tsv', 'in_domain_train.tsv', 'in_domain_dev.tsv']\n",
        "dfs = []\n",
        "\n",
        "for cf in cola_files:\n",
        "  df = pd.read_csv(f'{path}{cf}', delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "  df.drop(columns=['sentence_source', 'label_notes'], inplace=True)\n",
        "  df.insert(loc=0, column='source', value=cf.split('.')[0], allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "cola_df = pd.concat(dfs, ignore_index=True)\n",
        "cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cqOl6kTmFzR"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "i-NK-2DehmTG",
        "outputId": "ce06eb6e-54b2-4038-dd55-dcb589a1c437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing 9594 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:42<00:00,  3.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_cola_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4bda6562-b24a-4516-be66-ed244231a99d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The sailors rode the breeze clear of the rocks.</td>\n",
              "      <td>[2.278125, -0.20976563, -0.38027343, 0.4071289...</td>\n",
              "      <td>[0.09804688, 0.02421875, -0.35742188, -0.31718...</td>\n",
              "      <td>[0.03046875, 0.5109375, 0.40625, -0.49726564, ...</td>\n",
              "      <td>[-0.2484375, -0.31621093, -0.008203125, -0.635...</td>\n",
              "      <td>[-0.1421875, -0.0053710938, -0.2444336, -0.475...</td>\n",
              "      <td>[0.17460938, -0.7871094, -0.0076171877, -0.515...</td>\n",
              "      <td>[0.043164063, -0.6929687, 0.51225585, -0.64609...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.3984375, 0.296875, 0.49609375, ...</td>\n",
              "      <td>[-0.95703125, 0.5078125, -0.04663086, 0.773437...</td>\n",
              "      <td>[-1.2890625, 0.0087890625, 0.17578125, 0.56640...</td>\n",
              "      <td>[-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...</td>\n",
              "      <td>[-0.00390625, 0.072265625, 0.03125, 0.828125, ...</td>\n",
              "      <td>[-0.13476562, -0.12402344, -0.43945312, 1.0468...</td>\n",
              "      <td>[-0.47265625, -0.27148438, -1.0, 0.47265625, -...</td>\n",
              "      <td>[-1.359375, -0.15625, -1.203125, 0.33789062, -...</td>\n",
              "      <td>[-1.53125, 0.56640625, -0.5234375, 0.09667969,...</td>\n",
              "      <td>[-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The weights made the rope stretch over the pul...</td>\n",
              "      <td>[2.278125, -0.20976563, -0.38027343, 0.4071289...</td>\n",
              "      <td>[0.09804688, 0.02421875, -0.35742188, -0.31718...</td>\n",
              "      <td>[0.03046875, 0.5109375, 0.40625, -0.49726564, ...</td>\n",
              "      <td>[-0.2484375, -0.31621093, -0.008203125, -0.635...</td>\n",
              "      <td>[-0.1421875, -0.0053710938, -0.2444336, -0.475...</td>\n",
              "      <td>[0.17460938, -0.7871094, -0.0076171877, -0.515...</td>\n",
              "      <td>[0.043164063, -0.6929687, 0.51225585, -0.64609...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.3984375, 0.296875, 0.49609375, ...</td>\n",
              "      <td>[-0.95703125, 0.5078125, -0.04663086, 0.773437...</td>\n",
              "      <td>[-1.2890625, 0.0087890625, 0.17578125, 0.56640...</td>\n",
              "      <td>[-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...</td>\n",
              "      <td>[-0.00390625, 0.072265625, 0.03125, 0.828125, ...</td>\n",
              "      <td>[-0.13476562, -0.12402344, -0.43945312, 1.0468...</td>\n",
              "      <td>[-0.47265625, -0.27148438, -1.0, 0.47265625, -...</td>\n",
              "      <td>[-1.359375, -0.15625, -1.203125, 0.33789062, -...</td>\n",
              "      <td>[-1.53125, 0.56640625, -0.5234375, 0.09667969,...</td>\n",
              "      <td>[-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The mechanical doll wriggled itself loose.</td>\n",
              "      <td>[2.278125, -0.20976563, -0.38027343, 0.4071289...</td>\n",
              "      <td>[0.09804688, 0.02421875, -0.35742188, -0.31718...</td>\n",
              "      <td>[0.03046875, 0.5109375, 0.40625, -0.49726564, ...</td>\n",
              "      <td>[-0.2484375, -0.31621093, -0.008203125, -0.635...</td>\n",
              "      <td>[-0.1421875, -0.0053710938, -0.2444336, -0.475...</td>\n",
              "      <td>[0.17460938, -0.7871094, -0.0076171877, -0.515...</td>\n",
              "      <td>[0.043164063, -0.6929687, 0.51225585, -0.64609...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.3984375, 0.296875, 0.49609375, ...</td>\n",
              "      <td>[-0.95703125, 0.5078125, -0.04663086, 0.773437...</td>\n",
              "      <td>[-1.2890625, 0.0087890625, 0.17578125, 0.56640...</td>\n",
              "      <td>[-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...</td>\n",
              "      <td>[-0.00390625, 0.072265625, 0.03125, 0.828125, ...</td>\n",
              "      <td>[-0.13476562, -0.12402344, -0.43945312, 1.0468...</td>\n",
              "      <td>[-0.47265625, -0.27148438, -1.0, 0.47265625, -...</td>\n",
              "      <td>[-1.359375, -0.15625, -1.203125, 0.33789062, -...</td>\n",
              "      <td>[-1.53125, 0.56640625, -0.5234375, 0.09667969,...</td>\n",
              "      <td>[-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If you had eaten more, you would want less.</td>\n",
              "      <td>[2.278125, -0.20976563, -0.38027343, 0.4071289...</td>\n",
              "      <td>[0.09804688, 0.02421875, -0.35742188, -0.31718...</td>\n",
              "      <td>[0.03046875, 0.5109375, 0.40625, -0.49726564, ...</td>\n",
              "      <td>[-0.2484375, -0.31621093, -0.008203125, -0.635...</td>\n",
              "      <td>[-0.1421875, -0.0053710938, -0.2444336, -0.475...</td>\n",
              "      <td>[0.17460938, -0.7871094, -0.0076171877, -0.515...</td>\n",
              "      <td>[0.043164063, -0.6929687, 0.51225585, -0.64609...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.3984375, 0.296875, 0.49609375, ...</td>\n",
              "      <td>[-0.95703125, 0.5078125, -0.04663086, 0.773437...</td>\n",
              "      <td>[-1.2890625, 0.0087890625, 0.17578125, 0.56640...</td>\n",
              "      <td>[-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...</td>\n",
              "      <td>[-0.00390625, 0.072265625, 0.03125, 0.828125, ...</td>\n",
              "      <td>[-0.13476562, -0.12402344, -0.43945312, 1.0468...</td>\n",
              "      <td>[-0.47265625, -0.27148438, -1.0, 0.47265625, -...</td>\n",
              "      <td>[-1.359375, -0.15625, -1.203125, 0.33789062, -...</td>\n",
              "      <td>[-1.53125, 0.56640625, -0.5234375, 0.09667969,...</td>\n",
              "      <td>[-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>0</td>\n",
              "      <td>As you eat the most, you want the least.</td>\n",
              "      <td>[2.278125, -0.20976563, -0.38027343, 0.4071289...</td>\n",
              "      <td>[0.09804688, 0.02421875, -0.35742188, -0.31718...</td>\n",
              "      <td>[0.03046875, 0.5109375, 0.40625, -0.49726564, ...</td>\n",
              "      <td>[-0.2484375, -0.31621093, -0.008203125, -0.635...</td>\n",
              "      <td>[-0.1421875, -0.0053710938, -0.2444336, -0.475...</td>\n",
              "      <td>[0.17460938, -0.7871094, -0.0076171877, -0.515...</td>\n",
              "      <td>[0.043164063, -0.6929687, 0.51225585, -0.64609...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4921875, 0.3984375, 0.296875, 0.49609375, ...</td>\n",
              "      <td>[-0.95703125, 0.5078125, -0.04663086, 0.773437...</td>\n",
              "      <td>[-1.2890625, 0.0087890625, 0.17578125, 0.56640...</td>\n",
              "      <td>[-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...</td>\n",
              "      <td>[-0.00390625, 0.072265625, 0.03125, 0.828125, ...</td>\n",
              "      <td>[-0.13476562, -0.12402344, -0.43945312, 1.0468...</td>\n",
              "      <td>[-0.47265625, -0.27148438, -1.0, 0.47265625, -...</td>\n",
              "      <td>[-1.359375, -0.15625, -1.203125, 0.33789062, -...</td>\n",
              "      <td>[-1.53125, 0.56640625, -0.5234375, 0.09667969,...</td>\n",
              "      <td>[-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "      <td>[2.30625, -0.10625, -0.0109375, 0.54179686, 0....</td>\n",
              "      <td>[0.14335938, -0.01953125, -0.23359375, -0.0933...</td>\n",
              "      <td>[0.28828126, 0.33359376, 0.46914062, -0.246093...</td>\n",
              "      <td>[-0.16015625, -0.47460938, 0.33398438, -0.1605...</td>\n",
              "      <td>[-0.14414063, -0.23603515, 0.025341798, 0.0015...</td>\n",
              "      <td>[0.2859375, -0.63789064, 0.16025391, 0.0443237...</td>\n",
              "      <td>[0.14296874, -0.7, 0.39082032, -0.10507812, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.3203125, 0.35546875, 0.26171875, 0.3339843...</td>\n",
              "      <td>[-0.79296875, 0.42578125, -0.0625, 0.59375, -1...</td>\n",
              "      <td>[-1.0859375, -0.16601562, 0.15722656, 0.396484...</td>\n",
              "      <td>[-1.125, 0.3828125, -0.13378906, 0.6328125, -1...</td>\n",
              "      <td>[0.061523438, -0.12695312, 0.060546875, 0.7851...</td>\n",
              "      <td>[0.0043945312, -0.24023438, -0.43554688, 0.988...</td>\n",
              "      <td>[-0.45507812, -0.53515625, -0.81640625, 0.4648...</td>\n",
              "      <td>[-1.46875, -0.48046875, -1.0390625, 0.26953125...</td>\n",
              "      <td>[-2.0625, 0.35546875, -0.5234375, 0.19921875, ...</td>\n",
              "      <td>[-15.375, 0.26953125, -3.09375, 0.7890625, -3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "      <td>[2.30625, -0.10625, -0.0109375, 0.54179686, 0....</td>\n",
              "      <td>[0.14335938, -0.01953125, -0.23359375, -0.0933...</td>\n",
              "      <td>[0.28828126, 0.33359376, 0.46914062, -0.246093...</td>\n",
              "      <td>[-0.16015625, -0.47460938, 0.33398438, -0.1605...</td>\n",
              "      <td>[-0.14414063, -0.23603515, 0.025341798, 0.0015...</td>\n",
              "      <td>[0.2859375, -0.63789064, 0.16025391, 0.0443237...</td>\n",
              "      <td>[0.14296874, -0.7, 0.39082032, -0.10507812, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.3203125, 0.35546875, 0.26171875, 0.3339843...</td>\n",
              "      <td>[-0.79296875, 0.42578125, -0.0625, 0.59375, -1...</td>\n",
              "      <td>[-1.0859375, -0.16601562, 0.15722656, 0.396484...</td>\n",
              "      <td>[-1.125, 0.3828125, -0.13378906, 0.6328125, -1...</td>\n",
              "      <td>[0.061523438, -0.12695312, 0.060546875, 0.7851...</td>\n",
              "      <td>[0.0043945312, -0.24023438, -0.43554688, 0.988...</td>\n",
              "      <td>[-0.45507812, -0.53515625, -0.81640625, 0.4648...</td>\n",
              "      <td>[-1.46875, -0.48046875, -1.0390625, 0.26953125...</td>\n",
              "      <td>[-2.0625, 0.35546875, -0.5234375, 0.19921875, ...</td>\n",
              "      <td>[-15.375, 0.26953125, -3.09375, 0.7890625, -3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "      <td>[2.30625, -0.10625, -0.0109375, 0.54179686, 0....</td>\n",
              "      <td>[0.14335938, -0.01953125, -0.23359375, -0.0933...</td>\n",
              "      <td>[0.28828126, 0.33359376, 0.46914062, -0.246093...</td>\n",
              "      <td>[-0.16015625, -0.47460938, 0.33398438, -0.1605...</td>\n",
              "      <td>[-0.14414063, -0.23603515, 0.025341798, 0.0015...</td>\n",
              "      <td>[0.2859375, -0.63789064, 0.16025391, 0.0443237...</td>\n",
              "      <td>[0.14296874, -0.7, 0.39082032, -0.10507812, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.3203125, 0.35546875, 0.26171875, 0.3339843...</td>\n",
              "      <td>[-0.79296875, 0.42578125, -0.0625, 0.59375, -1...</td>\n",
              "      <td>[-1.0859375, -0.16601562, 0.15722656, 0.396484...</td>\n",
              "      <td>[-1.125, 0.3828125, -0.13378906, 0.6328125, -1...</td>\n",
              "      <td>[0.061523438, -0.12695312, 0.060546875, 0.7851...</td>\n",
              "      <td>[0.0043945312, -0.24023438, -0.43554688, 0.988...</td>\n",
              "      <td>[-0.45507812, -0.53515625, -0.81640625, 0.4648...</td>\n",
              "      <td>[-1.46875, -0.48046875, -1.0390625, 0.26953125...</td>\n",
              "      <td>[-2.0625, 0.35546875, -0.5234375, 0.19921875, ...</td>\n",
              "      <td>[-15.375, 0.26953125, -3.09375, 0.7890625, -3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "      <td>[2.30625, -0.10625, -0.0109375, 0.54179686, 0....</td>\n",
              "      <td>[0.14335938, -0.01953125, -0.23359375, -0.0933...</td>\n",
              "      <td>[0.28828126, 0.33359376, 0.46914062, -0.246093...</td>\n",
              "      <td>[-0.16015625, -0.47460938, 0.33398438, -0.1605...</td>\n",
              "      <td>[-0.14414063, -0.23603515, 0.025341798, 0.0015...</td>\n",
              "      <td>[0.2859375, -0.63789064, 0.16025391, 0.0443237...</td>\n",
              "      <td>[0.14296874, -0.7, 0.39082032, -0.10507812, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.3203125, 0.35546875, 0.26171875, 0.3339843...</td>\n",
              "      <td>[-0.79296875, 0.42578125, -0.0625, 0.59375, -1...</td>\n",
              "      <td>[-1.0859375, -0.16601562, 0.15722656, 0.396484...</td>\n",
              "      <td>[-1.125, 0.3828125, -0.13378906, 0.6328125, -1...</td>\n",
              "      <td>[0.061523438, -0.12695312, 0.060546875, 0.7851...</td>\n",
              "      <td>[0.0043945312, -0.24023438, -0.43554688, 0.988...</td>\n",
              "      <td>[-0.45507812, -0.53515625, -0.81640625, 0.4648...</td>\n",
              "      <td>[-1.46875, -0.48046875, -1.0390625, 0.26953125...</td>\n",
              "      <td>[-2.0625, 0.35546875, -0.5234375, 0.19921875, ...</td>\n",
              "      <td>[-15.375, 0.26953125, -3.09375, 0.7890625, -3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "      <td>[2.30625, -0.10625, -0.0109375, 0.54179686, 0....</td>\n",
              "      <td>[0.14335938, -0.01953125, -0.23359375, -0.0933...</td>\n",
              "      <td>[0.28828126, 0.33359376, 0.46914062, -0.246093...</td>\n",
              "      <td>[-0.16015625, -0.47460938, 0.33398438, -0.1605...</td>\n",
              "      <td>[-0.14414063, -0.23603515, 0.025341798, 0.0015...</td>\n",
              "      <td>[0.2859375, -0.63789064, 0.16025391, 0.0443237...</td>\n",
              "      <td>[0.14296874, -0.7, 0.39082032, -0.10507812, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.3203125, 0.35546875, 0.26171875, 0.3339843...</td>\n",
              "      <td>[-0.79296875, 0.42578125, -0.0625, 0.59375, -1...</td>\n",
              "      <td>[-1.0859375, -0.16601562, 0.15722656, 0.396484...</td>\n",
              "      <td>[-1.125, 0.3828125, -0.13378906, 0.6328125, -1...</td>\n",
              "      <td>[0.061523438, -0.12695312, 0.060546875, 0.7851...</td>\n",
              "      <td>[0.0043945312, -0.24023438, -0.43554688, 0.988...</td>\n",
              "      <td>[-0.45507812, -0.53515625, -0.81640625, 0.4648...</td>\n",
              "      <td>[-1.46875, -0.48046875, -1.0390625, 0.26953125...</td>\n",
              "      <td>[-2.0625, 0.35546875, -0.5234375, 0.19921875, ...</td>\n",
              "      <td>[-15.375, 0.26953125, -3.09375, 0.7890625, -3....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bda6562-b24a-4516-be66-ed244231a99d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bda6562-b24a-4516-be66-ed244231a99d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bda6562-b24a-4516-be66-ed244231a99d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e9f9a6c9-6678-4895-876a-d34f0b76f57d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9f9a6c9-6678-4895-876a-d34f0b76f57d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e9f9a6c9-6678-4895-876a-d34f0b76f57d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_daca1c8f-d918-40bf-9de1-17a6ad8a79c6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('activation_cola_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_daca1c8f-d918-40bf-9de1-17a6ad8a79c6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('activation_cola_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               source  label  \\\n",
              "0       in_domain_dev      1   \n",
              "1       in_domain_dev      1   \n",
              "2       in_domain_dev      1   \n",
              "3       in_domain_dev      1   \n",
              "4       in_domain_dev      0   \n",
              "...               ...    ...   \n",
              "9589  in_domain_train      0   \n",
              "9590  in_domain_train      0   \n",
              "9591  in_domain_train      1   \n",
              "9592  in_domain_train      1   \n",
              "9593  in_domain_train      1   \n",
              "\n",
              "                                               sentence  \\\n",
              "0       The sailors rode the breeze clear of the rocks.   \n",
              "1     The weights made the rope stretch over the pul...   \n",
              "2            The mechanical doll wriggled itself loose.   \n",
              "3           If you had eaten more, you would want less.   \n",
              "4              As you eat the most, you want the least.   \n",
              "...                                                 ...   \n",
              "9589                   Poseidon appears to own a dragon   \n",
              "9590                     Digitize is my happiest memory   \n",
              "9591                     It is easy to slay the Gorgon.   \n",
              "9592       I had the strangest feeling that I knew you.   \n",
              "9593                What all did you get for Christmas?   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [2.278125, -0.20976563, -0.38027343, 0.4071289...   \n",
              "1     [2.278125, -0.20976563, -0.38027343, 0.4071289...   \n",
              "2     [2.278125, -0.20976563, -0.38027343, 0.4071289...   \n",
              "3     [2.278125, -0.20976563, -0.38027343, 0.4071289...   \n",
              "4     [2.278125, -0.20976563, -0.38027343, 0.4071289...   \n",
              "...                                                 ...   \n",
              "9589  [2.30625, -0.10625, -0.0109375, 0.54179686, 0....   \n",
              "9590  [2.30625, -0.10625, -0.0109375, 0.54179686, 0....   \n",
              "9591  [2.30625, -0.10625, -0.0109375, 0.54179686, 0....   \n",
              "9592  [2.30625, -0.10625, -0.0109375, 0.54179686, 0....   \n",
              "9593  [2.30625, -0.10625, -0.0109375, 0.54179686, 0....   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [0.09804688, 0.02421875, -0.35742188, -0.31718...   \n",
              "1     [0.09804688, 0.02421875, -0.35742188, -0.31718...   \n",
              "2     [0.09804688, 0.02421875, -0.35742188, -0.31718...   \n",
              "3     [0.09804688, 0.02421875, -0.35742188, -0.31718...   \n",
              "4     [0.09804688, 0.02421875, -0.35742188, -0.31718...   \n",
              "...                                                 ...   \n",
              "9589  [0.14335938, -0.01953125, -0.23359375, -0.0933...   \n",
              "9590  [0.14335938, -0.01953125, -0.23359375, -0.0933...   \n",
              "9591  [0.14335938, -0.01953125, -0.23359375, -0.0933...   \n",
              "9592  [0.14335938, -0.01953125, -0.23359375, -0.0933...   \n",
              "9593  [0.14335938, -0.01953125, -0.23359375, -0.0933...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [0.03046875, 0.5109375, 0.40625, -0.49726564, ...   \n",
              "1     [0.03046875, 0.5109375, 0.40625, -0.49726564, ...   \n",
              "2     [0.03046875, 0.5109375, 0.40625, -0.49726564, ...   \n",
              "3     [0.03046875, 0.5109375, 0.40625, -0.49726564, ...   \n",
              "4     [0.03046875, 0.5109375, 0.40625, -0.49726564, ...   \n",
              "...                                                 ...   \n",
              "9589  [0.28828126, 0.33359376, 0.46914062, -0.246093...   \n",
              "9590  [0.28828126, 0.33359376, 0.46914062, -0.246093...   \n",
              "9591  [0.28828126, 0.33359376, 0.46914062, -0.246093...   \n",
              "9592  [0.28828126, 0.33359376, 0.46914062, -0.246093...   \n",
              "9593  [0.28828126, 0.33359376, 0.46914062, -0.246093...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.2484375, -0.31621093, -0.008203125, -0.635...   \n",
              "1     [-0.2484375, -0.31621093, -0.008203125, -0.635...   \n",
              "2     [-0.2484375, -0.31621093, -0.008203125, -0.635...   \n",
              "3     [-0.2484375, -0.31621093, -0.008203125, -0.635...   \n",
              "4     [-0.2484375, -0.31621093, -0.008203125, -0.635...   \n",
              "...                                                 ...   \n",
              "9589  [-0.16015625, -0.47460938, 0.33398438, -0.1605...   \n",
              "9590  [-0.16015625, -0.47460938, 0.33398438, -0.1605...   \n",
              "9591  [-0.16015625, -0.47460938, 0.33398438, -0.1605...   \n",
              "9592  [-0.16015625, -0.47460938, 0.33398438, -0.1605...   \n",
              "9593  [-0.16015625, -0.47460938, 0.33398438, -0.1605...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.1421875, -0.0053710938, -0.2444336, -0.475...   \n",
              "1     [-0.1421875, -0.0053710938, -0.2444336, -0.475...   \n",
              "2     [-0.1421875, -0.0053710938, -0.2444336, -0.475...   \n",
              "3     [-0.1421875, -0.0053710938, -0.2444336, -0.475...   \n",
              "4     [-0.1421875, -0.0053710938, -0.2444336, -0.475...   \n",
              "...                                                 ...   \n",
              "9589  [-0.14414063, -0.23603515, 0.025341798, 0.0015...   \n",
              "9590  [-0.14414063, -0.23603515, 0.025341798, 0.0015...   \n",
              "9591  [-0.14414063, -0.23603515, 0.025341798, 0.0015...   \n",
              "9592  [-0.14414063, -0.23603515, 0.025341798, 0.0015...   \n",
              "9593  [-0.14414063, -0.23603515, 0.025341798, 0.0015...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [0.17460938, -0.7871094, -0.0076171877, -0.515...   \n",
              "1     [0.17460938, -0.7871094, -0.0076171877, -0.515...   \n",
              "2     [0.17460938, -0.7871094, -0.0076171877, -0.515...   \n",
              "3     [0.17460938, -0.7871094, -0.0076171877, -0.515...   \n",
              "4     [0.17460938, -0.7871094, -0.0076171877, -0.515...   \n",
              "...                                                 ...   \n",
              "9589  [0.2859375, -0.63789064, 0.16025391, 0.0443237...   \n",
              "9590  [0.2859375, -0.63789064, 0.16025391, 0.0443237...   \n",
              "9591  [0.2859375, -0.63789064, 0.16025391, 0.0443237...   \n",
              "9592  [0.2859375, -0.63789064, 0.16025391, 0.0443237...   \n",
              "9593  [0.2859375, -0.63789064, 0.16025391, 0.0443237...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.043164063, -0.6929687, 0.51225585, -0.64609...  ...   \n",
              "1     [0.043164063, -0.6929687, 0.51225585, -0.64609...  ...   \n",
              "2     [0.043164063, -0.6929687, 0.51225585, -0.64609...  ...   \n",
              "3     [0.043164063, -0.6929687, 0.51225585, -0.64609...  ...   \n",
              "4     [0.043164063, -0.6929687, 0.51225585, -0.64609...  ...   \n",
              "...                                                 ...  ...   \n",
              "9589  [0.14296874, -0.7, 0.39082032, -0.10507812, -0...  ...   \n",
              "9590  [0.14296874, -0.7, 0.39082032, -0.10507812, -0...  ...   \n",
              "9591  [0.14296874, -0.7, 0.39082032, -0.10507812, -0...  ...   \n",
              "9592  [0.14296874, -0.7, 0.39082032, -0.10507812, -0...  ...   \n",
              "9593  [0.14296874, -0.7, 0.39082032, -0.10507812, -0...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.4921875, 0.3984375, 0.296875, 0.49609375, ...   \n",
              "1     [-0.4921875, 0.3984375, 0.296875, 0.49609375, ...   \n",
              "2     [-0.4921875, 0.3984375, 0.296875, 0.49609375, ...   \n",
              "3     [-0.4921875, 0.3984375, 0.296875, 0.49609375, ...   \n",
              "4     [-0.4921875, 0.3984375, 0.296875, 0.49609375, ...   \n",
              "...                                                 ...   \n",
              "9589  [-0.3203125, 0.35546875, 0.26171875, 0.3339843...   \n",
              "9590  [-0.3203125, 0.35546875, 0.26171875, 0.3339843...   \n",
              "9591  [-0.3203125, 0.35546875, 0.26171875, 0.3339843...   \n",
              "9592  [-0.3203125, 0.35546875, 0.26171875, 0.3339843...   \n",
              "9593  [-0.3203125, 0.35546875, 0.26171875, 0.3339843...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.95703125, 0.5078125, -0.04663086, 0.773437...   \n",
              "1     [-0.95703125, 0.5078125, -0.04663086, 0.773437...   \n",
              "2     [-0.95703125, 0.5078125, -0.04663086, 0.773437...   \n",
              "3     [-0.95703125, 0.5078125, -0.04663086, 0.773437...   \n",
              "4     [-0.95703125, 0.5078125, -0.04663086, 0.773437...   \n",
              "...                                                 ...   \n",
              "9589  [-0.79296875, 0.42578125, -0.0625, 0.59375, -1...   \n",
              "9590  [-0.79296875, 0.42578125, -0.0625, 0.59375, -1...   \n",
              "9591  [-0.79296875, 0.42578125, -0.0625, 0.59375, -1...   \n",
              "9592  [-0.79296875, 0.42578125, -0.0625, 0.59375, -1...   \n",
              "9593  [-0.79296875, 0.42578125, -0.0625, 0.59375, -1...   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.2890625, 0.0087890625, 0.17578125, 0.56640...   \n",
              "1     [-1.2890625, 0.0087890625, 0.17578125, 0.56640...   \n",
              "2     [-1.2890625, 0.0087890625, 0.17578125, 0.56640...   \n",
              "3     [-1.2890625, 0.0087890625, 0.17578125, 0.56640...   \n",
              "4     [-1.2890625, 0.0087890625, 0.17578125, 0.56640...   \n",
              "...                                                 ...   \n",
              "9589  [-1.0859375, -0.16601562, 0.15722656, 0.396484...   \n",
              "9590  [-1.0859375, -0.16601562, 0.15722656, 0.396484...   \n",
              "9591  [-1.0859375, -0.16601562, 0.15722656, 0.396484...   \n",
              "9592  [-1.0859375, -0.16601562, 0.15722656, 0.396484...   \n",
              "9593  [-1.0859375, -0.16601562, 0.15722656, 0.396484...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...   \n",
              "1     [-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...   \n",
              "2     [-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...   \n",
              "3     [-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...   \n",
              "4     [-1.25, 0.53125, -0.15820312, 0.76171875, -1.5...   \n",
              "...                                                 ...   \n",
              "9589  [-1.125, 0.3828125, -0.13378906, 0.6328125, -1...   \n",
              "9590  [-1.125, 0.3828125, -0.13378906, 0.6328125, -1...   \n",
              "9591  [-1.125, 0.3828125, -0.13378906, 0.6328125, -1...   \n",
              "9592  [-1.125, 0.3828125, -0.13378906, 0.6328125, -1...   \n",
              "9593  [-1.125, 0.3828125, -0.13378906, 0.6328125, -1...   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [-0.00390625, 0.072265625, 0.03125, 0.828125, ...   \n",
              "1     [-0.00390625, 0.072265625, 0.03125, 0.828125, ...   \n",
              "2     [-0.00390625, 0.072265625, 0.03125, 0.828125, ...   \n",
              "3     [-0.00390625, 0.072265625, 0.03125, 0.828125, ...   \n",
              "4     [-0.00390625, 0.072265625, 0.03125, 0.828125, ...   \n",
              "...                                                 ...   \n",
              "9589  [0.061523438, -0.12695312, 0.060546875, 0.7851...   \n",
              "9590  [0.061523438, -0.12695312, 0.060546875, 0.7851...   \n",
              "9591  [0.061523438, -0.12695312, 0.060546875, 0.7851...   \n",
              "9592  [0.061523438, -0.12695312, 0.060546875, 0.7851...   \n",
              "9593  [0.061523438, -0.12695312, 0.060546875, 0.7851...   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.13476562, -0.12402344, -0.43945312, 1.0468...   \n",
              "1     [-0.13476562, -0.12402344, -0.43945312, 1.0468...   \n",
              "2     [-0.13476562, -0.12402344, -0.43945312, 1.0468...   \n",
              "3     [-0.13476562, -0.12402344, -0.43945312, 1.0468...   \n",
              "4     [-0.13476562, -0.12402344, -0.43945312, 1.0468...   \n",
              "...                                                 ...   \n",
              "9589  [0.0043945312, -0.24023438, -0.43554688, 0.988...   \n",
              "9590  [0.0043945312, -0.24023438, -0.43554688, 0.988...   \n",
              "9591  [0.0043945312, -0.24023438, -0.43554688, 0.988...   \n",
              "9592  [0.0043945312, -0.24023438, -0.43554688, 0.988...   \n",
              "9593  [0.0043945312, -0.24023438, -0.43554688, 0.988...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.47265625, -0.27148438, -1.0, 0.47265625, -...   \n",
              "1     [-0.47265625, -0.27148438, -1.0, 0.47265625, -...   \n",
              "2     [-0.47265625, -0.27148438, -1.0, 0.47265625, -...   \n",
              "3     [-0.47265625, -0.27148438, -1.0, 0.47265625, -...   \n",
              "4     [-0.47265625, -0.27148438, -1.0, 0.47265625, -...   \n",
              "...                                                 ...   \n",
              "9589  [-0.45507812, -0.53515625, -0.81640625, 0.4648...   \n",
              "9590  [-0.45507812, -0.53515625, -0.81640625, 0.4648...   \n",
              "9591  [-0.45507812, -0.53515625, -0.81640625, 0.4648...   \n",
              "9592  [-0.45507812, -0.53515625, -0.81640625, 0.4648...   \n",
              "9593  [-0.45507812, -0.53515625, -0.81640625, 0.4648...   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.359375, -0.15625, -1.203125, 0.33789062, -...   \n",
              "1     [-1.359375, -0.15625, -1.203125, 0.33789062, -...   \n",
              "2     [-1.359375, -0.15625, -1.203125, 0.33789062, -...   \n",
              "3     [-1.359375, -0.15625, -1.203125, 0.33789062, -...   \n",
              "4     [-1.359375, -0.15625, -1.203125, 0.33789062, -...   \n",
              "...                                                 ...   \n",
              "9589  [-1.46875, -0.48046875, -1.0390625, 0.26953125...   \n",
              "9590  [-1.46875, -0.48046875, -1.0390625, 0.26953125...   \n",
              "9591  [-1.46875, -0.48046875, -1.0390625, 0.26953125...   \n",
              "9592  [-1.46875, -0.48046875, -1.0390625, 0.26953125...   \n",
              "9593  [-1.46875, -0.48046875, -1.0390625, 0.26953125...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.53125, 0.56640625, -0.5234375, 0.09667969,...   \n",
              "1     [-1.53125, 0.56640625, -0.5234375, 0.09667969,...   \n",
              "2     [-1.53125, 0.56640625, -0.5234375, 0.09667969,...   \n",
              "3     [-1.53125, 0.56640625, -0.5234375, 0.09667969,...   \n",
              "4     [-1.53125, 0.56640625, -0.5234375, 0.09667969,...   \n",
              "...                                                 ...   \n",
              "9589  [-2.0625, 0.35546875, -0.5234375, 0.19921875, ...   \n",
              "9590  [-2.0625, 0.35546875, -0.5234375, 0.19921875, ...   \n",
              "9591  [-2.0625, 0.35546875, -0.5234375, 0.19921875, ...   \n",
              "9592  [-2.0625, 0.35546875, -0.5234375, 0.19921875, ...   \n",
              "9593  [-2.0625, 0.35546875, -0.5234375, 0.19921875, ...   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...  \n",
              "1     [-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...  \n",
              "2     [-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...  \n",
              "3     [-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...  \n",
              "4     [-12.25, 0.47070312, 1.78125, 0.78515625, -1.7...  \n",
              "...                                                 ...  \n",
              "9589  [-15.375, 0.26953125, -3.09375, 0.7890625, -3....  \n",
              "9590  [-15.375, 0.26953125, -3.09375, 0.7890625, -3....  \n",
              "9591  [-15.375, 0.26953125, -3.09375, 0.7890625, -3....  \n",
              "9592  [-15.375, 0.26953125, -3.09375, 0.7890625, -3....  \n",
              "9593  [-15.375, 0.26953125, -3.09375, 0.7890625, -3....  \n",
              "\n",
              "[9594 rows x 29 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'source'\n",
        "\n",
        "activation_cola_df = extract_activations_df(cola_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df, 'cola', model_id_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmcKoW3NiPEm"
      },
      "outputs": [],
      "source": [
        "activation_cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCH6zRgvmpcx"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3PVCeFPRquJJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'source'\n",
        "\n",
        "activation_cola_df_2b = extract_activations_df(cola_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GbcWA0pr1ZF",
        "outputId": "4043d9ae-ad9c-4a0a-99ed-f4a0a7ffd57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving cola_t5gemma-2b-2b-ul2 to GDrive...\n",
            "Saved cola_t5gemma-2b-2b-ul2\n"
          ]
        }
      ],
      "source": [
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "v1QYQnRrq6fz",
        "outputId": "f3b05bce-f7be-4e17-9c71-0d3b776ec96a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_cola_df_2b"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6aa901e2-a9d9-45a6-953c-c6686a21608d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_18</th>\n",
              "      <th>decoder_layer_19</th>\n",
              "      <th>decoder_layer_20</th>\n",
              "      <th>decoder_layer_21</th>\n",
              "      <th>decoder_layer_22</th>\n",
              "      <th>decoder_layer_23</th>\n",
              "      <th>decoder_layer_24</th>\n",
              "      <th>decoder_layer_25</th>\n",
              "      <th>decoder_layer_26</th>\n",
              "      <th>decoder_layer_27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The sailors rode the breeze clear of the rocks.</td>\n",
              "      <td>[-0.20664063, -0.33125, -2.0703125, 0.18125, 1...</td>\n",
              "      <td>[-0.21699218, -0.6515625, -0.6003906, -0.14765...</td>\n",
              "      <td>[0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...</td>\n",
              "      <td>[0.85, -0.6933594, 0.91796875, 0.70703125, -0....</td>\n",
              "      <td>[0.4421875, -0.13125, 0.6152344, -0.10585938, ...</td>\n",
              "      <td>[0.34765625, -0.840625, 0.6154297, -0.35234374...</td>\n",
              "      <td>[0.76894534, -0.503125, 0.0041015623, 0.997656...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.0234375, -0.32421875, -0.10546875, -0.32421...</td>\n",
              "      <td>[-0.17578125, -0.12109375, 0.22851562, -0.5898...</td>\n",
              "      <td>[0.27734375, 0.53515625, -0.13085938, 0.25, -0...</td>\n",
              "      <td>[0.05859375, -0.515625, -0.796875, -0.515625, ...</td>\n",
              "      <td>[-0.44921875, -0.0703125, -0.30859375, -0.7812...</td>\n",
              "      <td>[-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...</td>\n",
              "      <td>[-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...</td>\n",
              "      <td>[-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...</td>\n",
              "      <td>[2.015625, 1.765625, 2.953125, -6.65625, 0.298...</td>\n",
              "      <td>[0.25976562, -0.36328125, 1.0859375, -0.277343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The weights made the rope stretch over the pul...</td>\n",
              "      <td>[-0.20664063, -0.33125, -2.0703125, 0.18125, 1...</td>\n",
              "      <td>[-0.21699218, -0.6515625, -0.6003906, -0.14765...</td>\n",
              "      <td>[0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...</td>\n",
              "      <td>[0.85, -0.6933594, 0.91796875, 0.70703125, -0....</td>\n",
              "      <td>[0.4421875, -0.13125, 0.6152344, -0.10585938, ...</td>\n",
              "      <td>[0.34765625, -0.840625, 0.6154297, -0.35234374...</td>\n",
              "      <td>[0.76894534, -0.503125, 0.0041015623, 0.997656...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.0234375, -0.32421875, -0.10546875, -0.32421...</td>\n",
              "      <td>[-0.17578125, -0.12109375, 0.22851562, -0.5898...</td>\n",
              "      <td>[0.27734375, 0.53515625, -0.13085938, 0.25, -0...</td>\n",
              "      <td>[0.05859375, -0.515625, -0.796875, -0.515625, ...</td>\n",
              "      <td>[-0.44921875, -0.0703125, -0.30859375, -0.7812...</td>\n",
              "      <td>[-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...</td>\n",
              "      <td>[-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...</td>\n",
              "      <td>[-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...</td>\n",
              "      <td>[2.015625, 1.765625, 2.953125, -6.65625, 0.298...</td>\n",
              "      <td>[0.25976562, -0.36328125, 1.0859375, -0.277343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>The mechanical doll wriggled itself loose.</td>\n",
              "      <td>[-0.20664063, -0.33125, -2.0703125, 0.18125, 1...</td>\n",
              "      <td>[-0.21699218, -0.6515625, -0.6003906, -0.14765...</td>\n",
              "      <td>[0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...</td>\n",
              "      <td>[0.85, -0.6933594, 0.91796875, 0.70703125, -0....</td>\n",
              "      <td>[0.4421875, -0.13125, 0.6152344, -0.10585938, ...</td>\n",
              "      <td>[0.34765625, -0.840625, 0.6154297, -0.35234374...</td>\n",
              "      <td>[0.76894534, -0.503125, 0.0041015623, 0.997656...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.0234375, -0.32421875, -0.10546875, -0.32421...</td>\n",
              "      <td>[-0.17578125, -0.12109375, 0.22851562, -0.5898...</td>\n",
              "      <td>[0.27734375, 0.53515625, -0.13085938, 0.25, -0...</td>\n",
              "      <td>[0.05859375, -0.515625, -0.796875, -0.515625, ...</td>\n",
              "      <td>[-0.44921875, -0.0703125, -0.30859375, -0.7812...</td>\n",
              "      <td>[-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...</td>\n",
              "      <td>[-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...</td>\n",
              "      <td>[-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...</td>\n",
              "      <td>[2.015625, 1.765625, 2.953125, -6.65625, 0.298...</td>\n",
              "      <td>[0.25976562, -0.36328125, 1.0859375, -0.277343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If you had eaten more, you would want less.</td>\n",
              "      <td>[-0.20664063, -0.33125, -2.0703125, 0.18125, 1...</td>\n",
              "      <td>[-0.21699218, -0.6515625, -0.6003906, -0.14765...</td>\n",
              "      <td>[0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...</td>\n",
              "      <td>[0.85, -0.6933594, 0.91796875, 0.70703125, -0....</td>\n",
              "      <td>[0.4421875, -0.13125, 0.6152344, -0.10585938, ...</td>\n",
              "      <td>[0.34765625, -0.840625, 0.6154297, -0.35234374...</td>\n",
              "      <td>[0.76894534, -0.503125, 0.0041015623, 0.997656...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.0234375, -0.32421875, -0.10546875, -0.32421...</td>\n",
              "      <td>[-0.17578125, -0.12109375, 0.22851562, -0.5898...</td>\n",
              "      <td>[0.27734375, 0.53515625, -0.13085938, 0.25, -0...</td>\n",
              "      <td>[0.05859375, -0.515625, -0.796875, -0.515625, ...</td>\n",
              "      <td>[-0.44921875, -0.0703125, -0.30859375, -0.7812...</td>\n",
              "      <td>[-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...</td>\n",
              "      <td>[-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...</td>\n",
              "      <td>[-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...</td>\n",
              "      <td>[2.015625, 1.765625, 2.953125, -6.65625, 0.298...</td>\n",
              "      <td>[0.25976562, -0.36328125, 1.0859375, -0.277343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in_domain_dev</td>\n",
              "      <td>0</td>\n",
              "      <td>As you eat the most, you want the least.</td>\n",
              "      <td>[-0.20664063, -0.33125, -2.0703125, 0.18125, 1...</td>\n",
              "      <td>[-0.21699218, -0.6515625, -0.6003906, -0.14765...</td>\n",
              "      <td>[0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...</td>\n",
              "      <td>[0.85, -0.6933594, 0.91796875, 0.70703125, -0....</td>\n",
              "      <td>[0.4421875, -0.13125, 0.6152344, -0.10585938, ...</td>\n",
              "      <td>[0.34765625, -0.840625, 0.6154297, -0.35234374...</td>\n",
              "      <td>[0.76894534, -0.503125, 0.0041015623, 0.997656...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.0234375, -0.32421875, -0.10546875, -0.32421...</td>\n",
              "      <td>[-0.17578125, -0.12109375, 0.22851562, -0.5898...</td>\n",
              "      <td>[0.27734375, 0.53515625, -0.13085938, 0.25, -0...</td>\n",
              "      <td>[0.05859375, -0.515625, -0.796875, -0.515625, ...</td>\n",
              "      <td>[-0.44921875, -0.0703125, -0.30859375, -0.7812...</td>\n",
              "      <td>[-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...</td>\n",
              "      <td>[-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...</td>\n",
              "      <td>[-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...</td>\n",
              "      <td>[2.015625, 1.765625, 2.953125, -6.65625, 0.298...</td>\n",
              "      <td>[0.25976562, -0.36328125, 1.0859375, -0.277343...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "      <td>[-0.2878906, -1.54375, -1.6765625, 0.3578125, ...</td>\n",
              "      <td>[-0.065820314, -1.0578125, -0.6777344, 0.11210...</td>\n",
              "      <td>[1.0828125, 0.27578124, 0.8769531, 1.171875, -...</td>\n",
              "      <td>[1.2980468, -0.1796875, 0.7171875, 1.3070313, ...</td>\n",
              "      <td>[0.6660156, 0.378125, 0.23671874, 0.98183596, ...</td>\n",
              "      <td>[1.1953125, -0.7453125, -0.042382814, 0.404687...</td>\n",
              "      <td>[1.3224609, -0.63671875, -0.34140626, 1.260937...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.13476562, -0.29492188, -0.464843...</td>\n",
              "      <td>[-0.0859375, -0.12109375, 0.060302734, -0.7031...</td>\n",
              "      <td>[0.31445312, 0.50390625, -0.40625, 0.12109375,...</td>\n",
              "      <td>[0.0703125, -0.67578125, -0.80078125, -0.65234...</td>\n",
              "      <td>[-0.37109375, -0.33984375, -0.44140625, -0.796...</td>\n",
              "      <td>[-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...</td>\n",
              "      <td>[-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...</td>\n",
              "      <td>[-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...</td>\n",
              "      <td>[2.46875, 1.5625, 1.8515625, -5.625, -0.162109...</td>\n",
              "      <td>[0.64453125, -1.2421875, 1.0078125, 0.9375, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "      <td>[-0.2878906, -1.54375, -1.6765625, 0.3578125, ...</td>\n",
              "      <td>[-0.065820314, -1.0578125, -0.6777344, 0.11210...</td>\n",
              "      <td>[1.0828125, 0.27578124, 0.8769531, 1.171875, -...</td>\n",
              "      <td>[1.2980468, -0.1796875, 0.7171875, 1.3070313, ...</td>\n",
              "      <td>[0.6660156, 0.378125, 0.23671874, 0.98183596, ...</td>\n",
              "      <td>[1.1953125, -0.7453125, -0.042382814, 0.404687...</td>\n",
              "      <td>[1.3224609, -0.63671875, -0.34140626, 1.260937...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.13476562, -0.29492188, -0.464843...</td>\n",
              "      <td>[-0.0859375, -0.12109375, 0.060302734, -0.7031...</td>\n",
              "      <td>[0.31445312, 0.50390625, -0.40625, 0.12109375,...</td>\n",
              "      <td>[0.0703125, -0.67578125, -0.80078125, -0.65234...</td>\n",
              "      <td>[-0.37109375, -0.33984375, -0.44140625, -0.796...</td>\n",
              "      <td>[-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...</td>\n",
              "      <td>[-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...</td>\n",
              "      <td>[-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...</td>\n",
              "      <td>[2.46875, 1.5625, 1.8515625, -5.625, -0.162109...</td>\n",
              "      <td>[0.64453125, -1.2421875, 1.0078125, 0.9375, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "      <td>[-0.2878906, -1.54375, -1.6765625, 0.3578125, ...</td>\n",
              "      <td>[-0.065820314, -1.0578125, -0.6777344, 0.11210...</td>\n",
              "      <td>[1.0828125, 0.27578124, 0.8769531, 1.171875, -...</td>\n",
              "      <td>[1.2980468, -0.1796875, 0.7171875, 1.3070313, ...</td>\n",
              "      <td>[0.6660156, 0.378125, 0.23671874, 0.98183596, ...</td>\n",
              "      <td>[1.1953125, -0.7453125, -0.042382814, 0.404687...</td>\n",
              "      <td>[1.3224609, -0.63671875, -0.34140626, 1.260937...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.13476562, -0.29492188, -0.464843...</td>\n",
              "      <td>[-0.0859375, -0.12109375, 0.060302734, -0.7031...</td>\n",
              "      <td>[0.31445312, 0.50390625, -0.40625, 0.12109375,...</td>\n",
              "      <td>[0.0703125, -0.67578125, -0.80078125, -0.65234...</td>\n",
              "      <td>[-0.37109375, -0.33984375, -0.44140625, -0.796...</td>\n",
              "      <td>[-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...</td>\n",
              "      <td>[-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...</td>\n",
              "      <td>[-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...</td>\n",
              "      <td>[2.46875, 1.5625, 1.8515625, -5.625, -0.162109...</td>\n",
              "      <td>[0.64453125, -1.2421875, 1.0078125, 0.9375, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "      <td>[-0.2878906, -1.54375, -1.6765625, 0.3578125, ...</td>\n",
              "      <td>[-0.065820314, -1.0578125, -0.6777344, 0.11210...</td>\n",
              "      <td>[1.0828125, 0.27578124, 0.8769531, 1.171875, -...</td>\n",
              "      <td>[1.2980468, -0.1796875, 0.7171875, 1.3070313, ...</td>\n",
              "      <td>[0.6660156, 0.378125, 0.23671874, 0.98183596, ...</td>\n",
              "      <td>[1.1953125, -0.7453125, -0.042382814, 0.404687...</td>\n",
              "      <td>[1.3224609, -0.63671875, -0.34140626, 1.260937...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.13476562, -0.29492188, -0.464843...</td>\n",
              "      <td>[-0.0859375, -0.12109375, 0.060302734, -0.7031...</td>\n",
              "      <td>[0.31445312, 0.50390625, -0.40625, 0.12109375,...</td>\n",
              "      <td>[0.0703125, -0.67578125, -0.80078125, -0.65234...</td>\n",
              "      <td>[-0.37109375, -0.33984375, -0.44140625, -0.796...</td>\n",
              "      <td>[-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...</td>\n",
              "      <td>[-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...</td>\n",
              "      <td>[-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...</td>\n",
              "      <td>[2.46875, 1.5625, 1.8515625, -5.625, -0.162109...</td>\n",
              "      <td>[0.64453125, -1.2421875, 1.0078125, 0.9375, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "      <td>[-0.2878906, -1.54375, -1.6765625, 0.3578125, ...</td>\n",
              "      <td>[-0.065820314, -1.0578125, -0.6777344, 0.11210...</td>\n",
              "      <td>[1.0828125, 0.27578124, 0.8769531, 1.171875, -...</td>\n",
              "      <td>[1.2980468, -0.1796875, 0.7171875, 1.3070313, ...</td>\n",
              "      <td>[0.6660156, 0.378125, 0.23671874, 0.98183596, ...</td>\n",
              "      <td>[1.1953125, -0.7453125, -0.042382814, 0.404687...</td>\n",
              "      <td>[1.3224609, -0.63671875, -0.34140626, 1.260937...</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.140625, -0.13476562, -0.29492188, -0.464843...</td>\n",
              "      <td>[-0.0859375, -0.12109375, 0.060302734, -0.7031...</td>\n",
              "      <td>[0.31445312, 0.50390625, -0.40625, 0.12109375,...</td>\n",
              "      <td>[0.0703125, -0.67578125, -0.80078125, -0.65234...</td>\n",
              "      <td>[-0.37109375, -0.33984375, -0.44140625, -0.796...</td>\n",
              "      <td>[-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...</td>\n",
              "      <td>[-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...</td>\n",
              "      <td>[-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...</td>\n",
              "      <td>[2.46875, 1.5625, 1.8515625, -5.625, -0.162109...</td>\n",
              "      <td>[0.64453125, -1.2421875, 1.0078125, 0.9375, -0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 57 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa901e2-a9d9-45a6-953c-c6686a21608d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6aa901e2-a9d9-45a6-953c-c6686a21608d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6aa901e2-a9d9-45a6-953c-c6686a21608d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6c301916-696e-4058-811b-fbb47046e0fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c301916-696e-4058-811b-fbb47046e0fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6c301916-696e-4058-811b-fbb47046e0fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_be55d50f-f77e-4386-b536-d273cc6f258d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('activation_cola_df_2b')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_be55d50f-f77e-4386-b536-d273cc6f258d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('activation_cola_df_2b');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               source  label  \\\n",
              "0       in_domain_dev      1   \n",
              "1       in_domain_dev      1   \n",
              "2       in_domain_dev      1   \n",
              "3       in_domain_dev      1   \n",
              "4       in_domain_dev      0   \n",
              "...               ...    ...   \n",
              "9589  in_domain_train      0   \n",
              "9590  in_domain_train      0   \n",
              "9591  in_domain_train      1   \n",
              "9592  in_domain_train      1   \n",
              "9593  in_domain_train      1   \n",
              "\n",
              "                                               sentence  \\\n",
              "0       The sailors rode the breeze clear of the rocks.   \n",
              "1     The weights made the rope stretch over the pul...   \n",
              "2            The mechanical doll wriggled itself loose.   \n",
              "3           If you had eaten more, you would want less.   \n",
              "4              As you eat the most, you want the least.   \n",
              "...                                                 ...   \n",
              "9589                   Poseidon appears to own a dragon   \n",
              "9590                     Digitize is my happiest memory   \n",
              "9591                     It is easy to slay the Gorgon.   \n",
              "9592       I had the strangest feeling that I knew you.   \n",
              "9593                What all did you get for Christmas?   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [-0.20664063, -0.33125, -2.0703125, 0.18125, 1...   \n",
              "1     [-0.20664063, -0.33125, -2.0703125, 0.18125, 1...   \n",
              "2     [-0.20664063, -0.33125, -2.0703125, 0.18125, 1...   \n",
              "3     [-0.20664063, -0.33125, -2.0703125, 0.18125, 1...   \n",
              "4     [-0.20664063, -0.33125, -2.0703125, 0.18125, 1...   \n",
              "...                                                 ...   \n",
              "9589  [-0.2878906, -1.54375, -1.6765625, 0.3578125, ...   \n",
              "9590  [-0.2878906, -1.54375, -1.6765625, 0.3578125, ...   \n",
              "9591  [-0.2878906, -1.54375, -1.6765625, 0.3578125, ...   \n",
              "9592  [-0.2878906, -1.54375, -1.6765625, 0.3578125, ...   \n",
              "9593  [-0.2878906, -1.54375, -1.6765625, 0.3578125, ...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [-0.21699218, -0.6515625, -0.6003906, -0.14765...   \n",
              "1     [-0.21699218, -0.6515625, -0.6003906, -0.14765...   \n",
              "2     [-0.21699218, -0.6515625, -0.6003906, -0.14765...   \n",
              "3     [-0.21699218, -0.6515625, -0.6003906, -0.14765...   \n",
              "4     [-0.21699218, -0.6515625, -0.6003906, -0.14765...   \n",
              "...                                                 ...   \n",
              "9589  [-0.065820314, -1.0578125, -0.6777344, 0.11210...   \n",
              "9590  [-0.065820314, -1.0578125, -0.6777344, 0.11210...   \n",
              "9591  [-0.065820314, -1.0578125, -0.6777344, 0.11210...   \n",
              "9592  [-0.065820314, -1.0578125, -0.6777344, 0.11210...   \n",
              "9593  [-0.065820314, -1.0578125, -0.6777344, 0.11210...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...   \n",
              "1     [0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...   \n",
              "2     [0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...   \n",
              "3     [0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...   \n",
              "4     [0.89140624, 0.5, 0.6953125, 0.39140624, -0.44...   \n",
              "...                                                 ...   \n",
              "9589  [1.0828125, 0.27578124, 0.8769531, 1.171875, -...   \n",
              "9590  [1.0828125, 0.27578124, 0.8769531, 1.171875, -...   \n",
              "9591  [1.0828125, 0.27578124, 0.8769531, 1.171875, -...   \n",
              "9592  [1.0828125, 0.27578124, 0.8769531, 1.171875, -...   \n",
              "9593  [1.0828125, 0.27578124, 0.8769531, 1.171875, -...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [0.85, -0.6933594, 0.91796875, 0.70703125, -0....   \n",
              "1     [0.85, -0.6933594, 0.91796875, 0.70703125, -0....   \n",
              "2     [0.85, -0.6933594, 0.91796875, 0.70703125, -0....   \n",
              "3     [0.85, -0.6933594, 0.91796875, 0.70703125, -0....   \n",
              "4     [0.85, -0.6933594, 0.91796875, 0.70703125, -0....   \n",
              "...                                                 ...   \n",
              "9589  [1.2980468, -0.1796875, 0.7171875, 1.3070313, ...   \n",
              "9590  [1.2980468, -0.1796875, 0.7171875, 1.3070313, ...   \n",
              "9591  [1.2980468, -0.1796875, 0.7171875, 1.3070313, ...   \n",
              "9592  [1.2980468, -0.1796875, 0.7171875, 1.3070313, ...   \n",
              "9593  [1.2980468, -0.1796875, 0.7171875, 1.3070313, ...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [0.4421875, -0.13125, 0.6152344, -0.10585938, ...   \n",
              "1     [0.4421875, -0.13125, 0.6152344, -0.10585938, ...   \n",
              "2     [0.4421875, -0.13125, 0.6152344, -0.10585938, ...   \n",
              "3     [0.4421875, -0.13125, 0.6152344, -0.10585938, ...   \n",
              "4     [0.4421875, -0.13125, 0.6152344, -0.10585938, ...   \n",
              "...                                                 ...   \n",
              "9589  [0.6660156, 0.378125, 0.23671874, 0.98183596, ...   \n",
              "9590  [0.6660156, 0.378125, 0.23671874, 0.98183596, ...   \n",
              "9591  [0.6660156, 0.378125, 0.23671874, 0.98183596, ...   \n",
              "9592  [0.6660156, 0.378125, 0.23671874, 0.98183596, ...   \n",
              "9593  [0.6660156, 0.378125, 0.23671874, 0.98183596, ...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [0.34765625, -0.840625, 0.6154297, -0.35234374...   \n",
              "1     [0.34765625, -0.840625, 0.6154297, -0.35234374...   \n",
              "2     [0.34765625, -0.840625, 0.6154297, -0.35234374...   \n",
              "3     [0.34765625, -0.840625, 0.6154297, -0.35234374...   \n",
              "4     [0.34765625, -0.840625, 0.6154297, -0.35234374...   \n",
              "...                                                 ...   \n",
              "9589  [1.1953125, -0.7453125, -0.042382814, 0.404687...   \n",
              "9590  [1.1953125, -0.7453125, -0.042382814, 0.404687...   \n",
              "9591  [1.1953125, -0.7453125, -0.042382814, 0.404687...   \n",
              "9592  [1.1953125, -0.7453125, -0.042382814, 0.404687...   \n",
              "9593  [1.1953125, -0.7453125, -0.042382814, 0.404687...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.76894534, -0.503125, 0.0041015623, 0.997656...  ...   \n",
              "1     [0.76894534, -0.503125, 0.0041015623, 0.997656...  ...   \n",
              "2     [0.76894534, -0.503125, 0.0041015623, 0.997656...  ...   \n",
              "3     [0.76894534, -0.503125, 0.0041015623, 0.997656...  ...   \n",
              "4     [0.76894534, -0.503125, 0.0041015623, 0.997656...  ...   \n",
              "...                                                 ...  ...   \n",
              "9589  [1.3224609, -0.63671875, -0.34140626, 1.260937...  ...   \n",
              "9590  [1.3224609, -0.63671875, -0.34140626, 1.260937...  ...   \n",
              "9591  [1.3224609, -0.63671875, -0.34140626, 1.260937...  ...   \n",
              "9592  [1.3224609, -0.63671875, -0.34140626, 1.260937...  ...   \n",
              "9593  [1.3224609, -0.63671875, -0.34140626, 1.260937...  ...   \n",
              "\n",
              "                                       decoder_layer_18  \\\n",
              "0     [0.0234375, -0.32421875, -0.10546875, -0.32421...   \n",
              "1     [0.0234375, -0.32421875, -0.10546875, -0.32421...   \n",
              "2     [0.0234375, -0.32421875, -0.10546875, -0.32421...   \n",
              "3     [0.0234375, -0.32421875, -0.10546875, -0.32421...   \n",
              "4     [0.0234375, -0.32421875, -0.10546875, -0.32421...   \n",
              "...                                                 ...   \n",
              "9589  [0.140625, -0.13476562, -0.29492188, -0.464843...   \n",
              "9590  [0.140625, -0.13476562, -0.29492188, -0.464843...   \n",
              "9591  [0.140625, -0.13476562, -0.29492188, -0.464843...   \n",
              "9592  [0.140625, -0.13476562, -0.29492188, -0.464843...   \n",
              "9593  [0.140625, -0.13476562, -0.29492188, -0.464843...   \n",
              "\n",
              "                                       decoder_layer_19  \\\n",
              "0     [-0.17578125, -0.12109375, 0.22851562, -0.5898...   \n",
              "1     [-0.17578125, -0.12109375, 0.22851562, -0.5898...   \n",
              "2     [-0.17578125, -0.12109375, 0.22851562, -0.5898...   \n",
              "3     [-0.17578125, -0.12109375, 0.22851562, -0.5898...   \n",
              "4     [-0.17578125, -0.12109375, 0.22851562, -0.5898...   \n",
              "...                                                 ...   \n",
              "9589  [-0.0859375, -0.12109375, 0.060302734, -0.7031...   \n",
              "9590  [-0.0859375, -0.12109375, 0.060302734, -0.7031...   \n",
              "9591  [-0.0859375, -0.12109375, 0.060302734, -0.7031...   \n",
              "9592  [-0.0859375, -0.12109375, 0.060302734, -0.7031...   \n",
              "9593  [-0.0859375, -0.12109375, 0.060302734, -0.7031...   \n",
              "\n",
              "                                       decoder_layer_20  \\\n",
              "0     [0.27734375, 0.53515625, -0.13085938, 0.25, -0...   \n",
              "1     [0.27734375, 0.53515625, -0.13085938, 0.25, -0...   \n",
              "2     [0.27734375, 0.53515625, -0.13085938, 0.25, -0...   \n",
              "3     [0.27734375, 0.53515625, -0.13085938, 0.25, -0...   \n",
              "4     [0.27734375, 0.53515625, -0.13085938, 0.25, -0...   \n",
              "...                                                 ...   \n",
              "9589  [0.31445312, 0.50390625, -0.40625, 0.12109375,...   \n",
              "9590  [0.31445312, 0.50390625, -0.40625, 0.12109375,...   \n",
              "9591  [0.31445312, 0.50390625, -0.40625, 0.12109375,...   \n",
              "9592  [0.31445312, 0.50390625, -0.40625, 0.12109375,...   \n",
              "9593  [0.31445312, 0.50390625, -0.40625, 0.12109375,...   \n",
              "\n",
              "                                       decoder_layer_21  \\\n",
              "0     [0.05859375, -0.515625, -0.796875, -0.515625, ...   \n",
              "1     [0.05859375, -0.515625, -0.796875, -0.515625, ...   \n",
              "2     [0.05859375, -0.515625, -0.796875, -0.515625, ...   \n",
              "3     [0.05859375, -0.515625, -0.796875, -0.515625, ...   \n",
              "4     [0.05859375, -0.515625, -0.796875, -0.515625, ...   \n",
              "...                                                 ...   \n",
              "9589  [0.0703125, -0.67578125, -0.80078125, -0.65234...   \n",
              "9590  [0.0703125, -0.67578125, -0.80078125, -0.65234...   \n",
              "9591  [0.0703125, -0.67578125, -0.80078125, -0.65234...   \n",
              "9592  [0.0703125, -0.67578125, -0.80078125, -0.65234...   \n",
              "9593  [0.0703125, -0.67578125, -0.80078125, -0.65234...   \n",
              "\n",
              "                                       decoder_layer_22  \\\n",
              "0     [-0.44921875, -0.0703125, -0.30859375, -0.7812...   \n",
              "1     [-0.44921875, -0.0703125, -0.30859375, -0.7812...   \n",
              "2     [-0.44921875, -0.0703125, -0.30859375, -0.7812...   \n",
              "3     [-0.44921875, -0.0703125, -0.30859375, -0.7812...   \n",
              "4     [-0.44921875, -0.0703125, -0.30859375, -0.7812...   \n",
              "...                                                 ...   \n",
              "9589  [-0.37109375, -0.33984375, -0.44140625, -0.796...   \n",
              "9590  [-0.37109375, -0.33984375, -0.44140625, -0.796...   \n",
              "9591  [-0.37109375, -0.33984375, -0.44140625, -0.796...   \n",
              "9592  [-0.37109375, -0.33984375, -0.44140625, -0.796...   \n",
              "9593  [-0.37109375, -0.33984375, -0.44140625, -0.796...   \n",
              "\n",
              "                                       decoder_layer_23  \\\n",
              "0     [-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...   \n",
              "1     [-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...   \n",
              "2     [-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...   \n",
              "3     [-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...   \n",
              "4     [-3.09375, 1.0546875, 1.6640625, -2.09375, 0.2...   \n",
              "...                                                 ...   \n",
              "9589  [-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...   \n",
              "9590  [-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...   \n",
              "9591  [-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...   \n",
              "9592  [-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...   \n",
              "9593  [-2.65625, 0.4453125, 1.03125, -1.703125, 0.26...   \n",
              "\n",
              "                                       decoder_layer_24  \\\n",
              "0     [-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...   \n",
              "1     [-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...   \n",
              "2     [-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...   \n",
              "3     [-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...   \n",
              "4     [-3.65625, 2.609375, 1.6328125, -5.9375, 1.351...   \n",
              "...                                                 ...   \n",
              "9589  [-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...   \n",
              "9590  [-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...   \n",
              "9591  [-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...   \n",
              "9592  [-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...   \n",
              "9593  [-2.9375, 1.6484375, 1.0, -5.5, 0.984375, -0.4...   \n",
              "\n",
              "                                       decoder_layer_25  \\\n",
              "0     [-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...   \n",
              "1     [-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...   \n",
              "2     [-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...   \n",
              "3     [-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...   \n",
              "4     [-2.9375, 2.71875, 1.9140625, -6.1875, 0.99218...   \n",
              "...                                                 ...   \n",
              "9589  [-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...   \n",
              "9590  [-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...   \n",
              "9591  [-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...   \n",
              "9592  [-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...   \n",
              "9593  [-2.296875, 1.8125, 1.0546875, -6.03125, 0.593...   \n",
              "\n",
              "                                       decoder_layer_26  \\\n",
              "0     [2.015625, 1.765625, 2.953125, -6.65625, 0.298...   \n",
              "1     [2.015625, 1.765625, 2.953125, -6.65625, 0.298...   \n",
              "2     [2.015625, 1.765625, 2.953125, -6.65625, 0.298...   \n",
              "3     [2.015625, 1.765625, 2.953125, -6.65625, 0.298...   \n",
              "4     [2.015625, 1.765625, 2.953125, -6.65625, 0.298...   \n",
              "...                                                 ...   \n",
              "9589  [2.46875, 1.5625, 1.8515625, -5.625, -0.162109...   \n",
              "9590  [2.46875, 1.5625, 1.8515625, -5.625, -0.162109...   \n",
              "9591  [2.46875, 1.5625, 1.8515625, -5.625, -0.162109...   \n",
              "9592  [2.46875, 1.5625, 1.8515625, -5.625, -0.162109...   \n",
              "9593  [2.46875, 1.5625, 1.8515625, -5.625, -0.162109...   \n",
              "\n",
              "                                       decoder_layer_27  \n",
              "0     [0.25976562, -0.36328125, 1.0859375, -0.277343...  \n",
              "1     [0.25976562, -0.36328125, 1.0859375, -0.277343...  \n",
              "2     [0.25976562, -0.36328125, 1.0859375, -0.277343...  \n",
              "3     [0.25976562, -0.36328125, 1.0859375, -0.277343...  \n",
              "4     [0.25976562, -0.36328125, 1.0859375, -0.277343...  \n",
              "...                                                 ...  \n",
              "9589  [0.64453125, -1.2421875, 1.0078125, 0.9375, -0...  \n",
              "9590  [0.64453125, -1.2421875, 1.0078125, 0.9375, -0...  \n",
              "9591  [0.64453125, -1.2421875, 1.0078125, 0.9375, -0...  \n",
              "9592  [0.64453125, -1.2421875, 1.0078125, 0.9375, -0...  \n",
              "9593  [0.64453125, -1.2421875, 1.0078125, 0.9375, -0...  \n",
              "\n",
              "[9594 rows x 57 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "activation_cola_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoT3PwO9q9Of"
      },
      "source": [
        "## UD_English-EWT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NW-Jc9bqrArz",
        "outputId": "704b4bb4-ecbd-4f82-9ab7-f5ed428278c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-6.0.0\n",
            "--2025-11-25 08:50:50--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/refs/heads/master/en_ewt-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15029817 (14M) [text/plain]\n",
            "Saving to: ‘en_ewt-ud-train.conllu’\n",
            "\n",
            "en_ewt-ud-train.con 100%[===================>]  14.33M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-11-25 08:50:51 (477 MB/s) - ‘en_ewt-ud-train.conllu’ saved [15029817/15029817]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/refs/heads/master/en_ewt-ud-train.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_tTkqzWvUnF",
        "outputId": "a877e9ef-588f-41a2-fceb-2721aa834f7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing conllu: 12544it [00:04, 2650.47it/s]\n",
            "Converting to DataFrame: 100%|██████████| 12544/12544 [00:00<00:00, 469430.93it/s]\n"
          ]
        }
      ],
      "source": [
        "from conllu import parse_incr\n",
        "\n",
        "def load_conllu(path):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for tokenlist in tqdm(parse_incr(f), desc='Parsing conllu'):\n",
        "            yield {\n",
        "                \"text\": tokenlist.metadata.get(\"text\", \"\"),\n",
        "                \"tokens\": [t[\"form\"] for t in tokenlist],\n",
        "                \"token_id\": [t[\"id\"] for t in tokenlist],\n",
        "                \"upos\": [t[\"upostag\"] for t in tokenlist],\n",
        "                #\"xpos\": [t[\"xpostag\"] for t in tokenlist],\n",
        "            }\n",
        "\n",
        "train = list(load_conllu(\"en_ewt-ud-train.conllu\"))\n",
        "\n",
        "items_to_df = {k:[] for k in train[0].keys()}\n",
        "\n",
        "for item in tqdm(train, desc='Converting to DataFrame'):\n",
        "  for k, v in item.items():\n",
        "    items_to_df[k].append(v)\n",
        "\n",
        "ewt_df = pd.DataFrame(items_to_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "collapsed": true,
        "id": "1oKlVx5WvVvJ",
        "outputId": "eb36d21a-134a-45ca-bb50-65056b5e77d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21e95f99-e38f-46c9-97c2-329e329fbb04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>token_id</th>\n",
              "      <th>upos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al-Zaman : American forces killed Shaikh Abdul...</td>\n",
              "      <td>[Al, -, Zaman, :, American, forces, killed, Sh...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PROPN, PUNCT, PROPN, PUNCT, ADJ, NOUN, VERB, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[This killing of a respected cleric will be ca...</td>\n",
              "      <td>[[, This, killing, of, a, respected, cleric, w...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PUNCT, DET, NOUN, ADP, DET, ADJ, NOUN, AUX, A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DPA: Iraqi authorities announced that they had...</td>\n",
              "      <td>[DPA, :, Iraqi, authorities, announced, that, ...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PROPN, PUNCT, ADJ, NOUN, VERB, SCONJ, PRON, A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two of them were being run by 2 officials of t...</td>\n",
              "      <td>[Two, of, them, were, being, run, by, 2, offic...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[NUM, ADP, PRON, AUX, AUX, VERB, ADP, NUM, NOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The MoI in Iraq is equivalent to the US FBI, s...</td>\n",
              "      <td>[The, MoI, in, Iraq, is, equivalent, to, the, ...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[DET, PROPN, ADP, PROPN, AUX, ADJ, ADP, DET, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12539</th>\n",
              "      <td>Of course, they couldn't call him either to as...</td>\n",
              "      <td>[Of, course, ,, they, couldn't, could, n't, ca...</td>\n",
              "      <td>[1, 2, 3, 4, (5, -, 6), 5, 6, 7, 8, 9, 10, 11,...</td>\n",
              "      <td>[ADP, NOUN, PUNCT, PRON, _, AUX, PART, VERB, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12540</th>\n",
              "      <td>On Monday I called and again it was a big to-d...</td>\n",
              "      <td>[On, Monday, I, called, and, again, it, was, a...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[ADP, PROPN, PRON, VERB, CCONJ, ADV, PRON, AUX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12541</th>\n",
              "      <td>Supposedly they will be holding it for me this...</td>\n",
              "      <td>[Supposedly, they, will, be, holding, it, for,...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, (13, -...</td>\n",
              "      <td>[ADV, PRON, AUX, AUX, VERB, PRON, ADP, PRON, D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12542</th>\n",
              "      <td>The employees at this Sear's are completely ap...</td>\n",
              "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, (11, -, 12), 1...</td>\n",
              "      <td>[DET, NOUN, ADP, DET, PROPN, AUX, ADV, ADJ, CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12543</th>\n",
              "      <td>I will never return there again (and now have ...</td>\n",
              "      <td>[I, will, never, return, there, again, (, and,...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PRON, AUX, ADV, VERB, ADV, ADV, PUNCT, CCONJ,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12544 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e95f99-e38f-46c9-97c2-329e329fbb04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21e95f99-e38f-46c9-97c2-329e329fbb04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21e95f99-e38f-46c9-97c2-329e329fbb04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "0      Al-Zaman : American forces killed Shaikh Abdul...   \n",
              "1      [This killing of a respected cleric will be ca...   \n",
              "2      DPA: Iraqi authorities announced that they had...   \n",
              "3      Two of them were being run by 2 officials of t...   \n",
              "4      The MoI in Iraq is equivalent to the US FBI, s...   \n",
              "...                                                  ...   \n",
              "12539  Of course, they couldn't call him either to as...   \n",
              "12540  On Monday I called and again it was a big to-d...   \n",
              "12541  Supposedly they will be holding it for me this...   \n",
              "12542  The employees at this Sear's are completely ap...   \n",
              "12543  I will never return there again (and now have ...   \n",
              "\n",
              "                                                  tokens  \\\n",
              "0      [Al, -, Zaman, :, American, forces, killed, Sh...   \n",
              "1      [[, This, killing, of, a, respected, cleric, w...   \n",
              "2      [DPA, :, Iraqi, authorities, announced, that, ...   \n",
              "3      [Two, of, them, were, being, run, by, 2, offic...   \n",
              "4      [The, MoI, in, Iraq, is, equivalent, to, the, ...   \n",
              "...                                                  ...   \n",
              "12539  [Of, course, ,, they, couldn't, could, n't, ca...   \n",
              "12540  [On, Monday, I, called, and, again, it, was, a...   \n",
              "12541  [Supposedly, they, will, be, holding, it, for,...   \n",
              "12542  [The, employees, at, this, Sear's, are, comple...   \n",
              "12543  [I, will, never, return, there, again, (, and,...   \n",
              "\n",
              "                                                token_id  \\\n",
              "0      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "2      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "3      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "4      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "...                                                  ...   \n",
              "12539  [1, 2, 3, 4, (5, -, 6), 5, 6, 7, 8, 9, 10, 11,...   \n",
              "12540  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "12541  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, (13, -...   \n",
              "12542  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, (11, -, 12), 1...   \n",
              "12543  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "\n",
              "                                                    upos  \n",
              "0      [PROPN, PUNCT, PROPN, PUNCT, ADJ, NOUN, VERB, ...  \n",
              "1      [PUNCT, DET, NOUN, ADP, DET, ADJ, NOUN, AUX, A...  \n",
              "2      [PROPN, PUNCT, ADJ, NOUN, VERB, SCONJ, PRON, A...  \n",
              "3      [NUM, ADP, PRON, AUX, AUX, VERB, ADP, NUM, NOU...  \n",
              "4      [DET, PROPN, ADP, PROPN, AUX, ADJ, ADP, DET, P...  \n",
              "...                                                  ...  \n",
              "12539  [ADP, NOUN, PUNCT, PRON, _, AUX, PART, VERB, P...  \n",
              "12540  [ADP, PROPN, PRON, VERB, CCONJ, ADV, PRON, AUX...  \n",
              "12541  [ADV, PRON, AUX, AUX, VERB, PRON, ADP, PRON, D...  \n",
              "12542  [DET, NOUN, ADP, DET, PROPN, AUX, ADV, ADJ, CC...  \n",
              "12543  [PRON, AUX, ADV, VERB, ADV, ADV, PUNCT, CCONJ,...  \n",
              "\n",
              "[12544 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zofmGBIYr27l"
      },
      "source": [
        "here we have 2 pos taggings upos (more general) and xpos (more specific).\n",
        "we will consider the upos for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcUn9Q030X33"
      },
      "source": [
        "now we define a function to convert the ewt dataset to a token version where the upos and xpos are more clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rufmBVMUy1Iz"
      },
      "outputs": [],
      "source": [
        "def convert_ewt_to_token(ewt_df):\n",
        "  token_ewt_dict = {\n",
        "      'words': [],\n",
        "      'sentence_id': [],\n",
        "      'upos': [],\n",
        "      'token_id':[]\n",
        "      #'xpos': [],\n",
        "  }\n",
        "\n",
        "  for row in ewt_df.iterrows():\n",
        "    for token, upos, token_id in zip(row[1]['tokens'], row[1]['upos'], row[1]['token_id']):\n",
        "      if isinstance(token_id, int):\n",
        "        token_ewt_dict['words'].append(token)\n",
        "        token_ewt_dict['sentence_id'].append(row[0])\n",
        "        token_ewt_dict['upos'].append(upos)\n",
        "        token_ewt_dict['token_id'].append(token_id)\n",
        "        #token_ewt_dict['xpos'].append(xpos)\n",
        "\n",
        "  return pd.DataFrame(token_ewt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "collapsed": true,
        "id": "bLtu7mX70qX3",
        "outputId": "c8cecfb1-a608-4b98-819d-c459c3970bc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d1e234e-6323-4d6d-b709-ccb8038d2fab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos</th>\n",
              "      <th>token_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204572</th>\n",
              "      <td>on</td>\n",
              "      <td>12543</td>\n",
              "      <td>ADP</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204573</th>\n",
              "      <td>my</td>\n",
              "      <td>12543</td>\n",
              "      <td>PRON</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204574</th>\n",
              "      <td>car</td>\n",
              "      <td>12543</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204575</th>\n",
              "      <td>)</td>\n",
              "      <td>12543</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204576</th>\n",
              "      <td>.</td>\n",
              "      <td>12543</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204577 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d1e234e-6323-4d6d-b709-ccb8038d2fab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d1e234e-6323-4d6d-b709-ccb8038d2fab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d1e234e-6323-4d6d-b709-ccb8038d2fab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           words  sentence_id   upos  token_id\n",
              "0             Al            0  PROPN         1\n",
              "1              -            0  PUNCT         2\n",
              "2          Zaman            0  PROPN         3\n",
              "3              :            0  PUNCT         4\n",
              "4       American            0    ADJ         5\n",
              "...          ...          ...    ...       ...\n",
              "204572        on        12543    ADP        22\n",
              "204573        my        12543   PRON        23\n",
              "204574       car        12543   NOUN        24\n",
              "204575         )        12543  PUNCT        25\n",
              "204576         .        12543  PUNCT        26\n",
              "\n",
              "[204577 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_ewt_df = convert_ewt_to_token(ewt_df)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dE9O8Wc9WNC"
      },
      "source": [
        "there is a problem of subtokenization, we will use the word_ids provided by the tokenizer and send to it the sentence divided into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpoil2Sv59Ty",
        "outputId": "6073c20c-d898-499b-a56e-8a262aa339da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checking sentences: 100%|██████████| 12544/12544 [00:15<00:00, 830.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Problematic sentences: 0 (0.00%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_sentences = token_ewt_df['sentence_id'].nunique()\n",
        "c = 0\n",
        "problematic_indexes = []\n",
        "\n",
        "for index in tqdm(range(num_sentences), desc='Checking sentences'):\n",
        "  words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "  inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "  word_ids = inputs.word_ids()\n",
        "\n",
        "  tokens = tokenizer_b.convert_ids_to_tokens(inputs.input_ids[0])\n",
        "\n",
        "  control = []\n",
        "  for word_idx in range(len(words)):\n",
        "    token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "\n",
        "    if not token_indices: # escape case (should not happen but who knows ...)\n",
        "        continue\n",
        "\n",
        "    subwords = [tokens[i] for i in token_indices]\n",
        "    reconstructed_word = ''.join(subwords)\n",
        "    control.append(reconstructed_word)\n",
        "\n",
        "  if control != words:\n",
        "    c = c+1 # c is the number of sentences where the subtoken aggregation differs from the 'dataset' tokenization\n",
        "    problematic_indexes.append(index) # sentence to be removed later\n",
        "\n",
        "assert(len(problematic_indexes)==c)\n",
        "print(f'\\nProblematic sentences: {c} ({c/(num_sentences)*100:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k41uxGH-9MUl"
      },
      "source": [
        "it works prefectly with all the sentences in the dataset!\n",
        "\n",
        "now let's try to get the word representations at a fixed layer for a fixed sentence: if a token corresponds to a word we will use the representation of the token as the representation of the word, if more token corresponds to a word (we know that thanks to the word_ids) we will calculate the mean (as done previously) to get the word representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtEFSwby4yp4",
        "outputId": "254ace0e-7716-4b2e-f406-19b0b2e125dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original words in the sentence: 17\n",
            "Tensor obtained: 17\n"
          ]
        }
      ],
      "source": [
        "index = 2\n",
        "layer = 0\n",
        "\n",
        "words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "\n",
        "model_b.eval()\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model_b(**inputs,decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "encoder_hidden_states = outputs.encoder_hidden_states[layer].squeeze(0)\n",
        "\n",
        "word_ids = inputs.word_ids()\n",
        "\n",
        "token_representation = []\n",
        "\n",
        "for word_idx in range(len(words)):\n",
        "  token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "  relevant_vectors = encoder_hidden_states[token_indices] # getting the correspondent hidden states\n",
        "  mean_vector = torch.mean(relevant_vectors, dim=0)\n",
        "  token_representation.append(mean_vector.cpu())\n",
        "\n",
        "print(f\"Original words in the sentence: {len(words)}\")\n",
        "print(f\"Tensor obtained: {len(token_representation)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0E7jX8S-Lgi"
      },
      "source": [
        "now let's put all together into a function to process the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs-Y2yyoDSSB"
      },
      "outputs": [],
      "source": [
        "def get_word_representation_df(model, tokenizer, df, batch_size=1):\n",
        "    sentences_words = df.groupby('sentence_id', sort=False)['words'].apply(list).tolist()\n",
        "    num_encoder_layers = model.config.encoder.num_hidden_layers + 1\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    word_representation_dict = {f'encoder_layer_{e+1}': [] for e in range(num_encoder_layers)}\n",
        "\n",
        "    for i in tqdm(range(0, len(sentences_words), batch_size), desc='Processing batches'):\n",
        "        batch_words = sentences_words[i : i + batch_size]\n",
        "        inputs = tokenizer(batch_words, return_tensors=\"pt\", padding=True, is_split_into_words=True, truncation=False).to(device)\n",
        "\n",
        "        current_batch_size = inputs.input_ids.shape[0]\n",
        "        start_token_id = tokenizer.bos_token_id\n",
        "        decoder_input_ids = torch.full((current_batch_size, 1), start_token_id, device=device, dtype=int) # [batch_size, 1 (<bos>)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "        all_layers_hidden_states = torch.stack(outputs.encoder_hidden_states) # [num_layers, batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # before iterating over batch sentences to calculate word_ids once\n",
        "        for b_idx in range(current_batch_size):\n",
        "            word_ids = inputs.word_ids(batch_index=b_idx)\n",
        "            num_original_words = len(batch_words[b_idx])\n",
        "\n",
        "            sentence_states = all_layers_hidden_states[:, b_idx, :, :] # [num_layers, seq_len, hidden_dim]\n",
        "\n",
        "            # later iterating over words\n",
        "            for word_idx in range(num_original_words):\n",
        "                token_indices = [k for k, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "                relevant_vectors = sentence_states[:, token_indices, :] # [num_layers, num_subtokens (possibily 1), hidden_dim]\n",
        "                mean_vectors = torch.mean(relevant_vectors, dim=1)\n",
        "                mean_vectors_np = mean_vectors.cpu().to(torch.float16).numpy()\n",
        "\n",
        "                # finally iterating over layers\n",
        "                for layer_idx in range(num_encoder_layers):\n",
        "                    word_representation_dict[f'encoder_layer_{layer_idx+1}'].append(mean_vectors_np[layer_idx])\n",
        "\n",
        "\n",
        "    token_representation_df = pd.DataFrame(word_representation_dict)\n",
        "\n",
        "    # safety check\n",
        "    print(f\"Original rows: {len(df)}\")\n",
        "    print(f\"Extracted rows: {len(token_representation_df)}\")\n",
        "\n",
        "    return token_representation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPQa2JlSttTm"
      },
      "source": [
        "now let's consider the labels\n",
        "\n",
        "we will consider the base label, with upos tags and also the control task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfC7lCmy9wsI"
      },
      "outputs": [],
      "source": [
        "# defining the POS tags\n",
        "upos_labels = token_ewt_df['upos'].unique()\n",
        "upos_tags = {u:i for i,u in enumerate(upos_labels)}\n",
        "\n",
        "# inserting the tags in the dataset\n",
        "token_ewt_df['upos_tag']=token_ewt_df['upos'].map(lambda upos: upos_tags[upos])\n",
        "token_ewt_df.drop(columns=['upos', 'token_id'], inplace=True)\n",
        "\n",
        "# defining the control task upos tags\n",
        "unique_words = list(token_ewt_df['words'].unique())\n",
        "np.random.shuffle(unique_words)\n",
        "\n",
        "num_upos_tags = len(upos_tags)\n",
        "token_ct_map_upos={x:i%num_upos_tags for i,x in enumerate(unique_words)}\n",
        "\n",
        "# adding the control task tags to the dataframe\n",
        "token_ewt_df['ct_upos_tag']=token_ewt_df['words'].map(lambda u: token_ct_map_upos[u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmdgN0aZyJb1"
      },
      "source": [
        "optional: xpos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db5e9y3AyLbc"
      },
      "outputs": [],
      "source": [
        "#xpos_labels=token_ewt_df['xpos'].unique()\n",
        "#xpos_tags={x:i for i,x in enumerate(xpos_labels)}\n",
        "#token_ewt_df['xpos_tag']=token_ewt_df['xpos'].map(lambda xpos: xpos_tags[xpos])\n",
        "#token_ewt_df.drop(columns=['xpos'], inplace=True)\n",
        "\n",
        "# control task\n",
        "\n",
        "#num_xpos_tags = len(xpos_tags)\n",
        "#token_ct_map_xpos={x:i%num_xpos_tags for i,x in enumerate(unique_tokens)} # token control task map for xpos\n",
        "#token_ewt_df['ct_xpos_tag']=token_ewt_df['tokens'].map(lambda x: token_ct_map_xpos[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Ou353rtRs8"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebqMzZuLtRs8",
        "outputId": "b0e9883a-a4e7-4a7f-daec-63326f9aaf79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 392/392 [01:52<00:00,  3.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original rows: 204577\n",
            "Extracted rows: 204577\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5caf7cc2-0395-43cc-b5dd-f141e6f986aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos_tag</th>\n",
              "      <th>ct_upos_tag</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>encoder_layer_8</th>\n",
              "      <th>encoder_layer_9</th>\n",
              "      <th>encoder_layer_10</th>\n",
              "      <th>encoder_layer_11</th>\n",
              "      <th>encoder_layer_12</th>\n",
              "      <th>encoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.953, -0.1245, -1.445, 0.2197, -0.1729, -0.3...</td>\n",
              "      <td>[-0.08594, 0.293, -1.25, -1.5, 0.1885, 1.391, ...</td>\n",
              "      <td>[-0.01074, -0.01807, -0.6875, -0.7812, 0.8555,...</td>\n",
              "      <td>[-0.4297, 0.3672, -0.9336, -0.539, 0.9297, 1.2...</td>\n",
              "      <td>[-0.2656, 0.6797, -0.6367, -0.578, 1.266, 1.46...</td>\n",
              "      <td>[-1.0, 0.3984, 0.04004, -0.1738, 1.516, 1.242,...</td>\n",
              "      <td>[-0.6797, 0.4727, 0.7773, 0.4727, 0.9766, 1.62...</td>\n",
              "      <td>[-1.008, 0.8633, -0.02344, 0.617, 0.914, 1.406...</td>\n",
              "      <td>[-0.5156, 0.0957, -0.8047, -0.629, 1.906, 2.15...</td>\n",
              "      <td>[-2.062, 0.02734, -1.156, -0.6953, 1.625, 2.29...</td>\n",
              "      <td>[-1.453, 0.1357, -0.547, -0.5625, 2.25, 3.11, ...</td>\n",
              "      <td>[-2.156, 1.406, -0.3574, 0.715, 2.766, 2.797, ...</td>\n",
              "      <td>[-3.922, 2.219, -1.922, -2.25, 7.562, 5.78, -3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>[0.664, -0.10254, 0.001694, 0.5156, -0.801, -3...</td>\n",
              "      <td>[-0.707, 0.6875, -0.0498, -0.6367, -0.875, 0.1...</td>\n",
              "      <td>[-0.801, 0.5547, 0.01758, -0.1855, -0.3242, 0....</td>\n",
              "      <td>[-0.3984, 0.4707, -0.3965, -0.25, 0.4453, -0.6...</td>\n",
              "      <td>[-1.156, 1.453, -0.05273, -0.6133, 0.6484, -0....</td>\n",
              "      <td>[-1.305, 1.227, 0.59, -0.459, 1.0625, -0.4766,...</td>\n",
              "      <td>[-1.969, 0.832, 0.9414, -1.6875, 1.352, 0.4941...</td>\n",
              "      <td>[-1.422, 0.5586, 1.016, -0.836, 0.4883, -2.0, ...</td>\n",
              "      <td>[-1.0625, 3.078, -2.0, -1.18, 0.2031, -0.02344...</td>\n",
              "      <td>[0.04688, 1.953, -1.32, -1.594, 0.2441, 1.961,...</td>\n",
              "      <td>[2.078, 3.5, 0.4414, -1.773, -1.508, 1.445, 0....</td>\n",
              "      <td>[4.688, 5.28, 3.344, -0.6367, -5.97, 2.89, -1....</td>\n",
              "      <td>[4.094, 2.594, 1.25, -0.3145, -4.094, 2.64, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>[3.438, 0.1245, -1.836, 1.141, 0.8984, -1.547,...</td>\n",
              "      <td>[-0.1777, 0.4453, -1.5625, 0.02734, 0.5625, -0...</td>\n",
              "      <td>[-0.4102, -0.4414, -0.9297, 0.4922, 0.6133, -0...</td>\n",
              "      <td>[-0.6875, -0.02148, -1.32, 0.4805, 0.785, -0.4...</td>\n",
              "      <td>[-0.2812, 0.1963, -1.086, 0.5625, 1.156, 0.212...</td>\n",
              "      <td>[-0.295, -0.3535, -0.1133, 0.832, 0.6484, 0.87...</td>\n",
              "      <td>[-0.416, 0.08203, 0.2041, 1.148, -0.7344, 1.64...</td>\n",
              "      <td>[-1.242, 0.1807, 0.001953, 0.922, -0.7305, 1.0...</td>\n",
              "      <td>[-0.7266, 0.252, 0.3926, 0.9883, 0.12256, 1.73...</td>\n",
              "      <td>[-2.062, 0.1719, -0.84, 1.453, -0.05566, 1.141...</td>\n",
              "      <td>[-1.594, 0.1816, -0.375, 1.93, 0.707, 2.25, -0...</td>\n",
              "      <td>[-1.852, 1.344, 0.2227, 3.625, 1.352, 1.961, -...</td>\n",
              "      <td>[-3.781, 3.031, -0.922, 6.062, 3.938, 5.75, -3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.2637, -1.844, 0.461, 1.148, -0.1118, -2.36,...</td>\n",
              "      <td>[-0.332, -0.625, 0.1309, -0.3008, 0.10254, 0.5...</td>\n",
              "      <td>[0.2754, -0.547, 0.664, -0.5117, 0.742, 0.1426...</td>\n",
              "      <td>[0.582, -0.2695, -0.1855, 0.03516, 0.2344, 0.3...</td>\n",
              "      <td>[-0.1348, -0.05664, 0.547, 0.007812, -0.2793, ...</td>\n",
              "      <td>[-0.3027, -0.8203, 0.10156, -0.1846, -0.463, 0...</td>\n",
              "      <td>[0.03125, -0.5625, 0.9062, 0.2578, -1.547, 1.2...</td>\n",
              "      <td>[-0.1118, -0.2012, -1.023, -0.0503, -1.305, 0....</td>\n",
              "      <td>[2.094, -2.11, -0.4883, -0.4648, -1.969, 0.277...</td>\n",
              "      <td>[1.398, -1.094, -0.461, -1.039, -1.852, 0.5, 0...</td>\n",
              "      <td>[2.062, -1.133, 0.8945, 0.338, -1.219, 2.14, 1...</td>\n",
              "      <td>[2.719, -0.02344, 2.562, 0.7227, -1.281, 1.594...</td>\n",
              "      <td>[4.844, 0.2119, 5.812, -2.188, -1.734, 4.78, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[3.375, 1.844, -0.4805, 1.352, 0.879, -0.828, ...</td>\n",
              "      <td>[0.0801, 0.914, -0.9414, 0.746, 1.344, -0.248,...</td>\n",
              "      <td>[-0.629, 0.4023, -0.75, 0.914, 1.766, -0.1357,...</td>\n",
              "      <td>[-1.0625, 0.2637, -0.9805, 0.953, 1.734, 0.554...</td>\n",
              "      <td>[-0.2578, 0.6094, -1.5625, 1.141, 2.14, 0.2461...</td>\n",
              "      <td>[-0.2969, -0.03906, -1.477, 0.9805, 1.609, 1.2...</td>\n",
              "      <td>[0.7773, 0.7188, 0.535, 1.297, 1.5625, 0.8164,...</td>\n",
              "      <td>[0.703, -0.01758, 0.582, 1.078, 1.531, 1.844, ...</td>\n",
              "      <td>[1.828, -1.117, 1.484, 1.117, 1.695, 2.156, 0....</td>\n",
              "      <td>[1.375, -0.5117, 0.2734, 1.0, 2.25, 1.867, -0....</td>\n",
              "      <td>[2.89, -0.633, 1.133, 0.8945, 2.734, 3.0, -0.3...</td>\n",
              "      <td>[1.3125, -0.5312, 2.281, 2.766, 2.625, 2.031, ...</td>\n",
              "      <td>[3.25, -2.328, 2.344, 3.734, 5.406, 4.125, -2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204572</th>\n",
              "      <td>on</td>\n",
              "      <td>12543</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>[2.406, -0.1719, -0.4883, 1.883, -1.18, -1.047...</td>\n",
              "      <td>[1.078, 0.2275, -0.371, 0.832, -1.828, 0.2178,...</td>\n",
              "      <td>[0.7656, 0.699, -0.06445, 0.9375, -1.375, 0.25...</td>\n",
              "      <td>[0.2617, 0.3535, -0.582, 0.6094, -0.9336, 0.08...</td>\n",
              "      <td>[0.4883, -0.3867, -0.2451, 0.2461, -1.578, -0....</td>\n",
              "      <td>[0.8516, 0.01172, -1.07, -0.295, -1.469, 0.085...</td>\n",
              "      <td>[1.125, -0.05396, -1.703, -0.252, -1.766, 0.13...</td>\n",
              "      <td>[1.766, -0.3242, -0.4062, -0.6055, -1.898, 0.1...</td>\n",
              "      <td>[1.031, -0.414, -1.539, -1.297, -1.992, 0.3457...</td>\n",
              "      <td>[1.203, -1.406, -1.898, -0.6094, -2.938, -0.90...</td>\n",
              "      <td>[1.891, -1.0625, -0.4805, -0.2812, -2.344, -1....</td>\n",
              "      <td>[0.875, -0.1484, -0.8594, 0.252, -3.047, -1.95...</td>\n",
              "      <td>[-0.2227, -0.8047, -3.89, -2.39, -6.594, -3.73...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204573</th>\n",
              "      <td>my</td>\n",
              "      <td>12543</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>[1.672, -0.3672, 1.867, -0.3594, -0.5312, -0.9...</td>\n",
              "      <td>[-0.797, 0.1865, 1.133, -0.8438, -0.539, -0.37...</td>\n",
              "      <td>[-0.2793, 0.578, 0.2266, -0.414, -0.04102, -0....</td>\n",
              "      <td>[-0.127, 0.3652, -0.3105, 0.01855, -1.109, -0....</td>\n",
              "      <td>[-0.11914, -0.4375, -1.406, 0.1943, -1.195, 0....</td>\n",
              "      <td>[1.297, -0.0547, -1.195, -0.33, -0.867, 0.1992...</td>\n",
              "      <td>[0.414, -0.07324, -0.3828, 0.4219, -0.4883, 0....</td>\n",
              "      <td>[0.578, -0.3438, -0.699, 0.1001, -1.094, -0.48...</td>\n",
              "      <td>[1.07, -0.377, -1.867, -0.992, -1.719, -0.2344...</td>\n",
              "      <td>[1.4375, -1.0, -3.156, -0.3125, -2.469, -1.539...</td>\n",
              "      <td>[1.703, 0.2617, -1.75, 0.59, -2.25, -0.1875, -...</td>\n",
              "      <td>[0.2812, 0.1562, -2.625, 2.031, -2.406, -0.621...</td>\n",
              "      <td>[0.2715, -0.2285, -5.438, 3.047, -4.562, -0.60...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204574</th>\n",
              "      <td>car</td>\n",
              "      <td>12543</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>[3.156, -0.535, 0.1396, 1.414, -0.9023, 0.1001...</td>\n",
              "      <td>[0.4453, 0.375, -0.1895, 0.629, -0.496, 0.8516...</td>\n",
              "      <td>[0.711, 0.4727, 0.3945, 0.703, -0.1914, -0.261...</td>\n",
              "      <td>[0.7734, 0.2656, -0.3848, 0.1562, 0.289, -0.45...</td>\n",
              "      <td>[0.9688, -1.031, -1.672, -0.336, -0.6016, -0.2...</td>\n",
              "      <td>[0.871, -1.242, -1.031, -0.4023, -0.5586, 0.47...</td>\n",
              "      <td>[0.742, -0.8203, -1.836, 0.00879, -1.031, 0.79...</td>\n",
              "      <td>[0.208, -0.742, -2.156, 0.05664, -1.273, 0.926...</td>\n",
              "      <td>[0.1914, -0.883, -2.312, -0.169, -1.25, 0.2617...</td>\n",
              "      <td>[-0.789, -1.531, -1.547, 0.2656, -1.25, -0.644...</td>\n",
              "      <td>[-0.4883, -1.125, -1.422, 0.6094, -1.664, 0.38...</td>\n",
              "      <td>[-0.7266, -1.281, -1.969, 1.6875, -1.492, 0.17...</td>\n",
              "      <td>[-2.234, -1.82, -3.61, 0.785, -2.75, 0.336, -7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204575</th>\n",
              "      <td>)</td>\n",
              "      <td>12543</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>[0.293, 0.8867, 1.211, 1.555, -0.3984, -2.672,...</td>\n",
              "      <td>[-1.125, 1.328, 0.3438, 0.4082, -0.461, 0.414,...</td>\n",
              "      <td>[-1.102, 0.582, 0.754, 0.2178, 0.1758, 0.10205...</td>\n",
              "      <td>[-0.6016, -0.6836, -0.3008, 0.3672, -0.03906, ...</td>\n",
              "      <td>[-0.1465, -1.195, -0.10547, -0.4941, 0.04883, ...</td>\n",
              "      <td>[-0.01758, -1.359, 0.07227, -0.7812, -0.3906, ...</td>\n",
              "      <td>[-0.668, -0.953, 0.6016, -1.023, -0.539, -0.30...</td>\n",
              "      <td>[0.3438, -1.664, -0.504, -1.102, -0.3438, -0.3...</td>\n",
              "      <td>[0.789, -1.422, -1.398, -2.203, -0.703, -0.425...</td>\n",
              "      <td>[0.6484, -1.242, -2.234, -2.203, -1.578, -1.34...</td>\n",
              "      <td>[0.2734, -1.914, -0.9805, -2.484, -0.2656, -0....</td>\n",
              "      <td>[-0.3027, -2.25, -0.8906, -2.766, -0.6094, -1....</td>\n",
              "      <td>[-1.781, -6.375, -4.062, -8.44, -1.43, -2.188,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204576</th>\n",
              "      <td>.</td>\n",
              "      <td>12543</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.3906, 0.1377, -0.09375, 1.672, -0.377, -2.6...</td>\n",
              "      <td>[-0.547, 0.617, -0.2051, -0.01563, 0.10254, 0....</td>\n",
              "      <td>[-0.7656, 0.375, 0.0674, -0.1816, 0.703, -0.07...</td>\n",
              "      <td>[-0.1641, 0.10693, -0.4805, -0.455, -0.1719, -...</td>\n",
              "      <td>[0.5938, -0.4707, -0.2236, -0.4883, -0.0742, -...</td>\n",
              "      <td>[0.2715, -1.258, 0.05566, -0.953, -0.4277, -1....</td>\n",
              "      <td>[-0.02527, -0.10596, -1.352, -1.258, -0.1113, ...</td>\n",
              "      <td>[-0.6836, -1.203, -0.7773, -1.344, -0.1914, -0...</td>\n",
              "      <td>[-0.4492, -1.281, -2.938, -2.969, -0.1377, -0....</td>\n",
              "      <td>[-0.4512, -0.4414, -3.875, -3.625, -1.031, -1....</td>\n",
              "      <td>[0.9805, -0.836, -3.734, -4.0, 0.3828, -1.219,...</td>\n",
              "      <td>[0.1465, -0.828, -2.938, -4.844, -0.2812, -4.3...</td>\n",
              "      <td>[0.961, -1.9375, -7.656, -10.25, -0.252, -5.47...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204577 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5caf7cc2-0395-43cc-b5dd-f141e6f986aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5caf7cc2-0395-43cc-b5dd-f141e6f986aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5caf7cc2-0395-43cc-b5dd-f141e6f986aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           words  sentence_id  upos_tag  ct_upos_tag  \\\n",
              "0             Al            0         0            1   \n",
              "1              -            0         1           12   \n",
              "2          Zaman            0         0            8   \n",
              "3              :            0         1            5   \n",
              "4       American            0         2            0   \n",
              "...          ...          ...       ...          ...   \n",
              "204572        on        12543         6           13   \n",
              "204573        my        12543         8           15   \n",
              "204574       car        12543         3           11   \n",
              "204575         )        12543         1           12   \n",
              "204576         .        12543         1           10   \n",
              "\n",
              "                                          encoder_layer_1  \\\n",
              "0       [1.953, -0.1245, -1.445, 0.2197, -0.1729, -0.3...   \n",
              "1       [0.664, -0.10254, 0.001694, 0.5156, -0.801, -3...   \n",
              "2       [3.438, 0.1245, -1.836, 1.141, 0.8984, -1.547,...   \n",
              "3       [0.2637, -1.844, 0.461, 1.148, -0.1118, -2.36,...   \n",
              "4       [3.375, 1.844, -0.4805, 1.352, 0.879, -0.828, ...   \n",
              "...                                                   ...   \n",
              "204572  [2.406, -0.1719, -0.4883, 1.883, -1.18, -1.047...   \n",
              "204573  [1.672, -0.3672, 1.867, -0.3594, -0.5312, -0.9...   \n",
              "204574  [3.156, -0.535, 0.1396, 1.414, -0.9023, 0.1001...   \n",
              "204575  [0.293, 0.8867, 1.211, 1.555, -0.3984, -2.672,...   \n",
              "204576  [0.3906, 0.1377, -0.09375, 1.672, -0.377, -2.6...   \n",
              "\n",
              "                                          encoder_layer_2  \\\n",
              "0       [-0.08594, 0.293, -1.25, -1.5, 0.1885, 1.391, ...   \n",
              "1       [-0.707, 0.6875, -0.0498, -0.6367, -0.875, 0.1...   \n",
              "2       [-0.1777, 0.4453, -1.5625, 0.02734, 0.5625, -0...   \n",
              "3       [-0.332, -0.625, 0.1309, -0.3008, 0.10254, 0.5...   \n",
              "4       [0.0801, 0.914, -0.9414, 0.746, 1.344, -0.248,...   \n",
              "...                                                   ...   \n",
              "204572  [1.078, 0.2275, -0.371, 0.832, -1.828, 0.2178,...   \n",
              "204573  [-0.797, 0.1865, 1.133, -0.8438, -0.539, -0.37...   \n",
              "204574  [0.4453, 0.375, -0.1895, 0.629, -0.496, 0.8516...   \n",
              "204575  [-1.125, 1.328, 0.3438, 0.4082, -0.461, 0.414,...   \n",
              "204576  [-0.547, 0.617, -0.2051, -0.01563, 0.10254, 0....   \n",
              "\n",
              "                                          encoder_layer_3  \\\n",
              "0       [-0.01074, -0.01807, -0.6875, -0.7812, 0.8555,...   \n",
              "1       [-0.801, 0.5547, 0.01758, -0.1855, -0.3242, 0....   \n",
              "2       [-0.4102, -0.4414, -0.9297, 0.4922, 0.6133, -0...   \n",
              "3       [0.2754, -0.547, 0.664, -0.5117, 0.742, 0.1426...   \n",
              "4       [-0.629, 0.4023, -0.75, 0.914, 1.766, -0.1357,...   \n",
              "...                                                   ...   \n",
              "204572  [0.7656, 0.699, -0.06445, 0.9375, -1.375, 0.25...   \n",
              "204573  [-0.2793, 0.578, 0.2266, -0.414, -0.04102, -0....   \n",
              "204574  [0.711, 0.4727, 0.3945, 0.703, -0.1914, -0.261...   \n",
              "204575  [-1.102, 0.582, 0.754, 0.2178, 0.1758, 0.10205...   \n",
              "204576  [-0.7656, 0.375, 0.0674, -0.1816, 0.703, -0.07...   \n",
              "\n",
              "                                          encoder_layer_4  \\\n",
              "0       [-0.4297, 0.3672, -0.9336, -0.539, 0.9297, 1.2...   \n",
              "1       [-0.3984, 0.4707, -0.3965, -0.25, 0.4453, -0.6...   \n",
              "2       [-0.6875, -0.02148, -1.32, 0.4805, 0.785, -0.4...   \n",
              "3       [0.582, -0.2695, -0.1855, 0.03516, 0.2344, 0.3...   \n",
              "4       [-1.0625, 0.2637, -0.9805, 0.953, 1.734, 0.554...   \n",
              "...                                                   ...   \n",
              "204572  [0.2617, 0.3535, -0.582, 0.6094, -0.9336, 0.08...   \n",
              "204573  [-0.127, 0.3652, -0.3105, 0.01855, -1.109, -0....   \n",
              "204574  [0.7734, 0.2656, -0.3848, 0.1562, 0.289, -0.45...   \n",
              "204575  [-0.6016, -0.6836, -0.3008, 0.3672, -0.03906, ...   \n",
              "204576  [-0.1641, 0.10693, -0.4805, -0.455, -0.1719, -...   \n",
              "\n",
              "                                          encoder_layer_5  \\\n",
              "0       [-0.2656, 0.6797, -0.6367, -0.578, 1.266, 1.46...   \n",
              "1       [-1.156, 1.453, -0.05273, -0.6133, 0.6484, -0....   \n",
              "2       [-0.2812, 0.1963, -1.086, 0.5625, 1.156, 0.212...   \n",
              "3       [-0.1348, -0.05664, 0.547, 0.007812, -0.2793, ...   \n",
              "4       [-0.2578, 0.6094, -1.5625, 1.141, 2.14, 0.2461...   \n",
              "...                                                   ...   \n",
              "204572  [0.4883, -0.3867, -0.2451, 0.2461, -1.578, -0....   \n",
              "204573  [-0.11914, -0.4375, -1.406, 0.1943, -1.195, 0....   \n",
              "204574  [0.9688, -1.031, -1.672, -0.336, -0.6016, -0.2...   \n",
              "204575  [-0.1465, -1.195, -0.10547, -0.4941, 0.04883, ...   \n",
              "204576  [0.5938, -0.4707, -0.2236, -0.4883, -0.0742, -...   \n",
              "\n",
              "                                          encoder_layer_6  \\\n",
              "0       [-1.0, 0.3984, 0.04004, -0.1738, 1.516, 1.242,...   \n",
              "1       [-1.305, 1.227, 0.59, -0.459, 1.0625, -0.4766,...   \n",
              "2       [-0.295, -0.3535, -0.1133, 0.832, 0.6484, 0.87...   \n",
              "3       [-0.3027, -0.8203, 0.10156, -0.1846, -0.463, 0...   \n",
              "4       [-0.2969, -0.03906, -1.477, 0.9805, 1.609, 1.2...   \n",
              "...                                                   ...   \n",
              "204572  [0.8516, 0.01172, -1.07, -0.295, -1.469, 0.085...   \n",
              "204573  [1.297, -0.0547, -1.195, -0.33, -0.867, 0.1992...   \n",
              "204574  [0.871, -1.242, -1.031, -0.4023, -0.5586, 0.47...   \n",
              "204575  [-0.01758, -1.359, 0.07227, -0.7812, -0.3906, ...   \n",
              "204576  [0.2715, -1.258, 0.05566, -0.953, -0.4277, -1....   \n",
              "\n",
              "                                          encoder_layer_7  \\\n",
              "0       [-0.6797, 0.4727, 0.7773, 0.4727, 0.9766, 1.62...   \n",
              "1       [-1.969, 0.832, 0.9414, -1.6875, 1.352, 0.4941...   \n",
              "2       [-0.416, 0.08203, 0.2041, 1.148, -0.7344, 1.64...   \n",
              "3       [0.03125, -0.5625, 0.9062, 0.2578, -1.547, 1.2...   \n",
              "4       [0.7773, 0.7188, 0.535, 1.297, 1.5625, 0.8164,...   \n",
              "...                                                   ...   \n",
              "204572  [1.125, -0.05396, -1.703, -0.252, -1.766, 0.13...   \n",
              "204573  [0.414, -0.07324, -0.3828, 0.4219, -0.4883, 0....   \n",
              "204574  [0.742, -0.8203, -1.836, 0.00879, -1.031, 0.79...   \n",
              "204575  [-0.668, -0.953, 0.6016, -1.023, -0.539, -0.30...   \n",
              "204576  [-0.02527, -0.10596, -1.352, -1.258, -0.1113, ...   \n",
              "\n",
              "                                          encoder_layer_8  \\\n",
              "0       [-1.008, 0.8633, -0.02344, 0.617, 0.914, 1.406...   \n",
              "1       [-1.422, 0.5586, 1.016, -0.836, 0.4883, -2.0, ...   \n",
              "2       [-1.242, 0.1807, 0.001953, 0.922, -0.7305, 1.0...   \n",
              "3       [-0.1118, -0.2012, -1.023, -0.0503, -1.305, 0....   \n",
              "4       [0.703, -0.01758, 0.582, 1.078, 1.531, 1.844, ...   \n",
              "...                                                   ...   \n",
              "204572  [1.766, -0.3242, -0.4062, -0.6055, -1.898, 0.1...   \n",
              "204573  [0.578, -0.3438, -0.699, 0.1001, -1.094, -0.48...   \n",
              "204574  [0.208, -0.742, -2.156, 0.05664, -1.273, 0.926...   \n",
              "204575  [0.3438, -1.664, -0.504, -1.102, -0.3438, -0.3...   \n",
              "204576  [-0.6836, -1.203, -0.7773, -1.344, -0.1914, -0...   \n",
              "\n",
              "                                          encoder_layer_9  \\\n",
              "0       [-0.5156, 0.0957, -0.8047, -0.629, 1.906, 2.15...   \n",
              "1       [-1.0625, 3.078, -2.0, -1.18, 0.2031, -0.02344...   \n",
              "2       [-0.7266, 0.252, 0.3926, 0.9883, 0.12256, 1.73...   \n",
              "3       [2.094, -2.11, -0.4883, -0.4648, -1.969, 0.277...   \n",
              "4       [1.828, -1.117, 1.484, 1.117, 1.695, 2.156, 0....   \n",
              "...                                                   ...   \n",
              "204572  [1.031, -0.414, -1.539, -1.297, -1.992, 0.3457...   \n",
              "204573  [1.07, -0.377, -1.867, -0.992, -1.719, -0.2344...   \n",
              "204574  [0.1914, -0.883, -2.312, -0.169, -1.25, 0.2617...   \n",
              "204575  [0.789, -1.422, -1.398, -2.203, -0.703, -0.425...   \n",
              "204576  [-0.4492, -1.281, -2.938, -2.969, -0.1377, -0....   \n",
              "\n",
              "                                         encoder_layer_10  \\\n",
              "0       [-2.062, 0.02734, -1.156, -0.6953, 1.625, 2.29...   \n",
              "1       [0.04688, 1.953, -1.32, -1.594, 0.2441, 1.961,...   \n",
              "2       [-2.062, 0.1719, -0.84, 1.453, -0.05566, 1.141...   \n",
              "3       [1.398, -1.094, -0.461, -1.039, -1.852, 0.5, 0...   \n",
              "4       [1.375, -0.5117, 0.2734, 1.0, 2.25, 1.867, -0....   \n",
              "...                                                   ...   \n",
              "204572  [1.203, -1.406, -1.898, -0.6094, -2.938, -0.90...   \n",
              "204573  [1.4375, -1.0, -3.156, -0.3125, -2.469, -1.539...   \n",
              "204574  [-0.789, -1.531, -1.547, 0.2656, -1.25, -0.644...   \n",
              "204575  [0.6484, -1.242, -2.234, -2.203, -1.578, -1.34...   \n",
              "204576  [-0.4512, -0.4414, -3.875, -3.625, -1.031, -1....   \n",
              "\n",
              "                                         encoder_layer_11  \\\n",
              "0       [-1.453, 0.1357, -0.547, -0.5625, 2.25, 3.11, ...   \n",
              "1       [2.078, 3.5, 0.4414, -1.773, -1.508, 1.445, 0....   \n",
              "2       [-1.594, 0.1816, -0.375, 1.93, 0.707, 2.25, -0...   \n",
              "3       [2.062, -1.133, 0.8945, 0.338, -1.219, 2.14, 1...   \n",
              "4       [2.89, -0.633, 1.133, 0.8945, 2.734, 3.0, -0.3...   \n",
              "...                                                   ...   \n",
              "204572  [1.891, -1.0625, -0.4805, -0.2812, -2.344, -1....   \n",
              "204573  [1.703, 0.2617, -1.75, 0.59, -2.25, -0.1875, -...   \n",
              "204574  [-0.4883, -1.125, -1.422, 0.6094, -1.664, 0.38...   \n",
              "204575  [0.2734, -1.914, -0.9805, -2.484, -0.2656, -0....   \n",
              "204576  [0.9805, -0.836, -3.734, -4.0, 0.3828, -1.219,...   \n",
              "\n",
              "                                         encoder_layer_12  \\\n",
              "0       [-2.156, 1.406, -0.3574, 0.715, 2.766, 2.797, ...   \n",
              "1       [4.688, 5.28, 3.344, -0.6367, -5.97, 2.89, -1....   \n",
              "2       [-1.852, 1.344, 0.2227, 3.625, 1.352, 1.961, -...   \n",
              "3       [2.719, -0.02344, 2.562, 0.7227, -1.281, 1.594...   \n",
              "4       [1.3125, -0.5312, 2.281, 2.766, 2.625, 2.031, ...   \n",
              "...                                                   ...   \n",
              "204572  [0.875, -0.1484, -0.8594, 0.252, -3.047, -1.95...   \n",
              "204573  [0.2812, 0.1562, -2.625, 2.031, -2.406, -0.621...   \n",
              "204574  [-0.7266, -1.281, -1.969, 1.6875, -1.492, 0.17...   \n",
              "204575  [-0.3027, -2.25, -0.8906, -2.766, -0.6094, -1....   \n",
              "204576  [0.1465, -0.828, -2.938, -4.844, -0.2812, -4.3...   \n",
              "\n",
              "                                         encoder_layer_13  \n",
              "0       [-3.922, 2.219, -1.922, -2.25, 7.562, 5.78, -3...  \n",
              "1       [4.094, 2.594, 1.25, -0.3145, -4.094, 2.64, -0...  \n",
              "2       [-3.781, 3.031, -0.922, 6.062, 3.938, 5.75, -3...  \n",
              "3       [4.844, 0.2119, 5.812, -2.188, -1.734, 4.78, 2...  \n",
              "4       [3.25, -2.328, 2.344, 3.734, 5.406, 4.125, -2....  \n",
              "...                                                   ...  \n",
              "204572  [-0.2227, -0.8047, -3.89, -2.39, -6.594, -3.73...  \n",
              "204573  [0.2715, -0.2285, -5.438, 3.047, -4.562, -0.60...  \n",
              "204574  [-2.234, -1.82, -3.61, 0.785, -2.75, 0.336, -7...  \n",
              "204575  [-1.781, -6.375, -4.062, -8.44, -1.43, -2.188,...  \n",
              "204576  [0.961, -1.9375, -7.656, -10.25, -0.252, -5.47...  \n",
              "\n",
              "[204577 rows x 17 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_representation_df = get_word_representation_df(model_b, tokenizer_b, token_ewt_df, 32)\n",
        "token_ewt_df=pd.concat([token_ewt_df, token_representation_df], axis=1)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSmHCgrtRs8"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK5HwVd8tRs8"
      },
      "outputs": [],
      "source": [
        "token_representation_df_2b = get_word_representation_df(model_2b, tokenizer_2b, token_ewt_df, 8)\n",
        "token_ewt_df_2b=pd.concat([token_ewt_df, token_representation_df_2b], axis=1)\n",
        "token_ewt_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfyDPIb1Xul"
      },
      "source": [
        "### previous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NeLhbgoHE2B"
      },
      "source": [
        "now let's define the function to get each token representation.\n",
        "\n",
        "First let's understand how the tokenizer works and how to adapt the tokenizer tokens with the dataset tokens (token at word level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oUGttIV6RRsG",
        "outputId": "55b79762-27b7-4a44-c141-573256f7710f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence word:  ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.']\n",
            "Tokens from the tokenizer:  ['Al', '-', 'Z', 'aman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Q', 'aim', ',', 'near', 'the', 'Syrian', 'border', '.']\n",
            "Tokens different from the original sentence:  ['Z', 'aman', 'Q', 'aim']\n",
            "{0: ['Al'], 1: ['-'], 2: ['Z', 'aman'], 3: [':'], 4: ['American'], 5: ['forces'], 6: ['killed'], 7: ['Shaikh'], 8: ['Abdullah'], 9: ['al'], 10: ['-'], 11: ['Ani'], 12: [','], 13: ['the'], 14: ['preacher'], 15: ['at'], 16: ['the'], 17: ['mosque'], 18: ['in'], 19: ['the'], 20: ['town'], 21: ['of'], 22: ['Q', 'aim'], 23: [','], 24: ['near'], 25: ['the'], 26: ['Syrian'], 27: ['border'], 28: ['.']}\n"
          ]
        }
      ],
      "source": [
        "sentence_id = 0\n",
        "text = ewt_df['text'][sentence_id]\n",
        "words = token_ewt_df[token_ewt_df['sentence_id']==sentence_id]['words'].to_list()\n",
        "\n",
        "inputs = tokenizer_b(text, return_tensors=\"pt\").to(model_b.device)\n",
        "tokens = [t.replace('▁','') for t in tokenizer_b.convert_ids_to_tokens(inputs.input_ids[0])]\n",
        "\n",
        "# this dictionary will contain an index and a list of sub tokens that compose the word\n",
        "subtoken_dict = {i:[] for i in range(len(words))}\n",
        "wt_count=0\n",
        "subword=''\n",
        "for i in range(len(tokens)):\n",
        "  if subword+tokens[i] == words[wt_count]:\n",
        "    subtoken_dict[wt_count].append(tokens[i])\n",
        "    wt_count+=1\n",
        "    subword=''\n",
        "  else:\n",
        "    subtoken_dict[wt_count].append(tokens[i])\n",
        "    subword=subword+tokens[i]\n",
        "\n",
        "print(subtoken_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx7y9yA5nzPe"
      },
      "source": [
        "defining a function to handle this behaviour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sw1MqZ0nyqA"
      },
      "outputs": [],
      "source": [
        "def get_subtokenization(sentence_id, tokenizer):\n",
        "\n",
        "    text = ewt_df['text'][sentence_id]\n",
        "    word_tokens = token_ewt_df[token_ewt_df['sentence_id']==sentence_id]['words'].tolist()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model_b.device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
        "    tokens = [t.replace(\"▁\", \"\") for t in tokens]\n",
        "    subtoken_dict = {i: [] for i in range(len(word_tokens))}\n",
        "\n",
        "    wt_count = 0\n",
        "    subword = \"\"\n",
        "\n",
        "    for tok in tokens:\n",
        "        if wt_count >= len(word_tokens):\n",
        "            break\n",
        "\n",
        "        target = word_tokens[wt_count]\n",
        "\n",
        "        subtoken_dict[wt_count].append(tok)\n",
        "        subword += tok\n",
        "\n",
        "        # perfect match -> process next token\n",
        "        if subword == target:\n",
        "            wt_count += 1\n",
        "            subword = \"\"\n",
        "\n",
        "    return subtoken_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHXnlBn3oTXr"
      },
      "source": [
        "let's check if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "luT0KGsgoEmG",
        "outputId": "dc67b9e8-cb05-424a-d3e0-357ed8f0b6d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checking sentences: 100%|██████████| 12544/12544 [00:21<00:00, 586.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Problematic sentences: 1647 (13.13%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_sentences = len(ewt_df)\n",
        "c = 0\n",
        "problematic_indexes = []\n",
        "\n",
        "for i in tqdm(range(num_sentences), desc='Checking sentences'):\n",
        "  subtoken_dict = get_subtokenization(i, tokenizer_b)\n",
        "\n",
        "  sentence_token_check = []\n",
        "\n",
        "  for k,v in subtoken_dict.items():\n",
        "    subtoken_list = ''.join(v)\n",
        "    sentence_token_check.append(subtoken_list)\n",
        "  word_tokens = token_ewt_df[token_ewt_df['sentence_id']==i]['words'].to_list()\n",
        "  if sentence_token_check != word_tokens:\n",
        "    c=c+1 # c is the number of sentences where the subtoken aggregation differs from the 'dataset' tokenization\n",
        "    problematic_indexes.append(i) # sentence to be removed later\n",
        "\n",
        "assert(len(problematic_indexes)==c)\n",
        "print(f'\\nProblematic sentences: {c} ({c/(num_sentences)*100:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkXNPV6RqZ2e"
      },
      "source": [
        "apparentely 1647 out of the 12543 sentences in the dataset have problems with this subtoken aggregation operation.\n",
        "\n",
        "This happens because the tokenizer does not divide some elements, for example \":]\" is kept by the tokenizer where in the dataset these are two tokens \".\" and \"]\".\n",
        "\n",
        "we can consider removing these sentence as the dataset is still big enough for out scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rgNazlEC06G2",
        "outputId": "991930a0-ac4f-4a79-88d7-03aec2f73bd6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "token_ewt_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b43d9364-3614-465c-91db-c6d3138f075b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos</th>\n",
              "      <th>token_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162434</th>\n",
              "      <td>be</td>\n",
              "      <td>10896</td>\n",
              "      <td>AUX</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162435</th>\n",
              "      <td>a</td>\n",
              "      <td>10896</td>\n",
              "      <td>DET</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162436</th>\n",
              "      <td>huge</td>\n",
              "      <td>10896</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162437</th>\n",
              "      <td>ordeal</td>\n",
              "      <td>10896</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162438</th>\n",
              "      <td>.</td>\n",
              "      <td>10896</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162439 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b43d9364-3614-465c-91db-c6d3138f075b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b43d9364-3614-465c-91db-c6d3138f075b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b43d9364-3614-465c-91db-c6d3138f075b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2bc102a7-e96b-412d-a9ec-3d740480bb28\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2bc102a7-e96b-412d-a9ec-3d740480bb28')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2bc102a7-e96b-412d-a9ec-3d740480bb28 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_df86e1b1-a35e-477a-b150-add84be1456c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('token_ewt_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_df86e1b1-a35e-477a-b150-add84be1456c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('token_ewt_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           words  sentence_id   upos  token_id\n",
              "0             Al            0  PROPN         1\n",
              "1              -            0  PUNCT         2\n",
              "2          Zaman            0  PROPN         3\n",
              "3              :            0  PUNCT         4\n",
              "4       American            0    ADJ         5\n",
              "...          ...          ...    ...       ...\n",
              "162434        be        10896    AUX        19\n",
              "162435         a        10896    DET        20\n",
              "162436      huge        10896    ADJ        21\n",
              "162437    ordeal        10896   NOUN        22\n",
              "162438         .        10896  PUNCT        23\n",
              "\n",
              "[162439 rows x 4 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop these sentences from the original dataset\n",
        "ewt_df.drop(index=problematic_indexes, inplace=True)\n",
        "ewt_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# convert the new dataset in the token version\n",
        "token_ewt_df = convert_ewt_to_token(ewt_df)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdm0gPNlv5sv"
      },
      "source": [
        "finally it's time to get the token representations with the subtoken considerations defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh8aGtk0v-tY",
        "outputId": "d344bf8e-0465-4e31-a2a5-ce363df94f14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17, 17)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fixed index and layer to test\n",
        "index = 0\n",
        "layer = 0\n",
        "\n",
        "sentence = ewt_df['text'][index]\n",
        "inputs = tokenizer_b(sentence, return_tensors=\"pt\").to(model_b.device)\n",
        "\n",
        "model_b.eval()\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model_b(\n",
        "        **inputs,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        output_hidden_states=True,\n",
        "    )\n",
        "\n",
        "encoder_hidden_states = [o.cpu() for o in outputs.encoder_hidden_states]\n",
        "decoder_hidden_states = [o.cpu() for o in outputs.decoder_hidden_states]\n",
        "\n",
        "subtokens = get_subtokenization(index, tokenizer_b)\n",
        "token_representation = []\n",
        "encoder_hidden_states = encoder_hidden_states[layer].squeeze(0)\n",
        "\n",
        "token_index = 0\n",
        "for k,v in subtokens.items():\n",
        "  n = len(v)\n",
        "  if n>1:\n",
        "    mean_tensors_list = []\n",
        "    for i in range(n):\n",
        "      mean_tensors_list.append(encoder_hidden_states[token_index+i])\n",
        "    mean = torch.mean(torch.stack(mean_tensors_list), dim=0)\n",
        "    token_representation.append(mean)\n",
        "  else:\n",
        "    token_representation.append(encoder_hidden_states[token_index])\n",
        "  token_index+=n\n",
        "\n",
        "len(token_representation), len(token_ewt_df[token_ewt_df['sentence_id'] == index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cXkrW4Txund"
      },
      "source": [
        "now let's write a function that can do the previous operation to the whole dataset.\n",
        "\n",
        "using a custom logic (for the subtokens joining) it is easier to keep the function not batched, even if it's not efficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOG36d6o3jBC"
      },
      "outputs": [],
      "source": [
        "def get_word_representation_df(model, tokenizer):\n",
        "  sentences = ewt_df['text'].to_list()\n",
        "  num_encoder_layers = model_b.config.encoder.num_hidden_layers+1 # considering also the embedding layer\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  word_representation_dict = {}\n",
        "  for e in range(num_encoder_layers):\n",
        "    word_representation_dict[f'encoder_layer_{e+1}'] = []\n",
        "\n",
        "  print('Starting to process sentences ...')\n",
        "  for sentence_idx, sentence in tqdm(enumerate(sentences), total=len(sentences), desc='Processing sentences to get word representation'):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(model.device)\n",
        "    start_token_id = tokenizer.bos_token_id\n",
        "    decoder_input_ids = torch.tensor([[start_token_id]], device=model.device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model_b(\n",
        "          **inputs,\n",
        "          decoder_input_ids=decoder_input_ids,\n",
        "          output_hidden_states=True,\n",
        "      )\n",
        "    encoder_hidden_states = torch.stack([e.cpu().squeeze(0) for e in outputs.encoder_hidden_states])\n",
        "\n",
        "    subtokens = get_subtokenization(sentence_idx, tokenizer)\n",
        "    for e in range(num_encoder_layers):\n",
        "        token_representation = word_representation_dict[f'encoder_layer_{e+1}']\n",
        "        ehs = encoder_hidden_states[e]\n",
        "        token_index = 0\n",
        "        for k,v in subtokens.items():\n",
        "          n = len(v)\n",
        "          if n>1:\n",
        "            mean_tensors_list = []\n",
        "            for i in range(n):\n",
        "              mean_tensors_list.append(ehs[token_index+i])\n",
        "            mean = torch.mean(torch.stack(mean_tensors_list), dim=0).to(torch.float32).numpy()\n",
        "            token_representation.append(mean)\n",
        "          else:\n",
        "            token_representation.append(ehs[token_index].to(torch.float32).numpy())\n",
        "          token_index+=n\n",
        "\n",
        "  token_representation_df =pd.DataFrame(word_representation_dict)\n",
        "  print('Sentence processed')\n",
        "  return token_representation_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15wnnA4TtRs-"
      },
      "outputs": [],
      "source": [
        "# new function, not batched\n",
        "\n",
        "def get_word_representation_df(model, tokenizer, df):\n",
        "    sentence_ids = df['sentence_id'].unique()\n",
        "    num_encoder_layers = model.config.encoder.num_hidden_layers + 1\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    word_representation_dict = {f'encoder_layer_{e+1}': [] for e in range(num_encoder_layers)}\n",
        "\n",
        "    for sent_id in tqdm(sentence_ids, desc='Processing sentences'):\n",
        "        words = df[df['sentence_id'] == sent_id]['words'].tolist()\n",
        "        inputs = tokenizer(words, return_tensors=\"pt\", is_split_into_words=True).to(model.device)\n",
        "        start_token_id = tokenizer.bos_token_id\n",
        "        decoder_input_ids = torch.tensor([[start_token_id]], device=model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                **inputs,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "                output_hidden_states=True\n",
        "            )\n",
        "\n",
        "        all_encoder_layers = torch.stack(outputs.encoder_hidden_states).squeeze(1)\n",
        "\n",
        "        word_ids = inputs.word_ids()\n",
        "\n",
        "        for word_idx in range(len(words)):\n",
        "            token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "\n",
        "            if not token_indices:\n",
        "                continue\n",
        "\n",
        "            relevant_vectors = all_encoder_layers[:, token_indices, :]\n",
        "            mean_vectors = torch.mean(relevant_vectors, dim=1)\n",
        "            mean_vectors_np = mean_vectors.cpu().to(torch.float32).numpy()\n",
        "\n",
        "            for layer_idx in range(num_encoder_layers):\n",
        "                word_representation_dict[f'encoder_layer_{layer_idx+1}'].append(mean_vectors_np[layer_idx])\n",
        "\n",
        "    first_key = list(word_representation_dict.keys())[0]\n",
        "    print(f\"Total words processed: {len(word_representation_dict[first_key])}\")\n",
        "\n",
        "    token_representation_df = pd.DataFrame(word_representation_dict)\n",
        "    return token_representation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznUQiL6zOdf"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "nVRDXJHQyDUc",
        "outputId": "6eb684aa-a1a1-4162-999a-63ca33d389ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to process sentences ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing sentences to get word representation:  48%|████▊     | 5260/10897 [08:24<09:00, 10.42it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2406444842.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_representation_ewt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_representation_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtoken_ewt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_ewt_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_representation_ewt_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoken_representation_ewt_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3292309469.py\u001b[0m in \u001b[0;36mget_word_representation_df\u001b[0;34m(model, tokenizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       outputs = model_b(\n\u001b[0m\u001b[1;32m     18\u001b[0m           \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5gemma/modeling_t5gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, decoder_input_ids, decoder_attention_mask, decoder_position_ids, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shift_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         decoder_outputs: Seq2SeqModelOutput = self.model(\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5gemma/modeling_t5gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, decoder_input_ids, decoder_attention_mask, decoder_position_ids, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5gemma/modeling_t5gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, encoder_hidden_states, encoder_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             hidden_states = layer_module(\n\u001b[0m\u001b[1;32m    869\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                 \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapped_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mcollected_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5gemma/modeling_t5gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, position_ids, past_key_values, use_cache, cache_position, encoder_hidden_states, encoder_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         )\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_self_attn_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5gemma/modeling_t5gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Llama does x.to(float16) * w whilst T5Gemma is (x * w).to(float16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# See https://github.com/huggingface/transformers/pull/29402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "token_representation_ewt_df = get_word_representation_df(model_b, tokenizer_b)\n",
        "token_ewt_df = pd.concat([token_ewt_df, token_representation_ewt_df], axis=1)\n",
        "token_representation_ewt_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "J6ZvViST2lqR",
        "outputId": "21b29dd2-9299-471f-ed3b-c3f4c4a33869"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "token_ewt_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4ab7561d-9cae-48f2-8fe2-baae172ba5b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos_tag</th>\n",
              "      <th>ct_upos_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162434</th>\n",
              "      <td>be</td>\n",
              "      <td>10896</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162435</th>\n",
              "      <td>a</td>\n",
              "      <td>10896</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162436</th>\n",
              "      <td>huge</td>\n",
              "      <td>10896</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162437</th>\n",
              "      <td>ordeal</td>\n",
              "      <td>10896</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162438</th>\n",
              "      <td>.</td>\n",
              "      <td>10896</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162439 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ab7561d-9cae-48f2-8fe2-baae172ba5b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ab7561d-9cae-48f2-8fe2-baae172ba5b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ab7561d-9cae-48f2-8fe2-baae172ba5b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e49c9ac8-120c-4792-bfca-4363b8a6bd77\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e49c9ac8-120c-4792-bfca-4363b8a6bd77')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e49c9ac8-120c-4792-bfca-4363b8a6bd77 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e788b10-1de8-405b-9277-b2516b364d6a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('token_ewt_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e788b10-1de8-405b-9277-b2516b364d6a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('token_ewt_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           words  sentence_id  upos_tag  ct_upos_tag\n",
              "0             Al            0         0            2\n",
              "1              -            0         1            7\n",
              "2          Zaman            0         0           13\n",
              "3              :            0         1            2\n",
              "4       American            0         2            3\n",
              "...          ...          ...       ...          ...\n",
              "162434        be        10896         9           11\n",
              "162435         a        10896         5            4\n",
              "162436      huge        10896         2            7\n",
              "162437    ordeal        10896         3            5\n",
              "162438         .        10896         1            1\n",
              "\n",
              "[162439 rows x 4 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X_IWa5grjfQ"
      },
      "source": [
        "## MultiNLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt-BNFOPrkvG"
      },
      "outputs": [],
      "source": [
        "multinli_dataset = load_dataset(\"nyu-mll/multi_nli\") # one of ['train', 'validation_matched', 'validation_mismatched']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDKt17QttRs-",
        "outputId": "1a80e884-6346-4845-b025-55e8c9cebc82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
              "        num_rows: 392702\n",
              "    })\n",
              "    validation_matched: Dataset({\n",
              "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
              "        num_rows: 9815\n",
              "    })\n",
              "    validation_mismatched: Dataset({\n",
              "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
              "        num_rows: 9832\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinli_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek8VE5z3tRs-",
        "outputId": "b9ebf468-1683-45b0-8e4b-63a8fa4fe5ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a0f9c71-9e35-496b-80f4-2662c81d1a12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The new rights are nice enough</td>\n",
              "      <td>Everyone really likes the newest benefits</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This site includes a list of all award winners...</td>\n",
              "      <td>The Government Executive articles housed on th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uh i don't know i i have mixed emotions about ...</td>\n",
              "      <td>I like him for the most part, but would still ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yeah i i think my favorite restaurant is alway...</td>\n",
              "      <td>My favorite restaurants are always at least a ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i don't know um do you do a lot of camping</td>\n",
              "      <td>I know exactly.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>Since 1998, LSC has initiated and overseen sig...</td>\n",
              "      <td>LSC has been focusing on improving it's state ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>Eighty percent of pagers in the United States ...</td>\n",
              "      <td>Pagers in the United States were unaffected by...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>Finally, the FDA will conduct workshops, issue...</td>\n",
              "      <td>The FDA is set to conduct workshops.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>Cirque du Soleil's The latest from the acclaim...</td>\n",
              "      <td>Cirque du Soleil is an international troupe.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>i'll listen  and agree with what i think sound...</td>\n",
              "      <td>I wont even bother listening.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a0f9c71-9e35-496b-80f4-2662c81d1a12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a0f9c71-9e35-496b-80f4-2662c81d1a12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a0f9c71-9e35-496b-80f4-2662c81d1a12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                premise  \\\n",
              "0                        The new rights are nice enough   \n",
              "1     This site includes a list of all award winners...   \n",
              "2     uh i don't know i i have mixed emotions about ...   \n",
              "3     yeah i i think my favorite restaurant is alway...   \n",
              "4            i don't know um do you do a lot of camping   \n",
              "...                                                 ...   \n",
              "9810  Since 1998, LSC has initiated and overseen sig...   \n",
              "9811  Eighty percent of pagers in the United States ...   \n",
              "9812  Finally, the FDA will conduct workshops, issue...   \n",
              "9813  Cirque du Soleil's The latest from the acclaim...   \n",
              "9814  i'll listen  and agree with what i think sound...   \n",
              "\n",
              "                                             hypothesis  label  \n",
              "0            Everyone really likes the newest benefits       1  \n",
              "1     The Government Executive articles housed on th...      2  \n",
              "2     I like him for the most part, but would still ...      0  \n",
              "3     My favorite restaurants are always at least a ...      2  \n",
              "4                                       I know exactly.      2  \n",
              "...                                                 ...    ...  \n",
              "9810  LSC has been focusing on improving it's state ...      1  \n",
              "9811  Pagers in the United States were unaffected by...      2  \n",
              "9812              The FDA is set to conduct workshops.       0  \n",
              "9813       Cirque du Soleil is an international troupe.      0  \n",
              "9814                      I wont even bother listening.      2  \n",
              "\n",
              "[9815 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinli_df = multinli_dataset.to_pandas()\n",
        "multinli_df.drop(columns=['promptID', 'pairID', 'premise_binary_parse', 'premise_parse', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre'], inplace=True)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsNT_6ZtRs-"
      },
      "source": [
        "as shown by [Finetuned Language Models Are Zero-Shot Learners] the model give a better representation if natural language instruction are given\n",
        "\n",
        "that is why here we use the prompt: 'premise: \"{}\", hypothesis: \"{}\"' to get a single sentence, and then use the sentence extraction function as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4UA_ruvtRs-",
        "outputId": "dd4f37e6-7f91-45ce-c536-23f52f349a1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4998aff6-672f-4dd4-8ac0-5daa8616709d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>premise: \"The new rights are nice enough\", hyp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>premise: \"This site includes a list of all awa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>premise: \"uh i don't know i i have mixed emoti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>premise: \"yeah i i think my favorite restauran...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>premise: \"i don't know um do you do a lot of c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>premise: \"Since 1998, LSC has initiated and ov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>premise: \"Eighty percent of pagers in the Unit...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>premise: \"Finally, the FDA will conduct worksh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>premise: \"Cirque du Soleil's The latest from t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>premise: \"i'll listen  and agree with what i t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4998aff6-672f-4dd4-8ac0-5daa8616709d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4998aff6-672f-4dd4-8ac0-5daa8616709d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4998aff6-672f-4dd4-8ac0-5daa8616709d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "0     premise: \"The new rights are nice enough\", hyp...      1\n",
              "1     premise: \"This site includes a list of all awa...      2\n",
              "2     premise: \"uh i don't know i i have mixed emoti...      0\n",
              "3     premise: \"yeah i i think my favorite restauran...      2\n",
              "4     premise: \"i don't know um do you do a lot of c...      2\n",
              "...                                                 ...    ...\n",
              "9810  premise: \"Since 1998, LSC has initiated and ov...      1\n",
              "9811  premise: \"Eighty percent of pagers in the Unit...      2\n",
              "9812  premise: \"Finally, the FDA will conduct worksh...      0\n",
              "9813  premise: \"Cirque du Soleil's The latest from t...      0\n",
              "9814  premise: \"i'll listen  and agree with what i t...      2\n",
              "\n",
              "[9815 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinli_df['sentence'] = multinli_df.apply(lambda row: 'premise: \"{}\", hypothesis: \"{}\"'.format(row['premise'], row['hypothesis']), axis=1)\n",
        "multinli_df.drop(columns=['premise', 'hypothesis'], inplace=True)\n",
        "multinli_df = multinli_df[['sentence', 'label']]\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxthbkR3tRs_"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIafZWy-tRs_",
        "outputId": "ee5b9746-a4e2-4317-cbf6-ab4b88fbcf4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing 9815 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/614 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 614/614 [02:04<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8a080043-4e72-427f-90fe-8d3dcc1d9847\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>encoder_layer_8</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>premise: \"The new rights are nice enough\", hyp...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.3440918, -0.4829834, 0.18120117, 0.5337769,...</td>\n",
              "      <td>[-0.038623046, -0.28076172, -0.029785156, -0.2...</td>\n",
              "      <td>[-0.09682617, -0.46001586, 0.17988892, 0.03776...</td>\n",
              "      <td>[-0.20791015, -0.4625, -0.05102539, 0.02680664...</td>\n",
              "      <td>[-0.16870117, -0.2611328, -0.19262695, 0.21333...</td>\n",
              "      <td>[-0.31350097, -0.124780275, -0.117041014, 0.09...</td>\n",
              "      <td>[0.12875977, -0.47001952, -0.22861329, 0.07890...</td>\n",
              "      <td>[-0.08895264, -0.1234375, -0.44965822, 0.21210...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.390625, 0.31835938, 0.53125, -0.47265...</td>\n",
              "      <td>[-0.9609375, 0.51171875, -0.037109375, 0.80468...</td>\n",
              "      <td>[-1.3046875, 0.036376953, 0.19628906, 0.601562...</td>\n",
              "      <td>[-1.25, 0.55078125, -0.14648438, 0.80078125, -...</td>\n",
              "      <td>[0.0, 0.0859375, 0.076171875, 0.87890625, -1.6...</td>\n",
              "      <td>[-0.1328125, -0.109375, -0.42578125, 1.0859375...</td>\n",
              "      <td>[-0.44921875, -0.26171875, -0.98828125, 0.5546...</td>\n",
              "      <td>[-1.25, -0.19238281, -1.1953125, 0.37695312, -...</td>\n",
              "      <td>[-1.2890625, 0.39648438, -0.33203125, 0.067382...</td>\n",
              "      <td>[-0.5625, -4.125, 0.390625, 0.6328125, -1.3984...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>premise: \"This site includes a list of all awa...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.5604467, -0.26682693, -0.06809645, 0.144312...</td>\n",
              "      <td>[0.06316356, 0.10495543, -0.14130108, -0.38393...</td>\n",
              "      <td>[0.040777743, -0.105669074, 0.055939503, -0.19...</td>\n",
              "      <td>[-0.4938652, -0.17963742, -0.24570563, -0.1655...</td>\n",
              "      <td>[-0.22133069, -0.080391124, 0.028295273, -0.24...</td>\n",
              "      <td>[-0.066021256, -0.17953727, -0.008263221, -0.0...</td>\n",
              "      <td>[0.6902794, -0.40889174, 0.43609777, 0.1479116...</td>\n",
              "      <td>[0.17598157, 0.051832933, 0.11714994, 0.174616...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48828125, 0.40625, 0.2734375, 0.5, -0.4589...</td>\n",
              "      <td>[-0.97265625, 0.53125, -0.09667969, 0.77734375...</td>\n",
              "      <td>[-1.3203125, 0.04345703, 0.13671875, 0.5859375...</td>\n",
              "      <td>[-1.2578125, 0.55859375, -0.20507812, 0.78125,...</td>\n",
              "      <td>[-0.005859375, 0.09277344, 0.03125, 0.8671875,...</td>\n",
              "      <td>[-0.14648438, -0.0859375, -0.44921875, 1.07812...</td>\n",
              "      <td>[-0.47851562, -0.21679688, -0.984375, 0.546875...</td>\n",
              "      <td>[-1.2890625, -0.13378906, -1.1953125, 0.429687...</td>\n",
              "      <td>[-1.359375, 0.53515625, -0.41796875, 0.1162109...</td>\n",
              "      <td>[14.3125, -1.5234375, -7.25, 4.53125, 0.084960...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>premise: \"uh i don't know i i have mixed emoti...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.1634928, -0.27386248, -0.28779885, -0.18302...</td>\n",
              "      <td>[-0.30266204, -0.077627674, -0.15052626, -0.46...</td>\n",
              "      <td>[-0.30654117, -0.2512388, 0.02706344, -0.08175...</td>\n",
              "      <td>[-0.11259404, -0.26548937, 0.088803895, -0.160...</td>\n",
              "      <td>[-0.4701606, -0.3502785, -0.0010262949, -0.280...</td>\n",
              "      <td>[-0.31323242, -0.40512875, 0.22087492, -0.3739...</td>\n",
              "      <td>[-0.102710865, -0.5272714, 0.2502351, 0.216471...</td>\n",
              "      <td>[0.09668873, -0.19750072, -0.035138164, -0.078...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3671875, 0.27929688, 0.5390625, -0.47...</td>\n",
              "      <td>[-0.94921875, 0.49609375, -0.067871094, 0.8046...</td>\n",
              "      <td>[-1.28125, -0.0075683594, 0.18457031, 0.605468...</td>\n",
              "      <td>[-1.2421875, 0.515625, -0.15429688, 0.80078125...</td>\n",
              "      <td>[0.01171875, 0.053710938, 0.087890625, 0.85546...</td>\n",
              "      <td>[-0.12695312, -0.14257812, -0.40234375, 1.0703...</td>\n",
              "      <td>[-0.45117188, -0.29296875, -0.9765625, 0.54296...</td>\n",
              "      <td>[-1.296875, -0.20800781, -1.171875, 0.35742188...</td>\n",
              "      <td>[-1.375, 0.31835938, -0.35546875, -0.12011719,...</td>\n",
              "      <td>[9.3125, -4.1875, -3.75, 3.96875, -0.8125, 3.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>premise: \"yeah i i think my favorite restauran...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.4026008, -0.49008876, 0.16643323, 0.1311140...</td>\n",
              "      <td>[-0.14332715, -0.16933079, -0.0051655015, -0.4...</td>\n",
              "      <td>[0.048697487, -0.32035533, 0.1254069, -0.18978...</td>\n",
              "      <td>[0.008030942, -0.45032382, 0.121952526, -0.140...</td>\n",
              "      <td>[-0.097202234, -0.33512798, -0.14341977, -0.04...</td>\n",
              "      <td>[-0.009714227, -0.46674547, -0.012532552, -0.0...</td>\n",
              "      <td>[0.43797973, -0.71749073, 0.084481224, 0.18203...</td>\n",
              "      <td>[0.3895542, -0.5375548, -0.28306606, 0.1034877...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.50390625, 0.36523438, 0.29882812, 0.527343...</td>\n",
              "      <td>[-0.9609375, 0.5, -0.057617188, 0.796875, -0.9...</td>\n",
              "      <td>[-1.3046875, 0.0048828125, 0.17871094, 0.59375...</td>\n",
              "      <td>[-1.2578125, 0.5234375, -0.18457031, 0.7929687...</td>\n",
              "      <td>[-0.0078125, 0.064453125, 0.044921875, 0.85546...</td>\n",
              "      <td>[-0.15039062, -0.13183594, -0.43359375, 1.0781...</td>\n",
              "      <td>[-0.4921875, -0.27734375, -1.015625, 0.53125, ...</td>\n",
              "      <td>[-1.328125, -0.2265625, -1.21875, 0.38476562, ...</td>\n",
              "      <td>[-1.359375, 0.25390625, -0.31640625, -0.027832...</td>\n",
              "      <td>[6.75, -6.3125, -1.40625, 4.75, -2.84375, 2.28...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>premise: \"i don't know um do you do a lot of c...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.4464926, -0.55497235, 0.014541626, 0.422470...</td>\n",
              "      <td>[-0.07045492, -0.16658528, -0.014038086, -0.46...</td>\n",
              "      <td>[-0.40856934, -0.37390137, 0.036946613, 0.0409...</td>\n",
              "      <td>[-0.29907227, -0.45324707, 0.2931722, -0.20540...</td>\n",
              "      <td>[-0.41174316, -0.4806315, -0.0848287, -0.18937...</td>\n",
              "      <td>[-0.05114746, -0.54500324, 0.005086263, -0.276...</td>\n",
              "      <td>[0.31348673, -0.88102216, -0.5447591, 0.102823...</td>\n",
              "      <td>[0.39134726, -0.2187907, -0.5087077, -0.024698...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48046875, 0.38476562, 0.29882812, 0.523437...</td>\n",
              "      <td>[-0.9375, 0.515625, -0.05126953, 0.78515625, -...</td>\n",
              "      <td>[-1.28125, 0.023925781, 0.19824219, 0.5859375,...</td>\n",
              "      <td>[-1.2265625, 0.54296875, -0.140625, 0.78125, -...</td>\n",
              "      <td>[0.017578125, 0.07128906, 0.083984375, 0.85156...</td>\n",
              "      <td>[-0.11328125, -0.13183594, -0.39453125, 1.0625...</td>\n",
              "      <td>[-0.45117188, -0.27929688, -0.95703125, 0.5312...</td>\n",
              "      <td>[-1.28125, -0.19335938, -1.1796875, 0.33984375...</td>\n",
              "      <td>[-1.296875, 0.37304688, -0.33203125, 0.0048828...</td>\n",
              "      <td>[4.15625, -1.5, -4.03125, 3.53125, -0.7421875,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>premise: \"Since 1998, LSC has initiated and ov...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.5056113, -0.28317988, 0.04054454, 0.4999224...</td>\n",
              "      <td>[0.04932416, -0.08460441, -0.25526258, -0.2153...</td>\n",
              "      <td>[0.038465712, -0.18367513, 0.041992188, -0.162...</td>\n",
              "      <td>[-0.02349563, -0.14353532, -0.05530754, -0.060...</td>\n",
              "      <td>[-0.11866009, -0.05366831, -0.12663148, -0.088...</td>\n",
              "      <td>[0.013253348, -0.35064796, 0.06337581, -0.0350...</td>\n",
              "      <td>[0.58928573, -0.062391493, 0.5281343, -0.11409...</td>\n",
              "      <td>[0.5792721, -0.3576389, 0.5518896, 0.2429703, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.38476562, 0.27734375, 0.5078125, -0.4...</td>\n",
              "      <td>[-0.96875, 0.5078125, -0.087402344, 0.78125, -...</td>\n",
              "      <td>[-1.3203125, 0.021972656, 0.1484375, 0.5742187...</td>\n",
              "      <td>[-1.2578125, 0.54296875, -0.20117188, 0.777343...</td>\n",
              "      <td>[0.009765625, 0.0859375, 0.0546875, 0.84765625...</td>\n",
              "      <td>[-0.13476562, -0.103515625, -0.43359375, 1.078...</td>\n",
              "      <td>[-0.46289062, -0.2421875, -1.0, 0.5625, -1.734...</td>\n",
              "      <td>[-1.2734375, -0.13964844, -1.171875, 0.3867187...</td>\n",
              "      <td>[-1.3203125, 0.41796875, -0.31640625, 0.032226...</td>\n",
              "      <td>[17.0, -1.9765625, -9.0, 2.859375, 0.15625, 3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>premise: \"Eighty percent of pagers in the Unit...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.758714, -0.41865736, -0.16970904, 0.3447641...</td>\n",
              "      <td>[-0.07344251, 0.07429387, -0.23615284, -0.3214...</td>\n",
              "      <td>[-0.17227252, -0.060684595, 0.14529498, -0.144...</td>\n",
              "      <td>[-0.19918118, -0.10386618, -0.012269631, -0.02...</td>\n",
              "      <td>[-0.06853466, -0.27865836, -0.20168519, -0.120...</td>\n",
              "      <td>[0.119290866, -0.1539964, -0.069436096, 0.1305...</td>\n",
              "      <td>[0.7214293, -0.4841684, -0.1459335, 0.5636018,...</td>\n",
              "      <td>[0.6591046, -0.017202524, -0.6033403, 0.510717...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.38867188, 0.3046875, 0.50390625, -0.4...</td>\n",
              "      <td>[-0.953125, 0.51953125, -0.057861328, 0.789062...</td>\n",
              "      <td>[-1.296875, 0.021240234, 0.18945312, 0.5976562...</td>\n",
              "      <td>[-1.2421875, 0.5234375, -0.15429688, 0.796875,...</td>\n",
              "      <td>[0.021484375, 0.0625, 0.072265625, 0.86328125,...</td>\n",
              "      <td>[-0.13671875, -0.13476562, -0.41015625, 1.0703...</td>\n",
              "      <td>[-0.484375, -0.26757812, -0.96484375, 0.539062...</td>\n",
              "      <td>[-1.328125, -0.203125, -1.1484375, 0.40820312,...</td>\n",
              "      <td>[-1.375, 0.390625, -0.29296875, 0.110839844, -...</td>\n",
              "      <td>[15.375, -3.703125, -5.96875, 4.1875, 0.730468...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>premise: \"Finally, the FDA will conduct worksh...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.7182292, 0.04305488, 0.08393283, 0.56455076...</td>\n",
              "      <td>[-0.056857638, 0.23723958, -0.16803385, -0.108...</td>\n",
              "      <td>[-0.08721788, 0.14518772, 0.12886284, 0.056966...</td>\n",
              "      <td>[-0.1820421, 0.027669271, 0.032872178, -0.1383...</td>\n",
              "      <td>[-0.212755, 0.15979004, 0.05808377, -0.2804362...</td>\n",
              "      <td>[-0.113834634, -0.17987196, 0.124338105, -0.26...</td>\n",
              "      <td>[0.3928928, 0.01673177, 0.35110676, -0.3658962...</td>\n",
              "      <td>[0.4287706, 0.2568739, -0.04054362, -0.2427191...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.49023438, 0.38867188, 0.29882812, 0.527343...</td>\n",
              "      <td>[-0.9609375, 0.5078125, -0.05810547, 0.8007812...</td>\n",
              "      <td>[-1.328125, 0.02368164, 0.16699219, 0.6015625,...</td>\n",
              "      <td>[-1.2578125, 0.5390625, -0.17773438, 0.8046875...</td>\n",
              "      <td>[0.0, 0.072265625, 0.06640625, 0.875, -1.66406...</td>\n",
              "      <td>[-0.1484375, -0.104003906, -0.40820312, 1.0859...</td>\n",
              "      <td>[-0.48828125, -0.2265625, -0.9453125, 0.554687...</td>\n",
              "      <td>[-1.296875, -0.15136719, -1.1328125, 0.3886718...</td>\n",
              "      <td>[-1.3125, 0.61328125, -0.37109375, -0.04809570...</td>\n",
              "      <td>[17.5, -2.125, -5.46875, 1.140625, -0.70703125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>premise: \"Cirque du Soleil's The latest from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.797499, -0.3222645, 0.14975315, 0.603753, -...</td>\n",
              "      <td>[0.031078197, -0.07969383, 0.031986944, -0.194...</td>\n",
              "      <td>[-0.06391963, -0.29064038, 0.45882162, -0.0063...</td>\n",
              "      <td>[-0.19576462, -0.27511936, 0.08912037, 0.02525...</td>\n",
              "      <td>[-0.16529225, -0.18569155, -0.04059064, -0.086...</td>\n",
              "      <td>[-0.028880931, -0.14476635, 0.06141493, 0.0710...</td>\n",
              "      <td>[0.34266493, 0.003273293, -0.18654153, 0.16594...</td>\n",
              "      <td>[0.35776547, 0.0059497976, -0.20985696, 0.0511...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.49023438, 0.390625, 0.29492188, 0.5234375,...</td>\n",
              "      <td>[-0.94921875, 0.51171875, -0.07421875, 0.79687...</td>\n",
              "      <td>[-1.3046875, 0.03564453, 0.16601562, 0.5976562...</td>\n",
              "      <td>[-1.2421875, 0.55078125, -0.19824219, 0.796875...</td>\n",
              "      <td>[0.021484375, 0.07421875, 0.029296875, 0.86718...</td>\n",
              "      <td>[-0.122558594, -0.140625, -0.45703125, 1.07812...</td>\n",
              "      <td>[-0.45507812, -0.29296875, -1.015625, 0.542968...</td>\n",
              "      <td>[-1.2890625, -0.2265625, -1.2265625, 0.3886718...</td>\n",
              "      <td>[-1.359375, 0.359375, -0.359375, 0.076171875, ...</td>\n",
              "      <td>[11.625, -2.703125, -2.5, 3.203125, 0.7578125,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>premise: \"i'll listen  and agree with what i t...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.5557016, -0.13872822, -0.15206674, 0.597534...</td>\n",
              "      <td>[-0.20789513, 0.12083083, -0.052358773, -0.055...</td>\n",
              "      <td>[-0.51096755, -0.012657752, 0.025935246, 0.192...</td>\n",
              "      <td>[-0.17982835, -0.11456768, -0.036808893, 0.084...</td>\n",
              "      <td>[-0.30878156, -0.41081354, -0.30163574, -0.060...</td>\n",
              "      <td>[-0.40782753, -0.31197417, -0.044809196, -0.21...</td>\n",
              "      <td>[-0.3765024, -0.5221229, -0.03448017, -0.03526...</td>\n",
              "      <td>[-0.14573318, -0.060960036, -0.29015175, -0.03...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.46875, 0.37695312, 0.3046875, 0.52734375, ...</td>\n",
              "      <td>[-0.9375, 0.5078125, -0.05053711, 0.796875, -0...</td>\n",
              "      <td>[-1.2734375, 0.015136719, 0.20410156, 0.59375,...</td>\n",
              "      <td>[-1.234375, 0.53125, -0.13085938, 0.78125, -1....</td>\n",
              "      <td>[0.005859375, 0.06542969, 0.10546875, 0.839843...</td>\n",
              "      <td>[-0.13183594, -0.13867188, -0.3828125, 1.04687...</td>\n",
              "      <td>[-0.47265625, -0.26757812, -0.9453125, 0.51562...</td>\n",
              "      <td>[-1.2890625, -0.20507812, -1.171875, 0.3417968...</td>\n",
              "      <td>[-1.265625, 0.29296875, -0.265625, 0.03564453,...</td>\n",
              "      <td>[11.3125, -3.234375, -3.34375, 4.5625, -0.4707...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a080043-4e72-427f-90fe-8d3dcc1d9847')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a080043-4e72-427f-90fe-8d3dcc1d9847 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a080043-4e72-427f-90fe-8d3dcc1d9847');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     premise: \"The new rights are nice enough\", hyp...      1   \n",
              "1     premise: \"This site includes a list of all awa...      2   \n",
              "2     premise: \"uh i don't know i i have mixed emoti...      0   \n",
              "3     premise: \"yeah i i think my favorite restauran...      2   \n",
              "4     premise: \"i don't know um do you do a lot of c...      2   \n",
              "...                                                 ...    ...   \n",
              "9810  premise: \"Since 1998, LSC has initiated and ov...      1   \n",
              "9811  premise: \"Eighty percent of pagers in the Unit...      2   \n",
              "9812  premise: \"Finally, the FDA will conduct worksh...      0   \n",
              "9813  premise: \"Cirque du Soleil's The latest from t...      0   \n",
              "9814  premise: \"i'll listen  and agree with what i t...      2   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [1.3440918, -0.4829834, 0.18120117, 0.5337769,...   \n",
              "1     [1.5604467, -0.26682693, -0.06809645, 0.144312...   \n",
              "2     [1.1634928, -0.27386248, -0.28779885, -0.18302...   \n",
              "3     [1.4026008, -0.49008876, 0.16643323, 0.1311140...   \n",
              "4     [1.4464926, -0.55497235, 0.014541626, 0.422470...   \n",
              "...                                                 ...   \n",
              "9810  [1.5056113, -0.28317988, 0.04054454, 0.4999224...   \n",
              "9811  [1.758714, -0.41865736, -0.16970904, 0.3447641...   \n",
              "9812  [1.7182292, 0.04305488, 0.08393283, 0.56455076...   \n",
              "9813  [1.797499, -0.3222645, 0.14975315, 0.603753, -...   \n",
              "9814  [1.5557016, -0.13872822, -0.15206674, 0.597534...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [-0.038623046, -0.28076172, -0.029785156, -0.2...   \n",
              "1     [0.06316356, 0.10495543, -0.14130108, -0.38393...   \n",
              "2     [-0.30266204, -0.077627674, -0.15052626, -0.46...   \n",
              "3     [-0.14332715, -0.16933079, -0.0051655015, -0.4...   \n",
              "4     [-0.07045492, -0.16658528, -0.014038086, -0.46...   \n",
              "...                                                 ...   \n",
              "9810  [0.04932416, -0.08460441, -0.25526258, -0.2153...   \n",
              "9811  [-0.07344251, 0.07429387, -0.23615284, -0.3214...   \n",
              "9812  [-0.056857638, 0.23723958, -0.16803385, -0.108...   \n",
              "9813  [0.031078197, -0.07969383, 0.031986944, -0.194...   \n",
              "9814  [-0.20789513, 0.12083083, -0.052358773, -0.055...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [-0.09682617, -0.46001586, 0.17988892, 0.03776...   \n",
              "1     [0.040777743, -0.105669074, 0.055939503, -0.19...   \n",
              "2     [-0.30654117, -0.2512388, 0.02706344, -0.08175...   \n",
              "3     [0.048697487, -0.32035533, 0.1254069, -0.18978...   \n",
              "4     [-0.40856934, -0.37390137, 0.036946613, 0.0409...   \n",
              "...                                                 ...   \n",
              "9810  [0.038465712, -0.18367513, 0.041992188, -0.162...   \n",
              "9811  [-0.17227252, -0.060684595, 0.14529498, -0.144...   \n",
              "9812  [-0.08721788, 0.14518772, 0.12886284, 0.056966...   \n",
              "9813  [-0.06391963, -0.29064038, 0.45882162, -0.0063...   \n",
              "9814  [-0.51096755, -0.012657752, 0.025935246, 0.192...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.20791015, -0.4625, -0.05102539, 0.02680664...   \n",
              "1     [-0.4938652, -0.17963742, -0.24570563, -0.1655...   \n",
              "2     [-0.11259404, -0.26548937, 0.088803895, -0.160...   \n",
              "3     [0.008030942, -0.45032382, 0.121952526, -0.140...   \n",
              "4     [-0.29907227, -0.45324707, 0.2931722, -0.20540...   \n",
              "...                                                 ...   \n",
              "9810  [-0.02349563, -0.14353532, -0.05530754, -0.060...   \n",
              "9811  [-0.19918118, -0.10386618, -0.012269631, -0.02...   \n",
              "9812  [-0.1820421, 0.027669271, 0.032872178, -0.1383...   \n",
              "9813  [-0.19576462, -0.27511936, 0.08912037, 0.02525...   \n",
              "9814  [-0.17982835, -0.11456768, -0.036808893, 0.084...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.16870117, -0.2611328, -0.19262695, 0.21333...   \n",
              "1     [-0.22133069, -0.080391124, 0.028295273, -0.24...   \n",
              "2     [-0.4701606, -0.3502785, -0.0010262949, -0.280...   \n",
              "3     [-0.097202234, -0.33512798, -0.14341977, -0.04...   \n",
              "4     [-0.41174316, -0.4806315, -0.0848287, -0.18937...   \n",
              "...                                                 ...   \n",
              "9810  [-0.11866009, -0.05366831, -0.12663148, -0.088...   \n",
              "9811  [-0.06853466, -0.27865836, -0.20168519, -0.120...   \n",
              "9812  [-0.212755, 0.15979004, 0.05808377, -0.2804362...   \n",
              "9813  [-0.16529225, -0.18569155, -0.04059064, -0.086...   \n",
              "9814  [-0.30878156, -0.41081354, -0.30163574, -0.060...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [-0.31350097, -0.124780275, -0.117041014, 0.09...   \n",
              "1     [-0.066021256, -0.17953727, -0.008263221, -0.0...   \n",
              "2     [-0.31323242, -0.40512875, 0.22087492, -0.3739...   \n",
              "3     [-0.009714227, -0.46674547, -0.012532552, -0.0...   \n",
              "4     [-0.05114746, -0.54500324, 0.005086263, -0.276...   \n",
              "...                                                 ...   \n",
              "9810  [0.013253348, -0.35064796, 0.06337581, -0.0350...   \n",
              "9811  [0.119290866, -0.1539964, -0.069436096, 0.1305...   \n",
              "9812  [-0.113834634, -0.17987196, 0.124338105, -0.26...   \n",
              "9813  [-0.028880931, -0.14476635, 0.06141493, 0.0710...   \n",
              "9814  [-0.40782753, -0.31197417, -0.044809196, -0.21...   \n",
              "\n",
              "                                        encoder_layer_7  \\\n",
              "0     [0.12875977, -0.47001952, -0.22861329, 0.07890...   \n",
              "1     [0.6902794, -0.40889174, 0.43609777, 0.1479116...   \n",
              "2     [-0.102710865, -0.5272714, 0.2502351, 0.216471...   \n",
              "3     [0.43797973, -0.71749073, 0.084481224, 0.18203...   \n",
              "4     [0.31348673, -0.88102216, -0.5447591, 0.102823...   \n",
              "...                                                 ...   \n",
              "9810  [0.58928573, -0.062391493, 0.5281343, -0.11409...   \n",
              "9811  [0.7214293, -0.4841684, -0.1459335, 0.5636018,...   \n",
              "9812  [0.3928928, 0.01673177, 0.35110676, -0.3658962...   \n",
              "9813  [0.34266493, 0.003273293, -0.18654153, 0.16594...   \n",
              "9814  [-0.3765024, -0.5221229, -0.03448017, -0.03526...   \n",
              "\n",
              "                                        encoder_layer_8  ...  \\\n",
              "0     [-0.08895264, -0.1234375, -0.44965822, 0.21210...  ...   \n",
              "1     [0.17598157, 0.051832933, 0.11714994, 0.174616...  ...   \n",
              "2     [0.09668873, -0.19750072, -0.035138164, -0.078...  ...   \n",
              "3     [0.3895542, -0.5375548, -0.28306606, 0.1034877...  ...   \n",
              "4     [0.39134726, -0.2187907, -0.5087077, -0.024698...  ...   \n",
              "...                                                 ...  ...   \n",
              "9810  [0.5792721, -0.3576389, 0.5518896, 0.2429703, ...  ...   \n",
              "9811  [0.6591046, -0.017202524, -0.6033403, 0.510717...  ...   \n",
              "9812  [0.4287706, 0.2568739, -0.04054362, -0.2427191...  ...   \n",
              "9813  [0.35776547, 0.0059497976, -0.20985696, 0.0511...  ...   \n",
              "9814  [-0.14573318, -0.060960036, -0.29015175, -0.03...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.5, 0.390625, 0.31835938, 0.53125, -0.47265...   \n",
              "1     [-0.48828125, 0.40625, 0.2734375, 0.5, -0.4589...   \n",
              "2     [-0.5, 0.3671875, 0.27929688, 0.5390625, -0.47...   \n",
              "3     [-0.50390625, 0.36523438, 0.29882812, 0.527343...   \n",
              "4     [-0.48046875, 0.38476562, 0.29882812, 0.523437...   \n",
              "...                                                 ...   \n",
              "9810  [-0.5, 0.38476562, 0.27734375, 0.5078125, -0.4...   \n",
              "9811  [-0.5, 0.38867188, 0.3046875, 0.50390625, -0.4...   \n",
              "9812  [-0.49023438, 0.38867188, 0.29882812, 0.527343...   \n",
              "9813  [-0.49023438, 0.390625, 0.29492188, 0.5234375,...   \n",
              "9814  [-0.46875, 0.37695312, 0.3046875, 0.52734375, ...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.9609375, 0.51171875, -0.037109375, 0.80468...   \n",
              "1     [-0.97265625, 0.53125, -0.09667969, 0.77734375...   \n",
              "2     [-0.94921875, 0.49609375, -0.067871094, 0.8046...   \n",
              "3     [-0.9609375, 0.5, -0.057617188, 0.796875, -0.9...   \n",
              "4     [-0.9375, 0.515625, -0.05126953, 0.78515625, -...   \n",
              "...                                                 ...   \n",
              "9810  [-0.96875, 0.5078125, -0.087402344, 0.78125, -...   \n",
              "9811  [-0.953125, 0.51953125, -0.057861328, 0.789062...   \n",
              "9812  [-0.9609375, 0.5078125, -0.05810547, 0.8007812...   \n",
              "9813  [-0.94921875, 0.51171875, -0.07421875, 0.79687...   \n",
              "9814  [-0.9375, 0.5078125, -0.05053711, 0.796875, -0...   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.3046875, 0.036376953, 0.19628906, 0.601562...   \n",
              "1     [-1.3203125, 0.04345703, 0.13671875, 0.5859375...   \n",
              "2     [-1.28125, -0.0075683594, 0.18457031, 0.605468...   \n",
              "3     [-1.3046875, 0.0048828125, 0.17871094, 0.59375...   \n",
              "4     [-1.28125, 0.023925781, 0.19824219, 0.5859375,...   \n",
              "...                                                 ...   \n",
              "9810  [-1.3203125, 0.021972656, 0.1484375, 0.5742187...   \n",
              "9811  [-1.296875, 0.021240234, 0.18945312, 0.5976562...   \n",
              "9812  [-1.328125, 0.02368164, 0.16699219, 0.6015625,...   \n",
              "9813  [-1.3046875, 0.03564453, 0.16601562, 0.5976562...   \n",
              "9814  [-1.2734375, 0.015136719, 0.20410156, 0.59375,...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.25, 0.55078125, -0.14648438, 0.80078125, -...   \n",
              "1     [-1.2578125, 0.55859375, -0.20507812, 0.78125,...   \n",
              "2     [-1.2421875, 0.515625, -0.15429688, 0.80078125...   \n",
              "3     [-1.2578125, 0.5234375, -0.18457031, 0.7929687...   \n",
              "4     [-1.2265625, 0.54296875, -0.140625, 0.78125, -...   \n",
              "...                                                 ...   \n",
              "9810  [-1.2578125, 0.54296875, -0.20117188, 0.777343...   \n",
              "9811  [-1.2421875, 0.5234375, -0.15429688, 0.796875,...   \n",
              "9812  [-1.2578125, 0.5390625, -0.17773438, 0.8046875...   \n",
              "9813  [-1.2421875, 0.55078125, -0.19824219, 0.796875...   \n",
              "9814  [-1.234375, 0.53125, -0.13085938, 0.78125, -1....   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [0.0, 0.0859375, 0.076171875, 0.87890625, -1.6...   \n",
              "1     [-0.005859375, 0.09277344, 0.03125, 0.8671875,...   \n",
              "2     [0.01171875, 0.053710938, 0.087890625, 0.85546...   \n",
              "3     [-0.0078125, 0.064453125, 0.044921875, 0.85546...   \n",
              "4     [0.017578125, 0.07128906, 0.083984375, 0.85156...   \n",
              "...                                                 ...   \n",
              "9810  [0.009765625, 0.0859375, 0.0546875, 0.84765625...   \n",
              "9811  [0.021484375, 0.0625, 0.072265625, 0.86328125,...   \n",
              "9812  [0.0, 0.072265625, 0.06640625, 0.875, -1.66406...   \n",
              "9813  [0.021484375, 0.07421875, 0.029296875, 0.86718...   \n",
              "9814  [0.005859375, 0.06542969, 0.10546875, 0.839843...   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.1328125, -0.109375, -0.42578125, 1.0859375...   \n",
              "1     [-0.14648438, -0.0859375, -0.44921875, 1.07812...   \n",
              "2     [-0.12695312, -0.14257812, -0.40234375, 1.0703...   \n",
              "3     [-0.15039062, -0.13183594, -0.43359375, 1.0781...   \n",
              "4     [-0.11328125, -0.13183594, -0.39453125, 1.0625...   \n",
              "...                                                 ...   \n",
              "9810  [-0.13476562, -0.103515625, -0.43359375, 1.078...   \n",
              "9811  [-0.13671875, -0.13476562, -0.41015625, 1.0703...   \n",
              "9812  [-0.1484375, -0.104003906, -0.40820312, 1.0859...   \n",
              "9813  [-0.122558594, -0.140625, -0.45703125, 1.07812...   \n",
              "9814  [-0.13183594, -0.13867188, -0.3828125, 1.04687...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.44921875, -0.26171875, -0.98828125, 0.5546...   \n",
              "1     [-0.47851562, -0.21679688, -0.984375, 0.546875...   \n",
              "2     [-0.45117188, -0.29296875, -0.9765625, 0.54296...   \n",
              "3     [-0.4921875, -0.27734375, -1.015625, 0.53125, ...   \n",
              "4     [-0.45117188, -0.27929688, -0.95703125, 0.5312...   \n",
              "...                                                 ...   \n",
              "9810  [-0.46289062, -0.2421875, -1.0, 0.5625, -1.734...   \n",
              "9811  [-0.484375, -0.26757812, -0.96484375, 0.539062...   \n",
              "9812  [-0.48828125, -0.2265625, -0.9453125, 0.554687...   \n",
              "9813  [-0.45507812, -0.29296875, -1.015625, 0.542968...   \n",
              "9814  [-0.47265625, -0.26757812, -0.9453125, 0.51562...   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.25, -0.19238281, -1.1953125, 0.37695312, -...   \n",
              "1     [-1.2890625, -0.13378906, -1.1953125, 0.429687...   \n",
              "2     [-1.296875, -0.20800781, -1.171875, 0.35742188...   \n",
              "3     [-1.328125, -0.2265625, -1.21875, 0.38476562, ...   \n",
              "4     [-1.28125, -0.19335938, -1.1796875, 0.33984375...   \n",
              "...                                                 ...   \n",
              "9810  [-1.2734375, -0.13964844, -1.171875, 0.3867187...   \n",
              "9811  [-1.328125, -0.203125, -1.1484375, 0.40820312,...   \n",
              "9812  [-1.296875, -0.15136719, -1.1328125, 0.3886718...   \n",
              "9813  [-1.2890625, -0.2265625, -1.2265625, 0.3886718...   \n",
              "9814  [-1.2890625, -0.20507812, -1.171875, 0.3417968...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.2890625, 0.39648438, -0.33203125, 0.067382...   \n",
              "1     [-1.359375, 0.53515625, -0.41796875, 0.1162109...   \n",
              "2     [-1.375, 0.31835938, -0.35546875, -0.12011719,...   \n",
              "3     [-1.359375, 0.25390625, -0.31640625, -0.027832...   \n",
              "4     [-1.296875, 0.37304688, -0.33203125, 0.0048828...   \n",
              "...                                                 ...   \n",
              "9810  [-1.3203125, 0.41796875, -0.31640625, 0.032226...   \n",
              "9811  [-1.375, 0.390625, -0.29296875, 0.110839844, -...   \n",
              "9812  [-1.3125, 0.61328125, -0.37109375, -0.04809570...   \n",
              "9813  [-1.359375, 0.359375, -0.359375, 0.076171875, ...   \n",
              "9814  [-1.265625, 0.29296875, -0.265625, 0.03564453,...   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [-0.5625, -4.125, 0.390625, 0.6328125, -1.3984...  \n",
              "1     [14.3125, -1.5234375, -7.25, 4.53125, 0.084960...  \n",
              "2     [9.3125, -4.1875, -3.75, 3.96875, -0.8125, 3.6...  \n",
              "3     [6.75, -6.3125, -1.40625, 4.75, -2.84375, 2.28...  \n",
              "4     [4.15625, -1.5, -4.03125, 3.53125, -0.7421875,...  \n",
              "...                                                 ...  \n",
              "9810  [17.0, -1.9765625, -9.0, 2.859375, 0.15625, 3....  \n",
              "9811  [15.375, -3.703125, -5.96875, 4.1875, 0.730468...  \n",
              "9812  [17.5, -2.125, -5.46875, 1.140625, -0.70703125...  \n",
              "9813  [11.625, -2.703125, -2.5, 3.203125, 0.7578125,...  \n",
              "9814  [11.3125, -3.234375, -3.34375, 4.5625, -0.4707...  \n",
              "\n",
              "[9815 rows x 28 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinli_df = extract_activations_df(multinli_df, model_b, tokenizer_b, 'sentence', BATCH_SIZE=16)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ykdxjTrlYm"
      },
      "source": [
        "## ParaRel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic5Kh3dshrG",
        "outputId": "2db9d7ba-667f-46df-b9c8-ff6b5f92c71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pararel'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 239 (delta 24), reused 28 (delta 23), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 1.24 MiB | 18.44 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yanaiela/pararel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z46mi70tRs_",
        "outputId": "62ef4bd9-4318-44bc-a42d-7aee24083d55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5742cf42-1f46-461e-8901-88293bc59afb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_entity</th>\n",
              "      <th>second_entity</th>\n",
              "      <th>relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Steve Jobs</td>\n",
              "      <td>Apple</td>\n",
              "      <td>works-for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Steve Wozniak</td>\n",
              "      <td>Apple</td>\n",
              "      <td>works-for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paul Allen</td>\n",
              "      <td>Microsoft</td>\n",
              "      <td>works-for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Satya Nadella</td>\n",
              "      <td>Microsoft</td>\n",
              "      <td>works-for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jeremy Paxman</td>\n",
              "      <td>BBC</td>\n",
              "      <td>works-for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27605</th>\n",
              "      <td>Taliban insurgency</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>locate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27606</th>\n",
              "      <td>Peterloo Massacre</td>\n",
              "      <td>Manchester</td>\n",
              "      <td>locate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27607</th>\n",
              "      <td>Platonic Academy</td>\n",
              "      <td>Florence</td>\n",
              "      <td>locate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27608</th>\n",
              "      <td>Highland Light Infantry</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>locate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27609</th>\n",
              "      <td>Al-Rifa'i Mosque</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>locate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27610 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5742cf42-1f46-461e-8901-88293bc59afb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5742cf42-1f46-461e-8901-88293bc59afb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5742cf42-1f46-461e-8901-88293bc59afb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  first_entity second_entity   relation\n",
              "0                   Steve Jobs         Apple  works-for\n",
              "1                Steve Wozniak         Apple  works-for\n",
              "2                   Paul Allen     Microsoft  works-for\n",
              "3                Satya Nadella     Microsoft  works-for\n",
              "4                Jeremy Paxman           BBC  works-for\n",
              "...                        ...           ...        ...\n",
              "27605       Taliban insurgency   Afghanistan     locate\n",
              "27606        Peterloo Massacre    Manchester     locate\n",
              "27607         Platonic Academy      Florence     locate\n",
              "27608  Highland Light Infantry       Glasgow     locate\n",
              "27609         Al-Rifa'i Mosque         Cairo     locate\n",
              "\n",
              "[27610 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "objects_files = os.listdir('/content/pararel/data/trex_lms_vocab')\n",
        "relations_file = os.listdir('/content/pararel/data/pattern_data/graphs_json')\n",
        "\n",
        "# read the jsonl files in objects_files and create a dataframe for each file, then join them all into a single dataframe\n",
        "pararel_dfs = []\n",
        "for obj_file in relations_file:\n",
        "    obj_path = f'/content/pararel/data/trex_lms_vocab/{obj_file}'\n",
        "    obj_df = pd.read_json(obj_path, lines=True)\n",
        "\n",
        "    # read the relations file (same name as obj_file but different path) to get the relation name\n",
        "    relation_path = f'/content/pararel/data/pattern_data/graphs_json/{obj_file}'\n",
        "    with open(relation_path, 'r', encoding='utf-8') as f:\n",
        "        relation = json.loads(f.readline())['extended_lemma']\n",
        "\n",
        "    obj_df['relation'] = relation\n",
        "    pararel_dfs.append(obj_df)\n",
        "pararel_df = pd.concat(pararel_dfs, ignore_index=True)\n",
        "pararel_df.drop(columns=['uuid'], inplace=True)\n",
        "pararel_df.columns = ['first_entity', 'second_entity', 'relation']\n",
        "\n",
        "pararel_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxD1v1eKtRs_",
        "outputId": "e377fe50-2fbd-46c0-c454-b08a0a2ffcd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['works-for', 'produce-by', 'used-work', 'write-in', 'native',\n",
              "        'maintains-diplomatic-relations', 'air-on-originally',\n",
              "        'develop-by', 'die-in', 'play', 'the-official-language',\n",
              "        'is-located', 'found-in', 'is-locate-in',\n",
              "        'represented-by-music-label', 'was-create-in', 'located-in',\n",
              "        'capital-of', 'headquarter', 'original-language-is',\n",
              "        'work-in-field', 'is-subclass', 'is-twin-city', 'is-name-after',\n",
              "        'plays-music', 'is-citizen', 'position', 'affiliated-with',\n",
              "        'share-border', 'communicate', 'is-part-of', 'born-in',\n",
              "        'play-in-position', 'legal-term', 'is-by-profession', 'owned-by',\n",
              "        'is-member-of', 'locate'], dtype=object),\n",
              " 38)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pararel_df['relation'].unique(), pararel_df['relation'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklURMe2tRs_"
      },
      "source": [
        "there are 38 relationships, we want to extract sentences in the form \"What {h1} is to {t1}, {h2} is to {t2}.\"\n",
        "- Random replacement (replace one of the second relation elements with something random)\n",
        "- Reverse direction (reverse the direction of a correct relation)\n",
        "- Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BSNuLeMtRs_"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"What {h1} is to {t1}, {h2} is to {t2}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4f4yn5vtRs_",
        "outputId": "f8b8206a-6dbc-4628-8c77-a98b8cf20da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lena Yada - works-for - WWE\n",
            "Dodge Monaco - produce-by - Dodge\n",
            "Carl Ritter - used-work - Berlin\n",
            "Tirant lo Blanc - write-in - Catalan\n",
            "Marthe Mellot - native - French\n",
            "Egypt - maintains-diplomatic-relations - Australia\n",
            "Knight Rider - air-on-originally - NBC\n",
            "Shining Blade - develop-by - Sega\n",
            "Pimen I of Moscow - die-in - Moscow\n",
            "Max Rostal - play - violin\n",
            "Kingdom of Bulgaria - the-official-language - Bulgarian\n",
            "Minamishitara District, Aichi - is-located - Japan\n",
            "Blakfish - found-in - Birmingham\n",
            "Honkala Island - is-locate-in - Antarctica\n",
            "It Doesn't Matter Anymore - represented-by-music-label - Coral\n",
            "Veronika Voss - was-create-in - Germany\n",
            "Buckeystown - located-in - Maryland\n",
            "West Pakistan - capital-of - Karachi\n",
            "United Airlines - headquarter - Chicago\n",
            "Flashdance - original-language-is - English\n",
            "Pierre Janet - work-in-field - psychology\n",
            "Thromboxane A2 receptor - is-subclass - protein\n",
            "Montreal - is-twin-city - Amsterdam\n",
            "Newquay Cornwall Airport - is-name-after - Cornwall\n",
            "Helge Schneider - plays-music - jazz\n",
            "Dominic Seiterle - is-citizen - Canada\n",
            "Daniel Mannix - position - bishop\n",
            "Saint Patrick - affiliated-with - Christianity\n",
            "Etterbeek - share-border - Brussels\n",
            "Samuel Parr - communicate - English\n",
            "Christianity in Iraq - is-part-of - Christianity\n",
            "Joe Venuti - born-in - Philadelphia\n",
            "Frederik Andersen - play-in-position - goaltender\n",
            "Welsh Government - legal-term - Wales\n",
            "Paul Kehoe - is-by-profession - politician\n",
            "Bundesautobahn 113 - owned-by - Germany\n",
            "Kerry King - is-member-of - Slayer\n",
            "Convention on preventing and combating violence against women and domestic violence - locate - Istanbul\n"
          ]
        }
      ],
      "source": [
        "for i in pararel_df['relation'].unique():\n",
        "    sample = pararel_df[pararel_df['relation']==i].sample(1)\n",
        "    print(f'{sample[\"first_entity\"].values[0]} - {i} - {sample[\"second_entity\"].values[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9bKLNMbtRs_",
        "outputId": "46131725-db5c-4e13-a0e9-68936fa0cd2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting correct relationships: 100%|██████████| 38/38 [00:02<00:00, 13.50it/s]\n",
            "Extracting wrong relationships (random): 100%|██████████| 38/38 [00:02<00:00, 14.41it/s]\n",
            "Extracting wrong relationships (reversed): 100%|██████████| 38/38 [00:02<00:00, 18.44it/s]\n",
            "Extracting wrong relationships (type): 100%|██████████| 38/38 [00:02<00:00, 15.09it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f2e3fef3-0d64-4a6e-b1e7-a18aa2620a4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What Barry Davies is to BBC, Eddie Mair is to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What Ward Cunningham is to Microsoft, Susan Ka...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What Paul Allen is to Microsoft, Brian Krzanic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What George Entwistle is to BBC, Michaela Pere...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What Tony Hall, Baron Hall of Birkenhead is to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11595</th>\n",
              "      <td>What Champaner-Pavagadh Archaeological Park is...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11596</th>\n",
              "      <td>What Hiroshima International Animation Festiva...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11597</th>\n",
              "      <td>What Montreal Screwjob is to Montreal, Halifax...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11598</th>\n",
              "      <td>What START I is to Moscow, Serpent Column is t...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11599</th>\n",
              "      <td>What South Yemen insurgency is to Yemen, Istan...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11600 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2e3fef3-0d64-4a6e-b1e7-a18aa2620a4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2e3fef3-0d64-4a6e-b1e7-a18aa2620a4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2e3fef3-0d64-4a6e-b1e7-a18aa2620a4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentences  type\n",
              "0      What Barry Davies is to BBC, Eddie Mair is to ...     0\n",
              "1      What Ward Cunningham is to Microsoft, Susan Ka...     0\n",
              "2      What Paul Allen is to Microsoft, Brian Krzanic...     0\n",
              "3      What George Entwistle is to BBC, Michaela Pere...     0\n",
              "4      What Tony Hall, Baron Hall of Birkenhead is to...     0\n",
              "...                                                  ...   ...\n",
              "11595  What Champaner-Pavagadh Archaeological Park is...     3\n",
              "11596  What Hiroshima International Animation Festiva...     3\n",
              "11597  What Montreal Screwjob is to Montreal, Halifax...     3\n",
              "11598  What START I is to Moscow, Serpent Column is t...     3\n",
              "11599  What South Yemen insurgency is to Yemen, Istan...     3\n",
              "\n",
              "[11600 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ideally the dataset will be 6000 (correct) + 3 (random, reverse, type) * 2000 (wrong) = 12000 sentences\n",
        "total_dataset_len = 12000\n",
        "number_correct_relationships = total_dataset_len//2\n",
        "number_wrong_relationships = total_dataset_len//6\n",
        "\n",
        "number_relationships = pararel_df['relation'].nunique()\n",
        "relationships = pararel_df['relation'].unique()\n",
        "pararel_analogies_dict = {'sentences': [], 'type': []}\n",
        "\n",
        "# correct relationships\n",
        "for r in tqdm(relationships, desc='Extracting correct relationships'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(number_correct_relationships//number_relationships):\n",
        "        if len(rel_df) > 2:\n",
        "            sampled = rel_df.sample(n=2)\n",
        "            row1 = sampled.iloc[0]\n",
        "            row2 = sampled.iloc[1]\n",
        "            rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "            h1 = row1['first_entity']\n",
        "            t1 = row1['second_entity']\n",
        "            h2 = row2['first_entity']\n",
        "            t2 = row2['second_entity']\n",
        "            correct_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t2)\n",
        "            pararel_analogies_dict['sentences'].append(correct_sentence)\n",
        "            pararel_analogies_dict['type'].append(0) # 0 means correct relationship\n",
        "\n",
        "# random replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (random)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 3 and rel_df['first_entity'].nunique()>2 and rel_df['second_entity'].nunique()>2:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=3)\n",
        "\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "\n",
        "                if (h1!=h2 and h1!=h3 and t1!=t2 and t1!=t3 and t2!=t3):\n",
        "                    random_choice = np.random.randint(1,3)\n",
        "                    if random_choice == 1:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t3)\n",
        "                    else:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=t2)\n",
        "\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(1) # 0 means random replacement\n",
        "\n",
        "                    sampled_done = True\n",
        "\n",
        "# reverse replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (reversed)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 2 and rel_df['first_entity'].nunique()>1 and rel_df['second_entity'].nunique()>1:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=2)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                if (h1!=h2 and t1!=t2):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=t2, t2=h2)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(2) # 2 means reverse replacement\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "# type replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (type)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range((number_wrong_relationships//2)//number_relationships):\n",
        "        if len(rel_df) > 4 and rel_df['first_entity'].nunique()>3 and rel_df['second_entity'].nunique()>3:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=4)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "                row4 = sampled.iloc[3]\n",
        "\n",
        "                # correct\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                # to be replaced\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "                h4 = row4['first_entity']\n",
        "                t4 = row4['second_entity']\n",
        "\n",
        "                if (h1!=h3 and h1!=h4 and h2!=h3 and h2!=h4 and t1!=t3 and t1!=t4 and t2!=t3 and t2!=t4 and h3!=h4 and t3!=t4):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "                    random_replacement_sentence_1 = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=h4)\n",
        "                    random_replacement_sentence_2 = PROMPT.format(h1=h2, t1=t2, h2=t3, t2=t4)\n",
        "\n",
        "                    # first wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_1)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "\n",
        "                    # second wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_2)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "pararel_analogies_df = pd.DataFrame(pararel_analogies_dict)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx-4ftA4tRtA",
        "outputId": "ec844852-0549-4065-8fd8-5d76011ee2af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What Barry Davies is to BBC, Eddie Mair is to BBC.',\n",
              " 'What Ward Cunningham is to Microsoft, Susan Kare is to Apple.',\n",
              " 'What Paul Allen is to Microsoft, Brian Krzanich is to Intel.',\n",
              " 'What George Entwistle is to BBC, Michaela Pereira is to CNN.',\n",
              " 'What Tony Hall, Baron Hall of Birkenhead is to BBC, Griff Rhys Jones is to BBC.']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pararel_analogies_df.head()['sentences'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybj7KczntRtA",
        "outputId": "c53c331d-3612-41aa-db26-1cc1bbdb5a9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-58b0cf0b-3362-4bbc-865c-ec26c23d79d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What Boston Beer Company is to Boston, The Ima...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What Ron Eschete is to jazz, 704 Hauser is to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What Johann Heinrich Lambert is to physics, Ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What Godbluff is to English, Meduza is to Germ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What Allied-occupied Germany is to Berlin, Alg...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11595</th>\n",
              "      <td>What Wretch 32 is to Tottenham, Preston Ridleh...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11596</th>\n",
              "      <td>What Constitution of Nevada is to Nevada, Neva...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11597</th>\n",
              "      <td>What Bundesautobahn 11 is to Germany, Joconde ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11598</th>\n",
              "      <td>What Sweden is to Germany, Italy is to Slovakia.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11599</th>\n",
              "      <td>What Maria Valtorta is to Italian, Parvin E'te...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11600 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58b0cf0b-3362-4bbc-865c-ec26c23d79d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58b0cf0b-3362-4bbc-865c-ec26c23d79d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58b0cf0b-3362-4bbc-865c-ec26c23d79d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentences  type  label\n",
              "0      What Boston Beer Company is to Boston, The Ima...     3      0\n",
              "1      What Ron Eschete is to jazz, 704 Hauser is to ...     0      1\n",
              "2      What Johann Heinrich Lambert is to physics, Ni...     0      1\n",
              "3      What Godbluff is to English, Meduza is to Germ...     3      0\n",
              "4      What Allied-occupied Germany is to Berlin, Alg...     0      1\n",
              "...                                                  ...   ...    ...\n",
              "11595  What Wretch 32 is to Tottenham, Preston Ridleh...     3      0\n",
              "11596  What Constitution of Nevada is to Nevada, Neva...     0      1\n",
              "11597  What Bundesautobahn 11 is to Germany, Joconde ...     0      1\n",
              "11598   What Sweden is to Germany, Italy is to Slovakia.     0      1\n",
              "11599  What Maria Valtorta is to Italian, Parvin E'te...     1      0\n",
              "\n",
              "[11600 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pararel_analogies_df['label'] = pararel_analogies_df['type'].apply(lambda x: 1 if x == 0 else 0)\n",
        "pararel_analogies_df = pararel_analogies_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_LMOTzktRtA"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ1LbGEitRtA",
        "outputId": "2b040b25-7197-41e8-aa33-3a028ca1347f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing 11600 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 91/91 [00:40<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93b9663a-4e68-4998-8f9b-f1b2f98cdeec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>type</th>\n",
              "      <th>label</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What Boston Beer Company is to Boston, The Ima...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.6624916, 0.09933339, -0.21312946, 0.6483313...</td>\n",
              "      <td>[-0.065535836, 0.35086194, -0.38383153, -0.363...</td>\n",
              "      <td>[-0.092444375, 0.012116806, 0.2989555, -0.2215...</td>\n",
              "      <td>[-0.0107421875, -0.20193614, -0.032693613, -0....</td>\n",
              "      <td>[-0.047633957, -0.038637906, -0.2320822, -0.18...</td>\n",
              "      <td>[-0.108610734, -0.35674253, -0.17994225, -0.23...</td>\n",
              "      <td>[0.50492525, -0.365107, -0.17828634, -0.057999...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48242188, 0.38671875, 0.29882812, 0.511718...</td>\n",
              "      <td>[-0.9609375, 0.515625, -0.06982422, 0.7890625,...</td>\n",
              "      <td>[-1.3046875, 0.03466797, 0.15332031, 0.5859375...</td>\n",
              "      <td>[-1.2421875, 0.55859375, -0.19726562, 0.777343...</td>\n",
              "      <td>[0.017578125, 0.111328125, 0.0234375, 0.863281...</td>\n",
              "      <td>[-0.11621094, -0.10253906, -0.47265625, 1.0859...</td>\n",
              "      <td>[-0.42382812, -0.25585938, -1.046875, 0.539062...</td>\n",
              "      <td>[-1.2578125, -0.16503906, -1.2734375, 0.408203...</td>\n",
              "      <td>[-1.21875, 0.32226562, -0.4921875, 0.0859375, ...</td>\n",
              "      <td>[21.625, -4.03125, 0.076171875, 6.96875, 3.75,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What Ron Eschete is to jazz, 704 Hauser is to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.6842448, -0.35868326, 0.026801215, 0.647732...</td>\n",
              "      <td>[-0.10183377, -0.06241862, -0.17230903, -0.250...</td>\n",
              "      <td>[0.0037163629, -0.5972222, 0.13528103, 0.00035...</td>\n",
              "      <td>[0.13709852, -0.6448025, -0.14507379, -0.40511...</td>\n",
              "      <td>[0.2633735, -0.2353719, -0.37428114, -0.094238...</td>\n",
              "      <td>[0.2323405, -0.76291233, 0.17209202, -0.015462...</td>\n",
              "      <td>[0.7201606, -0.246148, -0.042263456, 0.0411241...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48828125, 0.37890625, 0.28515625, 0.503906...</td>\n",
              "      <td>[-0.953125, 0.49609375, -0.08105469, 0.7695312...</td>\n",
              "      <td>[-1.296875, 0.007080078, 0.17089844, 0.5703125...</td>\n",
              "      <td>[-1.2421875, 0.52734375, -0.18164062, 0.761718...</td>\n",
              "      <td>[0.017578125, 0.072265625, 0.033203125, 0.8359...</td>\n",
              "      <td>[-0.13085938, -0.15722656, -0.44921875, 1.0390...</td>\n",
              "      <td>[-0.4296875, -0.29492188, -1.03125, 0.50390625...</td>\n",
              "      <td>[-1.234375, -0.23242188, -1.2421875, 0.3632812...</td>\n",
              "      <td>[-1.265625, 0.33984375, -0.46484375, 0.0634765...</td>\n",
              "      <td>[23.5, -5.125, -1.9453125, 5.75, -0.83984375, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What Johann Heinrich Lambert is to physics, Ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2.2213542, -0.03125, -0.015625, 0.26498005, 0...</td>\n",
              "      <td>[-0.10983073, 0.36477864, -0.060091145, -0.289...</td>\n",
              "      <td>[-0.060026042, 0.10084636, 0.40416667, -0.2351...</td>\n",
              "      <td>[0.07285156, 0.061848957, -0.1974935, -0.52942...</td>\n",
              "      <td>[0.40559897, 0.11751302, -0.5799479, -0.123722...</td>\n",
              "      <td>[0.29479167, -0.5173177, -0.08457031, -0.00270...</td>\n",
              "      <td>[1.0210937, -0.5966797, -0.023372395, 0.219824...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.35351562, 0.31640625, 0.5, -0.4511718...</td>\n",
              "      <td>[-0.953125, 0.47265625, -0.048095703, 0.789062...</td>\n",
              "      <td>[-1.296875, -0.03125, 0.19433594, 0.59375, -1....</td>\n",
              "      <td>[-1.2421875, 0.484375, -0.13964844, 0.78125, -...</td>\n",
              "      <td>[0.021484375, 0.02734375, 0.0703125, 0.8554687...</td>\n",
              "      <td>[-0.13671875, -0.20507812, -0.38085938, 1.0703...</td>\n",
              "      <td>[-0.44726562, -0.34375, -0.97265625, 0.5195312...</td>\n",
              "      <td>[-1.2890625, -0.26953125, -1.1796875, 0.396484...</td>\n",
              "      <td>[-1.3203125, 0.26953125, -0.515625, 0.07910156...</td>\n",
              "      <td>[20.625, -3.28125, 0.41796875, 1.2265625, -0.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What Godbluff is to English, Meduza is to Germ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.8885417, 0.117496744, -0.39576823, 0.319401...</td>\n",
              "      <td>[0.05644531, 0.47981772, -0.5026042, -0.645117...</td>\n",
              "      <td>[-0.11757813, 0.2783203, -0.13746744, -0.36054...</td>\n",
              "      <td>[0.05045573, -0.05369466, -0.43868002, -0.5082...</td>\n",
              "      <td>[0.35097656, 0.2510091, -0.7111979, -0.5028646...</td>\n",
              "      <td>[0.18489583, -0.37198892, -0.19697265, -0.6839...</td>\n",
              "      <td>[0.5320638, 0.1530599, -0.46354166, -0.6924479...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.47265625, 0.390625, 0.28125, 0.49023438, -...</td>\n",
              "      <td>[-0.9453125, 0.50390625, -0.08642578, 0.765625...</td>\n",
              "      <td>[-1.28125, 0.016113281, 0.15429688, 0.5625, -1...</td>\n",
              "      <td>[-1.21875, 0.5390625, -0.19335938, 0.75390625,...</td>\n",
              "      <td>[0.048828125, 0.08105469, 0.029296875, 0.82421...</td>\n",
              "      <td>[-0.11425781, -0.13671875, -0.41796875, 1.0390...</td>\n",
              "      <td>[-0.41796875, -0.27539062, -0.98828125, 0.5, -...</td>\n",
              "      <td>[-1.265625, -0.21777344, -1.21875, 0.32421875,...</td>\n",
              "      <td>[-1.296875, 0.38671875, -0.48828125, 0.0026855...</td>\n",
              "      <td>[23.75, 1.03125, -3.78125, 1.9140625, 1.929687...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What Allied-occupied Germany is to Berlin, Alg...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.814174, -0.03013393, -0.0855375, 0.1968471,...</td>\n",
              "      <td>[-0.12625559, 0.22070312, -0.23950195, -0.4607...</td>\n",
              "      <td>[-0.19384766, -0.009765625, 0.14181082, -0.298...</td>\n",
              "      <td>[-0.107003346, 0.10257394, -0.320731, -0.40987...</td>\n",
              "      <td>[0.22452219, 0.023925781, -0.6046317, -0.14109...</td>\n",
              "      <td>[0.16657366, -0.3569336, -0.12548828, -0.40035...</td>\n",
              "      <td>[0.6185128, -0.31912667, 0.050816126, -0.12402...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5390625, 0.3828125, 0.31054688, 0.5078125,...</td>\n",
              "      <td>[-0.984375, 0.5078125, -0.053710938, 0.7929687...</td>\n",
              "      <td>[-1.3125, 0.012939453, 0.18652344, 0.58203125,...</td>\n",
              "      <td>[-1.2578125, 0.5390625, -0.16113281, 0.7734375...</td>\n",
              "      <td>[0.009765625, 0.08300781, 0.056640625, 0.84375...</td>\n",
              "      <td>[-0.16015625, -0.13476562, -0.41015625, 1.0781...</td>\n",
              "      <td>[-0.4765625, -0.265625, -0.99609375, 0.53125, ...</td>\n",
              "      <td>[-1.296875, -0.19042969, -1.25, 0.38476562, -2...</td>\n",
              "      <td>[-1.3984375, 0.36914062, -0.50390625, 0.058837...</td>\n",
              "      <td>[19.875, -4.0, -1.8203125, 0.39648438, 1.3125,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11595</th>\n",
              "      <td>What Wretch 32 is to Tottenham, Preston Ridleh...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[2.278832, -0.30268788, -0.34965587, 0.3586455...</td>\n",
              "      <td>[0.017392114, 0.18815105, -0.42857143, -0.3806...</td>\n",
              "      <td>[-0.06989397, -0.11597842, -0.048874628, -0.43...</td>\n",
              "      <td>[0.20414807, -0.24916294, -0.49444288, -0.5413...</td>\n",
              "      <td>[0.33899507, 0.21349517, -0.6307664, -0.344680...</td>\n",
              "      <td>[0.2765997, -0.45768228, -0.3008045, -0.417736...</td>\n",
              "      <td>[0.828311, -0.10514323, -0.55032784, -0.498628...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.515625, 0.37109375, 0.28710938, 0.5, -0.43...</td>\n",
              "      <td>[-0.98046875, 0.49609375, -0.07324219, 0.78125...</td>\n",
              "      <td>[-1.3203125, 0.004638672, 0.15234375, 0.582031...</td>\n",
              "      <td>[-1.265625, 0.52734375, -0.1953125, 0.76953125...</td>\n",
              "      <td>[0.0, 0.064453125, 0.0390625, 0.84765625, -1.5...</td>\n",
              "      <td>[-0.14648438, -0.15234375, -0.43359375, 1.0546...</td>\n",
              "      <td>[-0.46484375, -0.30664062, -1.03125, 0.515625,...</td>\n",
              "      <td>[-1.3046875, -0.22460938, -1.234375, 0.3925781...</td>\n",
              "      <td>[-1.328125, 0.29296875, -0.47265625, 0.0305175...</td>\n",
              "      <td>[21.875, -6.75, 1.1875, 1.421875, -1.7421875, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11596</th>\n",
              "      <td>What Constitution of Nevada is to Nevada, Neva...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2.1132812, 0.7569057, 0.18568638, 0.6010742, ...</td>\n",
              "      <td>[0.25613838, 0.73186386, 0.10227748, -0.257882...</td>\n",
              "      <td>[0.17926897, 0.4468471, 0.3592355, -0.08081055...</td>\n",
              "      <td>[0.25097656, 0.30691963, -0.09402902, -0.20807...</td>\n",
              "      <td>[0.5511998, 0.25697544, -0.50683594, -0.096958...</td>\n",
              "      <td>[0.8313337, 0.072684154, -0.20947266, 0.168387...</td>\n",
              "      <td>[1.1405029, -0.20619419, 0.011230469, 0.171944...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.48828125, 0.37890625, 0.29101562, 0.523437...</td>\n",
              "      <td>[-0.9453125, 0.5, -0.068847656, 0.796875, -0.8...</td>\n",
              "      <td>[-1.28125, 0.005859375, 0.17285156, 0.59375, -...</td>\n",
              "      <td>[-1.2265625, 0.53125, -0.17871094, 0.78125, -1...</td>\n",
              "      <td>[0.0390625, 0.07128906, 0.05078125, 0.84765625...</td>\n",
              "      <td>[-0.12402344, -0.13671875, -0.41210938, 1.0703...</td>\n",
              "      <td>[-0.4375, -0.2734375, -0.98828125, 0.5546875, ...</td>\n",
              "      <td>[-1.28125, -0.19824219, -1.2109375, 0.4375, -2...</td>\n",
              "      <td>[-1.296875, 0.49609375, -0.546875, 0.17480469,...</td>\n",
              "      <td>[27.25, -0.17382812, -5.09375, 7.6875, -2.7187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11597</th>\n",
              "      <td>What Bundesautobahn 11 is to Germany, Joconde ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.9427849, -0.022231158, -0.10862821, 0.73556...</td>\n",
              "      <td>[0.034352023, 0.33088234, -0.27131203, -0.2529...</td>\n",
              "      <td>[-0.030330881, 0.18054917, 0.09695255, -0.1970...</td>\n",
              "      <td>[0.18732767, 0.068093695, -0.11965763, -0.3004...</td>\n",
              "      <td>[0.3253102, 0.21254596, -0.3862592, -0.1728084...</td>\n",
              "      <td>[0.14545037, -0.3068704, -0.04319853, -0.45743...</td>\n",
              "      <td>[0.6763126, 0.48664406, -0.6628849, -0.3385225...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5078125, 0.37890625, 0.29101562, 0.5078125...</td>\n",
              "      <td>[-0.953125, 0.51171875, -0.07080078, 0.8046875...</td>\n",
              "      <td>[-1.2890625, 0.013427734, 0.16015625, 0.601562...</td>\n",
              "      <td>[-1.2265625, 0.53125, -0.18554688, 0.796875, -...</td>\n",
              "      <td>[0.02734375, 0.06933594, 0.037109375, 0.871093...</td>\n",
              "      <td>[-0.119140625, -0.15625, -0.41796875, 1.09375,...</td>\n",
              "      <td>[-0.42773438, -0.2890625, -0.99609375, 0.54296...</td>\n",
              "      <td>[-1.2578125, -0.18164062, -1.234375, 0.3984375...</td>\n",
              "      <td>[-1.359375, 0.3203125, -0.484375, 0.08496094, ...</td>\n",
              "      <td>[12.0, -2.703125, 1.5703125, 1.921875, -1.3984...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11598</th>\n",
              "      <td>What Sweden is to Germany, Italy is to Slovakia.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.537642, 0.058815695, -0.09248491, 0.4729226...</td>\n",
              "      <td>[-0.12526633, 0.08274148, -0.29840642, -0.5311...</td>\n",
              "      <td>[-0.052201703, 0.07723722, 0.1772017, -0.19837...</td>\n",
              "      <td>[-0.19109553, -0.36257103, -0.19176136, -0.252...</td>\n",
              "      <td>[0.24232067, -0.25261897, -0.64559656, 0.00763...</td>\n",
              "      <td>[0.38436612, -0.6759588, -0.5842507, -0.268377...</td>\n",
              "      <td>[0.9135298, -0.67578125, -0.39124644, 0.074573...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.51171875, 0.36328125, 0.31640625, 0.519531...</td>\n",
              "      <td>[-0.9609375, 0.5, -0.044433594, 0.8125, -0.906...</td>\n",
              "      <td>[-1.2890625, -0.00048828125, 0.17675781, 0.593...</td>\n",
              "      <td>[-1.234375, 0.51953125, -0.16210938, 0.7851562...</td>\n",
              "      <td>[0.025390625, 0.056640625, 0.046875, 0.8554687...</td>\n",
              "      <td>[-0.12451172, -0.16796875, -0.390625, 1.078125...</td>\n",
              "      <td>[-0.4453125, -0.30859375, -0.98828125, 0.55468...</td>\n",
              "      <td>[-1.25, -0.24902344, -1.2421875, 0.39648438, -...</td>\n",
              "      <td>[-1.3671875, 0.32421875, -0.484375, 0.078125, ...</td>\n",
              "      <td>[22.5, -2.8125, 0.4140625, 2.28125, -0.3144531...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11599</th>\n",
              "      <td>What Maria Valtorta is to Italian, Parvin E'te...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.9013672, 0.05851237, -0.1139662, 0.30485025...</td>\n",
              "      <td>[-0.061197918, 0.48849827, -0.20480686, -0.502...</td>\n",
              "      <td>[0.005750868, 0.2940267, 0.06906467, -0.404513...</td>\n",
              "      <td>[0.030653212, 0.17578125, -0.41314018, -0.7895...</td>\n",
              "      <td>[0.23583984, 0.19471571, -0.6065538, -0.360785...</td>\n",
              "      <td>[0.41134983, -0.31814235, -0.26850045, -0.4681...</td>\n",
              "      <td>[0.8812392, -0.0405816, -0.304579, -0.43267143...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.47070312, 0.40429688, 0.28125, 0.515625, -...</td>\n",
              "      <td>[-0.953125, 0.53125, -0.0703125, 0.8046875, -0...</td>\n",
              "      <td>[-1.296875, 0.032958984, 0.15917969, 0.5976562...</td>\n",
              "      <td>[-1.234375, 0.5546875, -0.18554688, 0.7890625,...</td>\n",
              "      <td>[0.01953125, 0.09765625, 0.017578125, 0.863281...</td>\n",
              "      <td>[-0.11767578, -0.115234375, -0.4453125, 1.0781...</td>\n",
              "      <td>[-0.421875, -0.265625, -1.015625, 0.53125, -1....</td>\n",
              "      <td>[-1.2265625, -0.1953125, -1.234375, 0.40625, -...</td>\n",
              "      <td>[-1.203125, 0.29882812, -0.546875, 0.087890625...</td>\n",
              "      <td>[23.25, -2.15625, -1.7578125, 1.609375, 2.2343...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11600 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93b9663a-4e68-4998-8f9b-f1b2f98cdeec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93b9663a-4e68-4998-8f9b-f1b2f98cdeec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93b9663a-4e68-4998-8f9b-f1b2f98cdeec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentences  type  label  \\\n",
              "0      What Boston Beer Company is to Boston, The Ima...     3      0   \n",
              "1      What Ron Eschete is to jazz, 704 Hauser is to ...     0      1   \n",
              "2      What Johann Heinrich Lambert is to physics, Ni...     0      1   \n",
              "3      What Godbluff is to English, Meduza is to Germ...     3      0   \n",
              "4      What Allied-occupied Germany is to Berlin, Alg...     0      1   \n",
              "...                                                  ...   ...    ...   \n",
              "11595  What Wretch 32 is to Tottenham, Preston Ridleh...     3      0   \n",
              "11596  What Constitution of Nevada is to Nevada, Neva...     0      1   \n",
              "11597  What Bundesautobahn 11 is to Germany, Joconde ...     0      1   \n",
              "11598   What Sweden is to Germany, Italy is to Slovakia.     0      1   \n",
              "11599  What Maria Valtorta is to Italian, Parvin E'te...     1      0   \n",
              "\n",
              "                                         encoder_layer_1  \\\n",
              "0      [1.6624916, 0.09933339, -0.21312946, 0.6483313...   \n",
              "1      [1.6842448, -0.35868326, 0.026801215, 0.647732...   \n",
              "2      [2.2213542, -0.03125, -0.015625, 0.26498005, 0...   \n",
              "3      [1.8885417, 0.117496744, -0.39576823, 0.319401...   \n",
              "4      [1.814174, -0.03013393, -0.0855375, 0.1968471,...   \n",
              "...                                                  ...   \n",
              "11595  [2.278832, -0.30268788, -0.34965587, 0.3586455...   \n",
              "11596  [2.1132812, 0.7569057, 0.18568638, 0.6010742, ...   \n",
              "11597  [1.9427849, -0.022231158, -0.10862821, 0.73556...   \n",
              "11598  [1.537642, 0.058815695, -0.09248491, 0.4729226...   \n",
              "11599  [1.9013672, 0.05851237, -0.1139662, 0.30485025...   \n",
              "\n",
              "                                         encoder_layer_2  \\\n",
              "0      [-0.065535836, 0.35086194, -0.38383153, -0.363...   \n",
              "1      [-0.10183377, -0.06241862, -0.17230903, -0.250...   \n",
              "2      [-0.10983073, 0.36477864, -0.060091145, -0.289...   \n",
              "3      [0.05644531, 0.47981772, -0.5026042, -0.645117...   \n",
              "4      [-0.12625559, 0.22070312, -0.23950195, -0.4607...   \n",
              "...                                                  ...   \n",
              "11595  [0.017392114, 0.18815105, -0.42857143, -0.3806...   \n",
              "11596  [0.25613838, 0.73186386, 0.10227748, -0.257882...   \n",
              "11597  [0.034352023, 0.33088234, -0.27131203, -0.2529...   \n",
              "11598  [-0.12526633, 0.08274148, -0.29840642, -0.5311...   \n",
              "11599  [-0.061197918, 0.48849827, -0.20480686, -0.502...   \n",
              "\n",
              "                                         encoder_layer_3  \\\n",
              "0      [-0.092444375, 0.012116806, 0.2989555, -0.2215...   \n",
              "1      [0.0037163629, -0.5972222, 0.13528103, 0.00035...   \n",
              "2      [-0.060026042, 0.10084636, 0.40416667, -0.2351...   \n",
              "3      [-0.11757813, 0.2783203, -0.13746744, -0.36054...   \n",
              "4      [-0.19384766, -0.009765625, 0.14181082, -0.298...   \n",
              "...                                                  ...   \n",
              "11595  [-0.06989397, -0.11597842, -0.048874628, -0.43...   \n",
              "11596  [0.17926897, 0.4468471, 0.3592355, -0.08081055...   \n",
              "11597  [-0.030330881, 0.18054917, 0.09695255, -0.1970...   \n",
              "11598  [-0.052201703, 0.07723722, 0.1772017, -0.19837...   \n",
              "11599  [0.005750868, 0.2940267, 0.06906467, -0.404513...   \n",
              "\n",
              "                                         encoder_layer_4  \\\n",
              "0      [-0.0107421875, -0.20193614, -0.032693613, -0....   \n",
              "1      [0.13709852, -0.6448025, -0.14507379, -0.40511...   \n",
              "2      [0.07285156, 0.061848957, -0.1974935, -0.52942...   \n",
              "3      [0.05045573, -0.05369466, -0.43868002, -0.5082...   \n",
              "4      [-0.107003346, 0.10257394, -0.320731, -0.40987...   \n",
              "...                                                  ...   \n",
              "11595  [0.20414807, -0.24916294, -0.49444288, -0.5413...   \n",
              "11596  [0.25097656, 0.30691963, -0.09402902, -0.20807...   \n",
              "11597  [0.18732767, 0.068093695, -0.11965763, -0.3004...   \n",
              "11598  [-0.19109553, -0.36257103, -0.19176136, -0.252...   \n",
              "11599  [0.030653212, 0.17578125, -0.41314018, -0.7895...   \n",
              "\n",
              "                                         encoder_layer_5  \\\n",
              "0      [-0.047633957, -0.038637906, -0.2320822, -0.18...   \n",
              "1      [0.2633735, -0.2353719, -0.37428114, -0.094238...   \n",
              "2      [0.40559897, 0.11751302, -0.5799479, -0.123722...   \n",
              "3      [0.35097656, 0.2510091, -0.7111979, -0.5028646...   \n",
              "4      [0.22452219, 0.023925781, -0.6046317, -0.14109...   \n",
              "...                                                  ...   \n",
              "11595  [0.33899507, 0.21349517, -0.6307664, -0.344680...   \n",
              "11596  [0.5511998, 0.25697544, -0.50683594, -0.096958...   \n",
              "11597  [0.3253102, 0.21254596, -0.3862592, -0.1728084...   \n",
              "11598  [0.24232067, -0.25261897, -0.64559656, 0.00763...   \n",
              "11599  [0.23583984, 0.19471571, -0.6065538, -0.360785...   \n",
              "\n",
              "                                         encoder_layer_6  \\\n",
              "0      [-0.108610734, -0.35674253, -0.17994225, -0.23...   \n",
              "1      [0.2323405, -0.76291233, 0.17209202, -0.015462...   \n",
              "2      [0.29479167, -0.5173177, -0.08457031, -0.00270...   \n",
              "3      [0.18489583, -0.37198892, -0.19697265, -0.6839...   \n",
              "4      [0.16657366, -0.3569336, -0.12548828, -0.40035...   \n",
              "...                                                  ...   \n",
              "11595  [0.2765997, -0.45768228, -0.3008045, -0.417736...   \n",
              "11596  [0.8313337, 0.072684154, -0.20947266, 0.168387...   \n",
              "11597  [0.14545037, -0.3068704, -0.04319853, -0.45743...   \n",
              "11598  [0.38436612, -0.6759588, -0.5842507, -0.268377...   \n",
              "11599  [0.41134983, -0.31814235, -0.26850045, -0.4681...   \n",
              "\n",
              "                                         encoder_layer_7  ...  \\\n",
              "0      [0.50492525, -0.365107, -0.17828634, -0.057999...  ...   \n",
              "1      [0.7201606, -0.246148, -0.042263456, 0.0411241...  ...   \n",
              "2      [1.0210937, -0.5966797, -0.023372395, 0.219824...  ...   \n",
              "3      [0.5320638, 0.1530599, -0.46354166, -0.6924479...  ...   \n",
              "4      [0.6185128, -0.31912667, 0.050816126, -0.12402...  ...   \n",
              "...                                                  ...  ...   \n",
              "11595  [0.828311, -0.10514323, -0.55032784, -0.498628...  ...   \n",
              "11596  [1.1405029, -0.20619419, 0.011230469, 0.171944...  ...   \n",
              "11597  [0.6763126, 0.48664406, -0.6628849, -0.3385225...  ...   \n",
              "11598  [0.9135298, -0.67578125, -0.39124644, 0.074573...  ...   \n",
              "11599  [0.8812392, -0.0405816, -0.304579, -0.43267143...  ...   \n",
              "\n",
              "                                         decoder_layer_4  \\\n",
              "0      [-0.48242188, 0.38671875, 0.29882812, 0.511718...   \n",
              "1      [-0.48828125, 0.37890625, 0.28515625, 0.503906...   \n",
              "2      [-0.5, 0.35351562, 0.31640625, 0.5, -0.4511718...   \n",
              "3      [-0.47265625, 0.390625, 0.28125, 0.49023438, -...   \n",
              "4      [-0.5390625, 0.3828125, 0.31054688, 0.5078125,...   \n",
              "...                                                  ...   \n",
              "11595  [-0.515625, 0.37109375, 0.28710938, 0.5, -0.43...   \n",
              "11596  [-0.48828125, 0.37890625, 0.29101562, 0.523437...   \n",
              "11597  [-0.5078125, 0.37890625, 0.29101562, 0.5078125...   \n",
              "11598  [-0.51171875, 0.36328125, 0.31640625, 0.519531...   \n",
              "11599  [-0.47070312, 0.40429688, 0.28125, 0.515625, -...   \n",
              "\n",
              "                                         decoder_layer_5  \\\n",
              "0      [-0.9609375, 0.515625, -0.06982422, 0.7890625,...   \n",
              "1      [-0.953125, 0.49609375, -0.08105469, 0.7695312...   \n",
              "2      [-0.953125, 0.47265625, -0.048095703, 0.789062...   \n",
              "3      [-0.9453125, 0.50390625, -0.08642578, 0.765625...   \n",
              "4      [-0.984375, 0.5078125, -0.053710938, 0.7929687...   \n",
              "...                                                  ...   \n",
              "11595  [-0.98046875, 0.49609375, -0.07324219, 0.78125...   \n",
              "11596  [-0.9453125, 0.5, -0.068847656, 0.796875, -0.8...   \n",
              "11597  [-0.953125, 0.51171875, -0.07080078, 0.8046875...   \n",
              "11598  [-0.9609375, 0.5, -0.044433594, 0.8125, -0.906...   \n",
              "11599  [-0.953125, 0.53125, -0.0703125, 0.8046875, -0...   \n",
              "\n",
              "                                         decoder_layer_6  \\\n",
              "0      [-1.3046875, 0.03466797, 0.15332031, 0.5859375...   \n",
              "1      [-1.296875, 0.007080078, 0.17089844, 0.5703125...   \n",
              "2      [-1.296875, -0.03125, 0.19433594, 0.59375, -1....   \n",
              "3      [-1.28125, 0.016113281, 0.15429688, 0.5625, -1...   \n",
              "4      [-1.3125, 0.012939453, 0.18652344, 0.58203125,...   \n",
              "...                                                  ...   \n",
              "11595  [-1.3203125, 0.004638672, 0.15234375, 0.582031...   \n",
              "11596  [-1.28125, 0.005859375, 0.17285156, 0.59375, -...   \n",
              "11597  [-1.2890625, 0.013427734, 0.16015625, 0.601562...   \n",
              "11598  [-1.2890625, -0.00048828125, 0.17675781, 0.593...   \n",
              "11599  [-1.296875, 0.032958984, 0.15917969, 0.5976562...   \n",
              "\n",
              "                                         decoder_layer_7  \\\n",
              "0      [-1.2421875, 0.55859375, -0.19726562, 0.777343...   \n",
              "1      [-1.2421875, 0.52734375, -0.18164062, 0.761718...   \n",
              "2      [-1.2421875, 0.484375, -0.13964844, 0.78125, -...   \n",
              "3      [-1.21875, 0.5390625, -0.19335938, 0.75390625,...   \n",
              "4      [-1.2578125, 0.5390625, -0.16113281, 0.7734375...   \n",
              "...                                                  ...   \n",
              "11595  [-1.265625, 0.52734375, -0.1953125, 0.76953125...   \n",
              "11596  [-1.2265625, 0.53125, -0.17871094, 0.78125, -1...   \n",
              "11597  [-1.2265625, 0.53125, -0.18554688, 0.796875, -...   \n",
              "11598  [-1.234375, 0.51953125, -0.16210938, 0.7851562...   \n",
              "11599  [-1.234375, 0.5546875, -0.18554688, 0.7890625,...   \n",
              "\n",
              "                                         decoder_layer_8  \\\n",
              "0      [0.017578125, 0.111328125, 0.0234375, 0.863281...   \n",
              "1      [0.017578125, 0.072265625, 0.033203125, 0.8359...   \n",
              "2      [0.021484375, 0.02734375, 0.0703125, 0.8554687...   \n",
              "3      [0.048828125, 0.08105469, 0.029296875, 0.82421...   \n",
              "4      [0.009765625, 0.08300781, 0.056640625, 0.84375...   \n",
              "...                                                  ...   \n",
              "11595  [0.0, 0.064453125, 0.0390625, 0.84765625, -1.5...   \n",
              "11596  [0.0390625, 0.07128906, 0.05078125, 0.84765625...   \n",
              "11597  [0.02734375, 0.06933594, 0.037109375, 0.871093...   \n",
              "11598  [0.025390625, 0.056640625, 0.046875, 0.8554687...   \n",
              "11599  [0.01953125, 0.09765625, 0.017578125, 0.863281...   \n",
              "\n",
              "                                         decoder_layer_9  \\\n",
              "0      [-0.11621094, -0.10253906, -0.47265625, 1.0859...   \n",
              "1      [-0.13085938, -0.15722656, -0.44921875, 1.0390...   \n",
              "2      [-0.13671875, -0.20507812, -0.38085938, 1.0703...   \n",
              "3      [-0.11425781, -0.13671875, -0.41796875, 1.0390...   \n",
              "4      [-0.16015625, -0.13476562, -0.41015625, 1.0781...   \n",
              "...                                                  ...   \n",
              "11595  [-0.14648438, -0.15234375, -0.43359375, 1.0546...   \n",
              "11596  [-0.12402344, -0.13671875, -0.41210938, 1.0703...   \n",
              "11597  [-0.119140625, -0.15625, -0.41796875, 1.09375,...   \n",
              "11598  [-0.12451172, -0.16796875, -0.390625, 1.078125...   \n",
              "11599  [-0.11767578, -0.115234375, -0.4453125, 1.0781...   \n",
              "\n",
              "                                        decoder_layer_10  \\\n",
              "0      [-0.42382812, -0.25585938, -1.046875, 0.539062...   \n",
              "1      [-0.4296875, -0.29492188, -1.03125, 0.50390625...   \n",
              "2      [-0.44726562, -0.34375, -0.97265625, 0.5195312...   \n",
              "3      [-0.41796875, -0.27539062, -0.98828125, 0.5, -...   \n",
              "4      [-0.4765625, -0.265625, -0.99609375, 0.53125, ...   \n",
              "...                                                  ...   \n",
              "11595  [-0.46484375, -0.30664062, -1.03125, 0.515625,...   \n",
              "11596  [-0.4375, -0.2734375, -0.98828125, 0.5546875, ...   \n",
              "11597  [-0.42773438, -0.2890625, -0.99609375, 0.54296...   \n",
              "11598  [-0.4453125, -0.30859375, -0.98828125, 0.55468...   \n",
              "11599  [-0.421875, -0.265625, -1.015625, 0.53125, -1....   \n",
              "\n",
              "                                        decoder_layer_11  \\\n",
              "0      [-1.2578125, -0.16503906, -1.2734375, 0.408203...   \n",
              "1      [-1.234375, -0.23242188, -1.2421875, 0.3632812...   \n",
              "2      [-1.2890625, -0.26953125, -1.1796875, 0.396484...   \n",
              "3      [-1.265625, -0.21777344, -1.21875, 0.32421875,...   \n",
              "4      [-1.296875, -0.19042969, -1.25, 0.38476562, -2...   \n",
              "...                                                  ...   \n",
              "11595  [-1.3046875, -0.22460938, -1.234375, 0.3925781...   \n",
              "11596  [-1.28125, -0.19824219, -1.2109375, 0.4375, -2...   \n",
              "11597  [-1.2578125, -0.18164062, -1.234375, 0.3984375...   \n",
              "11598  [-1.25, -0.24902344, -1.2421875, 0.39648438, -...   \n",
              "11599  [-1.2265625, -0.1953125, -1.234375, 0.40625, -...   \n",
              "\n",
              "                                        decoder_layer_12  \\\n",
              "0      [-1.21875, 0.32226562, -0.4921875, 0.0859375, ...   \n",
              "1      [-1.265625, 0.33984375, -0.46484375, 0.0634765...   \n",
              "2      [-1.3203125, 0.26953125, -0.515625, 0.07910156...   \n",
              "3      [-1.296875, 0.38671875, -0.48828125, 0.0026855...   \n",
              "4      [-1.3984375, 0.36914062, -0.50390625, 0.058837...   \n",
              "...                                                  ...   \n",
              "11595  [-1.328125, 0.29296875, -0.47265625, 0.0305175...   \n",
              "11596  [-1.296875, 0.49609375, -0.546875, 0.17480469,...   \n",
              "11597  [-1.359375, 0.3203125, -0.484375, 0.08496094, ...   \n",
              "11598  [-1.3671875, 0.32421875, -0.484375, 0.078125, ...   \n",
              "11599  [-1.203125, 0.29882812, -0.546875, 0.087890625...   \n",
              "\n",
              "                                        decoder_layer_13  \n",
              "0      [21.625, -4.03125, 0.076171875, 6.96875, 3.75,...  \n",
              "1      [23.5, -5.125, -1.9453125, 5.75, -0.83984375, ...  \n",
              "2      [20.625, -3.28125, 0.41796875, 1.2265625, -0.7...  \n",
              "3      [23.75, 1.03125, -3.78125, 1.9140625, 1.929687...  \n",
              "4      [19.875, -4.0, -1.8203125, 0.39648438, 1.3125,...  \n",
              "...                                                  ...  \n",
              "11595  [21.875, -6.75, 1.1875, 1.421875, -1.7421875, ...  \n",
              "11596  [27.25, -0.17382812, -5.09375, 7.6875, -2.7187...  \n",
              "11597  [12.0, -2.703125, 1.5703125, 1.921875, -1.3984...  \n",
              "11598  [22.5, -2.8125, 0.4140625, 2.28125, -0.3144531...  \n",
              "11599  [23.25, -2.15625, -1.7578125, 1.609375, 2.2343...  \n",
              "\n",
              "[11600 rows x 29 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_b, tokenizer_b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2YUuDZdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfkiIbpttRtA"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTo5yHPAtRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_2b, tokenizer_2b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUKE82pdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_2b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6a3H8citRtA"
      },
      "source": [
        "## Perturbations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV1boEqtRtA"
      },
      "source": [
        "here we consider the perturbations on the dataset\n",
        "\n",
        "we have to perturbe just the validation set, for being able to detect the model's strength\n",
        "\n",
        "we can use 2 different perturbation levels: semantic level and syntactic level\n",
        "- for semantic level we can use https://github.com/makcedward/nlpaug (sinonimi)\n",
        "- for syntactic level we can use again nlpaug\n",
        "\n",
        "https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
        "\n",
        "for datasets\n",
        "- true/false: both\n",
        "- CoLA: semantic (syntactic would change the label)\n",
        "- EWT: both\n",
        "- ParaRel: none\n",
        "- MultiNLI: both (with carefuleness about syntactic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq2ymKU_tRtA"
      },
      "source": [
        "# Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YCjfsHlk0Pmp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MOYYlmAszNzg"
      },
      "outputs": [],
      "source": [
        "class Probe(nn.Module):\n",
        "  def fit(self, train_loader, epochs=10, lr=0.001, device=None):\n",
        "    total_losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    criterion = nn.CrossEntropyLoss() # standard\n",
        "    optimizer = optim.Adam(self.parameters(), lr=lr) # to be defined with hyperparams\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      self.train()\n",
        "      total_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "      # Statistiche di fine epoca\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      acc = correct / total\n",
        "      total_losses.append(avg_loss)\n",
        "      accuracies.append(acc)\n",
        "      #print(f\"Epoca [{epoch+1}/{epochs}] \\t Loss: {avg_loss:.4f} \\t Acc: {acc:.4f}\")\n",
        "\n",
        "    return total_losses, accuracies\n",
        "\n",
        "  def evaluate(self, test_loader, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # torch.no_grad() risparmia memoria e calcoli perché non traccia i gradienti\n",
        "    with torch.no_grad():\n",
        "      for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        outputs = self(batch_x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "class NonLinearProbe(Probe):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(NonLinearProbe, self).__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "class LinearProbe(Probe):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearProbe, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 200)\n",
        "    self.linear2 = nn.Linear(200, output_dim)\n",
        "\n",
        "  def fit(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kvgWaCJyRvin"
      },
      "outputs": [],
      "source": [
        "def iterate_training_layers(model_size, df, num_layers, encdec, probe, probe_args={}, split_index=75):\n",
        "  train_accuracy = []\n",
        "  test_accuracy = []\n",
        "\n",
        "  print(f'Training on model {model_size}, considering {encdec}')\n",
        "  for layer in trange(num_layers):\n",
        "    col_name = f'{encdec}_layer_{layer+1}'\n",
        "    num_train_instances = len(df) * split_index // 100\n",
        "    num_test_instances = len(df) - num_train_instances\n",
        "\n",
        "    # shuffle the df\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    train_df = df[:num_train_instances]\n",
        "    test_df = df[num_train_instances:]\n",
        "\n",
        "    X_train_tensor = torch.stack([torch.from_numpy(t) for t in train_df[col_name].tolist()])\n",
        "    y_train_tensor = torch.tensor(train_df['label'].tolist())\n",
        "\n",
        "    X_test_tensor = torch.stack([torch.from_numpy(t) for t in test_df[col_name].tolist()])\n",
        "    y_test_tensor = torch.tensor(test_df['label'].tolist())\n",
        "\n",
        "    # training of the probe\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "    if probe=='linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = LinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim)\n",
        "    elif probe == 'non_linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = NonLinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim, **probe_args)\n",
        "    else:\n",
        "      raise ValueError('Probe must be either linear or non_linear')\n",
        "\n",
        "    results = probe_instance.fit(train_loader, epochs=25, lr=0.001)\n",
        "    train_accuracy.append(results[1][-1])\n",
        "\n",
        "    # evaluating test accuracy\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "    test_acc = probe_instance.evaluate(test_loader)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n",
        "  return train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WRHoApyrGUzO"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(train_accuracy, test_accuracy, model, probe, knowledge, encdec):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(train_accuracy, label='Train Accuracy')\n",
        "  plt.plot(test_accuracy, label='Test Accuracy')\n",
        "  plt.xlabel('Layer')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(f'{knowledge}, model {model}, linearity {probe}, encdec {encdec}')\n",
        "  plt.grid(True)\n",
        "  plt.legend(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGRKft-YUGP8"
      },
      "source": [
        "model b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "Nrdisnnm0diE"
      },
      "outputs": [],
      "source": [
        "tf_b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-b-b-ul2'\n",
        "tf_b_df = pd.read_pickle(tf_b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SleK9ZLCUia_",
        "outputId": "940b02a3-87f8-40ce-d7a9-88e7bf74799b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on model b, considering encoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 2/13 [00:13<01:14,  6.74s/it]"
          ]
        }
      ],
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : tf_b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13,\n",
        "    'encdec':'encoder'\n",
        "}\n",
        "\n",
        "encoder_results = iterate_training_layers(**configb)\n",
        "decoder_results = iterate_training_layers(**configb)\n",
        "\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'factual', 'encoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'non_linear', 'factual', 'decoder')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89_0OnHUfPX"
      },
      "source": [
        "model 2b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkL8QH37MUVD"
      },
      "outputs": [],
      "source": [
        "tf_2b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-2b-2b-ul2'\n",
        "tf_2b_df = pd.read_pickle(tf_2b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RXbhQ9XRU_SI",
        "outputId": "6b98fc51-9740-4301-b7bb-e19d98cd242b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on model 2b, considering encoder\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [02:55<00:00,  6.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on model 2b, considering decoder\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [02:54<00:00,  6.45s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAApfVJREFUeJzs3Xd8VFX6x/HPzKQ3SEijh96kKxFEsVBERFEsYKHYRWysq+IqiLjyW3VZVldFXdpaEXtFEMRGU8CC9F7TSSfJZOb+/rjJwJBCyoRJ+b5fr7xg7ty589zJmcl95pzzHIthGAYiIiIiIiJSLVZvByAiIiIiIlIfKLkSERERERHxACVXIiIiIiIiHqDkSkRERERExAOUXImIiIiIiHiAkisREREREREPUHIlIiIiIiLiAUquREREREREPEDJlYiIiIiIiAcouRKphX7++WcGDBhAcHAwFouFX3/91dshVdm+ffuwWCwsXLjQ26FUyYQJE4iLi6vSYy+88EIuvPBCj8WycOFCLBYLv/zyi8eOWdrv58knn8RisXjsOWpKXW9bnlLcLvbt2+fa5um2JyVZLBaefPJJb4cBQFxcHBMmTPB2GGWq7fGJeJKSK5Faxm63c+2115KWlsa//vUv3njjDVq3bu3R59iyZQtPPvmk28WYeEdubi4vvfQSQ4cOpWnTpoSGhtK7d29eeeUVHA6Ht8Orc7788stac8ErIiINj5IrkVpm9+7d7N+/n4ceeog77riDm266ifDwcI8+x5YtW5gxY4aSq1pgz5493HvvvRiGwZQpU3j++edp06YNkyZN4pZbbvFKTI8//jjHjx/3ynNXRuvWrTl+/Dg333yza9uXX37JjBkzvBhV7bBs2TKWLVvm7TBERBocH28HICLukpKSAGjcuLF3A5EzIjY2lj/++INu3bq5tt15553ccsstLFiwgCeeeIL27duf0Zh8fHzw8am9fx4KCwtxOp34+fkREBDg7XBqJT8/P2+HUK6cnByCg4O9HYbUQSe//0VqI/VcidQiEyZMYNCgQQBce+21WCwW17yJ33//nQkTJtC2bVsCAgKIjY3llltuITU1tcRxDh8+zK233kqzZs3w9/enTZs23H333RQUFLBw4UKuvfZaAC666CIsFgsWi4VVq1YBZc8jOHXMfFpaGg899BDdu3cnJCSEsLAwhg8fzm+//ebR18RisTB58mSWLFlC165dCQwMpH///vzxxx8AvPrqq7Rv356AgAAuvPDCUnvjlixZQt++fQkMDCQyMpKbbrqJw4cPl9jv448/5qyzziIgIICzzjqLjz76qNSYnE4nc+bMoVu3bgQEBBATE8Odd97JsWPHKn1+kZGRbolVsauuugqArVu3lrgvNzeXO++8kyZNmhAWFsa4ceOq9NxlKW3OVfHvofg18vf3p1u3bixdurTE4w8fPswtt9xCTEyMa7/58+e77VNQUMC0adPo27cvjRo1Ijg4mPPPP59vv/3Wbb/ieVXPP/88c+bMoV27dvj7+7Nly5YSc64mTJjASy+95Iq3+McwDOLi4rjyyitLxJqXl0ejRo248847y31NKnP+mzZtYvjw4YSFhRESEsIll1zC2rVr3fYpnif1008/MWXKFKKioggODuaqq64iOTm53Fgq4tQ5V6tWrcJisfDee+/x97//nRYtWhAQEMAll1zCrl27Sjx+3bp1XHrppTRq1IigoCAGDRrETz/95LbP/v37mTRpEp06dSIwMJAmTZpw7bXXlngPFp/rd999x6RJk4iOjqZFixZVOq+vvvqK888/n+DgYEJDQxkxYgR//vmn2z4TJkwgJCSEw4cPM2rUKEJCQoiKiuKhhx4qMdTW6XTy73//m+7duxMQEEBUVBSXXnqp27zG/Px8HnzwQaKioggNDeWKK67g0KFDpcZXkbYPZrt78skn6dixIwEBATRt2pSrr76a3bt3l3v+hmHw9NNP06JFC4KCgrjoootKnH+x9PR0HnjgAVq2bIm/vz/t27fnH//4B06ns9KvQWFhITNnznS9/+Li4njsscfIz8+v0fjKe/+L1Fa196tJkQbozjvvpHnz5jzzzDPcd999nHPOOcTExACwfPly9uzZw8SJE4mNjeXPP//ktdde488//2Tt2rWui+EjR47Qr18/0tPTueOOO+jcuTOHDx/m/fffJzc3lwsuuID77ruPF154gccee4wuXboAuP6tqD179vDxxx9z7bXX0qZNGxITE3n11VcZNGgQW7ZsoVmzZh57XX744Qc+/fRT7rnnHgBmzZrF5ZdfzsMPP8zLL7/MpEmTOHbsGM8++yy33HILK1eudD124cKFTJw4kXPOOYdZs2aRmJjIv//9b3766Sc2bdrk6iFctmwZo0ePpmvXrsyaNYvU1FQmTpxY6kXgnXfe6Trufffdx969e/nPf/7Dpk2b+Omnn/D19a32OSckJABm8nWqyZMn07hxY5588km2b9/OK6+8wv79+10X0DXlxx9/5MMPP2TSpEmEhobywgsvMHr0aA4cOECTJk0ASExM5Nxzz3UlI1FRUXz11VfceuutZGZm8sADDwCQmZnJf//7X8aOHcvtt99OVlYW8+bNY9iwYaxfv55evXq5PfeCBQvIy8vjjjvuwN/fn4iIiBIXiXfeeSdHjhxh+fLlvPHGG67tFouFm266iWeffZa0tDQiIiJc93322WdkZmZy0003eeT8//zzT84//3zCwsJ4+OGH8fX15dVXX+XCCy/ku+++Iz4+3u2Y9957L+Hh4UyfPp19+/YxZ84cJk+ezOLFiyv8e6mM//u//8NqtfLQQw+RkZHBs88+y4033si6detc+6xcuZLhw4fTt29fpk+fjtVqZcGCBVx88cX88MMP9OvXDzAL76xevZoxY8bQokUL9u3bxyuvvMKFF17Ili1bCAoKcnvuSZMmERUVxbRp08jJyal07G+88Qbjx49n2LBh/OMf/yA3N5dXXnmFgQMHsmnTJrfCMw6Hg2HDhhEfH8/zzz/PN998wz//+U/atWvH3Xff7drv1ltvZeHChQwfPpzbbruNwsJCfvjhB9auXcvZZ58NwG233cabb77JDTfcwIABA1i5ciUjRowoEV9F277D4eDyyy9nxYoVjBkzhvvvv5+srCyWL1/O5s2badeuXZmvwbRp03j66ae57LLLuOyyy9i4cSNDhw6loKDAbb/c3FwGDRrE4cOHufPOO2nVqhWrV69m6tSpHD16lDlz5lT6NVi0aBHXXHMNf/nLX1i3bh2zZs1i69atbl9C1UR8UPr7X6TWMkSkVvn2228NwFiyZInb9tzc3BL7vvPOOwZgfP/9965t48aNM6xWq/Hzzz+X2N/pdBqGYRhLliwxAOPbb78tsQ9gTJ8+vcT21q1bG+PHj3fdzsvLMxwOh9s+e/fuNfz9/Y2nnnrKbRtgLFiwoLTTPS3A8Pf3N/bu3eva9uqrrxqAERsba2RmZrq2T5061QBc+xYUFBjR0dHGWWedZRw/fty13+eff24AxrRp01zbevXqZTRt2tRIT093bVu2bJkBGK1bt3Zt++GHHwzAeOutt9ziXLp0aYntgwYNMgYNGlTpc87Pzze6du1qtGnTxrDb7a7tCxYsMACjb9++RkFBgWv7s88+awDGJ598UunnKu33M336dOPUPw+A4efnZ+zatcu17bfffjMA48UXX3Rtu/XWW42mTZsaKSkpbo8fM2aM0ahRI1c7LiwsNPLz8932OXbsmBETE2PccsstJeILCwszkpKSThv7PffcUyJ2wzCM7du3G4DxyiuvuG2/4oorjLi4ONd7oywVPf9Ro0YZfn5+xu7du13bjhw5YoSGhhoXXHCBa1vx73Lw4MFuz/3ggw8aNpvNrR2eTvGxTn6PnNr2ij9XunTp4va6//vf/zYA448//jAMw/yM6NChgzFs2DC3uHJzc402bdoYQ4YMcdt2qjVr1hiA8b///a9EfAMHDjQKCwsrfF4ny8rKMho3bmzcfvvtbtsTEhKMRo0auW0fP368Abh9DhmGYfTu3dvo27ev6/bKlSsNwLjvvvtKPF/xuf/6668GYEyaNMnt/htuuKHEZ2VF2/78+fMNwJg9e3aZz1uapKQkw8/PzxgxYoTbfo899pgBuH0+z5w50wgODjZ27NjhdoxHH33UsNlsxoEDByr9Gtx2221u9z/00EMGYKxcubLG4ivv/S9SW2lYoEgdERgY6Pp/Xl4eKSkpnHvuuQBs3LgRMId3fPzxx4wcOdL1jePJPNmr4e/vj9VqfoQ4HA5SU1MJCQmhU6dOrng85ZJLLnH7Vrr42//Ro0cTGhpaYvuePXsA+OWXX0hKSmLSpEluc3NGjBhB586d+eKLLwA4evQov/76K+PHj6dRo0au/YYMGULXrl3dYlmyZAmNGjViyJAhpKSkuH769u1LSEhIiWFtVTF58mS2bNnCf/7zn1LnPt1xxx1uvWN33303Pj4+fPnll9V+7vIMHjzY7Vv1Hj16EBYW5nq9DcPggw8+YOTIkRiG4fb6DBs2jIyMDFfbsNlsrjkTTqeTtLQ0CgsLOfvss0ttP6NHjyYqKqrKsXfs2JH4+Hjeeust17a0tDS++uorbrzxxgq9N053/g6Hg2XLljFq1Cjatm3r2q9p06bccMMN/Pjjj2RmZrod84477nB77vPPPx+Hw8H+/furfK7lmThxottclfPPPx848Z759ddf2blzJzfccAOpqamu319OTg6XXHIJ33//vavH8OTPJLvdTmpqKu3bt6dx48al/g5vv/12bDZbleJevnw56enpjB071q1d2Ww24uPjS33f3XXXXW63zz//fNd5AnzwwQdYLBamT59e4rHFv5Pi99R9993ndn9xL1SxyrT9Dz74gMjISO69994yn7c033zzDQUFBdx7771u+50aC5ifU+effz7h4eFusQwePBiHw8H3339f6ddgypQpbvf/5S9/AXB9jtZEfMWq+/4XOZM0LFCkjkhLS2PGjBm8++67rqIXxTIyMgBITk4mMzOTs846q8bjKR6n//LLL7N37163uQzFQ6Q8pVWrVm63ixOgli1blrq9eP5R8QVqp06dShyzc+fO/Pjjj277dejQocR+pyaLO3fuJCMjg+jo6FJjPfV3U1nPPfccr7/+OjNnzuSyyy4rdZ9T4wwJCaFp06Y1Xv3x1N8DQHh4uOv1Tk5OJj09nddee43XXnut1GOc/PosWrSIf/7zn2zbtg273e7a3qZNmxKPK21bZY0bN47Jkyezf/9+WrduzZIlS7Db7W7VBstTkfPPzc0ttb116dIFp9PJwYMH3ebYnXrM4sqgnpxDd7LTPd/OnTsBGD9+fJnHyMjIIDw8nOPHjzNr1iwWLFjA4cOHMQzDbZ9TVed3WBzXxRdfXOr9YWFhbreL5w6d7OTfFZiVWZs1a1buELP9+/djtVpLDNU79Xdcmba/e/duOnXqVOmiMWV9TkVFRZWoKLtz505+//33MhOSk2Op6GtwamGd2NhYGjdu7IqrJuIr5on3v8iZouRKpI647rrrWL16NX/961/p1asXISEhOJ1OLr300hJzT2rCqRPBn3nmGZ544gluueUWZs6cSUREBFarlQceeMDj8ZT1bXdZ20++yPM0p9NJdHS0Ww/Iyarz7erChQt55JFHuOuuu3j88cerfJyacrrXu/j3ftNNN5V5cd6jRw8A3nzzTSZMmMCoUaP461//SnR0NDabjVmzZpU6qf/kXpKqGjNmDA8++CBvvfUWjz32GG+++SZnn312qclQaWqivZ3pNlzR3+Fzzz1XYt5bsZCQEMCcL7ZgwQIeeOAB+vfvT6NGjbBYLIwZM6bUz4Dq/A6Lj/fGG28QGxtb4v5TE5Wq9pBVVWXa/pmKZ8iQITz88MOl3t+xY8dKH9OTIx8qG58n3v8iZ4qSK5E64NixY6xYsYIZM2Ywbdo01/bib3OLRUVFERYWxubNm8s9Xnl/JMPDw0lPT3fbVlBQwNGjR922vf/++1x00UXMmzfPbXt6enqpRRi8oXjx5e3bt5f4xnv79u2u+4v/PfX1LN7vZO3ateObb77hvPPO8+gf/E8++YTbbruNq6++2lXxriw7d+7koosuct3Ozs7m6NGjZfZ0nSnF1dQcDgeDBw8ud9/333+ftm3b8uGHH7q1x9KGJ1VGeW07IiKCESNG8NZbb3HjjTfy008/lZg4Xx1RUVEEBQWVaDMA27Ztw2q1luhtrW2Ke2jCwsIq9DscP348//znP13b8vLySnx+eDKu6Ojo08ZVmWN+/fXXJYqcnKx169Y4nU5Xb1OxU3/HlWn77dq1Y926ddjt9koVvzn5c+rkYafJycklejrbtWtHdnZ2hWKp6Guwc+dOt8JHiYmJpKenl/o56qn4ROoizbkSqQOKv4U99dvsUy8MrVYro0aN4rPPPnMro1us+PHF68uUdhHUrl27EuPdX3vttRI9VzabrUQ8S5YsKbXEubecffbZREdHM3fuXLeSwV999RVbt251Vfxq2rQpvXr1YtGiRW7DmZYvX16i5O91112Hw+Fg5syZJZ6vsLCwSheW33//PWPGjOGCCy7grbfecs1lK8trr73mNozulVdeobCwkOHDh1f6uT3JZrMxevRoPvjgg1IT/JNLjJfWptetW8eaNWuqFUN5bRvg5ptvZsuWLfz1r3/FZrMxZsyYaj3fyWw2G0OHDuWTTz5xG6KZmJjI22+/zcCBA0sMX6tt+vbtS7t27Xj++efJzs4ucf+pv8NTPwNefPHFEp8VnjBs2DDCwsJ45pln3Np+aXFV1OjRozEMo9RFp4vPq/g99cILL7jdf+pnb2Xa/ujRo0lJSeE///lPmc9bmsGDB+Pr68uLL77otl9pXxBcd911rFmzhq+//rrEfenp6RQWFrpiOd1rUPylzanPM3v2bADX52hNxCdSF6nnSqQOCAsL44ILLuDZZ5/FbrfTvHlzli1bxt69e0vs+8wzz7Bs2TIGDRrEHXfcQZcuXTh69ChLlizhxx9/pHHjxvTq1QubzcY//vEPMjIy8Pf35+KLLyY6OprbbruNu+66i9GjRzNkyBB+++03vv766xK9UZdffjlPPfUUEydOZMCAAfzxxx+89dZbbt9YlmXfvn20adOG8ePHu9Yoqgm+vr784x//YOLEiQwaNIixY8e6SrHHxcXx4IMPuvadNWsWI0aMYODAgdxyyy2kpaXx4osv0q1bN7eLzEGDBnHnnXcya9Ysfv31V4YOHYqvry87d+5kyZIl/Pvf/+aaa66pcIz79+/niiuuwGKxcM0117BkyRK3+3v06FFiOFFBQQGXXHIJ1113Hdu3b+fll19m4MCBXHHFFa59ikvFL1iwwG19spr2f//3f3z77bfEx8dz++2307VrV9LS0ti4cSPffPMNaWlpgNl+PvzwQ6666ipGjBjB3r17mTt3Ll27di31or6i+vbtC5gFCIYNG1YigRoxYgRNmjRhyZIlDB8+vMy5c1X19NNPs3z5cgYOHMikSZPw8fHh1VdfJT8/n2effdajz1UTrFYr//3vfxk+fDjdunVj4sSJNG/enMOHD/Ptt98SFhbGZ599Bpi/wzfeeINGjRrRtWtX1qxZwzfffFPpOZcWi4VBgwa51torTVhYGK+88go333wzffr0YcyYMURFRXHgwAG++OILzjvvvFKTlfJcdNFF3Hzzzbzwwgvs3LnTNcT6hx9+4KKLLmLy5Mn06tWLsWPH8vLLL5ORkcGAAQNYsWJFqWuDVbTtjxs3jv/9739MmTKF9evXc/7555OTk8M333zDpEmTSl2PDXCt1VW8FMVll13Gpk2b+Oqrr0p8Pv/1r3/l008/5fLLL2fChAn07duXnJwc/vjjD95//3327dtHZGRkhV6Dnj17Mn78eF577TXS09MZNGgQ69evZ9GiRYwaNcrVi14T8YnUSWeyNKGInF5ZpdgPHTpkXHXVVUbjxo2NRo0aGddee61x5MiRUkun79+/3xg3bpwRFRVl+Pv7G23btjXuuecetxLMr7/+utG2bVvDZrO5lWV3OBzGI488YkRGRhpBQUHGsGHDjF27dpVaiv0vf/mL0bRpUyMwMNA477zzjDVr1pQoAV1auew//vjDAIxHH330tK8HYNxzzz1u24qP+dxzz1XotVu8eLHRu3dvw9/f34iIiDBuvPFG49ChQyWe64MPPjC6dOli+Pv7G127djU+/PBDY/z48W6l2Iu99tprRt++fY3AwEAjNDTU6N69u/Hwww8bR44cce1TkVLsxTGX9XPy77a4pPV3331n3HHHHUZ4eLgREhJi3HjjjUZqaqrbcV988UUDMJYuXVru81emFPupvwfDKFmi3zAMIzEx0bjnnnuMli1bGr6+vkZsbKxxySWXGK+99pprH6fTaTzzzDNG69atDX9/f6N3797G559/XuL1Lut3XVbshYWFxr333mtERUUZFoul1LLskyZNMgDj7bffLve1qer5b9y40Rg2bJgREhJiBAUFGRdddJGxevVqt32Kf5enLplQ3B5KWyahLJUpxX7qe6OspRI2bdpkXH311UaTJk0Mf39/o3Xr1sZ1111nrFixwrXPsWPHjIkTJxqRkZFGSEiIMWzYMGPbtm0lXpOyztUwzBLrgDFmzJgKneu3335rDBs2zGjUqJEREBBgtGvXzpgwYYLxyy+/uPYZP368ERwcXOKxpbXrwsJC47nnnjM6d+5s+Pn5GVFRUcbw4cONDRs2uPY5fvy4cd999xlNmjQxgoODjZEjRxoHDx4s9bO3Im3fMMwy9n/729+MNm3auPa75ppr3Er4l8bhcBgzZsxwfe5eeOGFxubNm0tth1lZWcbUqVON9u3bG35+fkZkZKQxYMAA4/nnn3dbyqEir4HdbjdmzJjhirdly5bG1KlTjby8vBqNr7z3v0htZTGMGpz5LSJSipdffpmHH36Y3bt3uxZJFs+67rrr2LdvH+vXr/d2KLXOgw8+yLx580hISCix0K2cWV9++SWXX345v/32G927d/d2OCIi1aZhgSJyxn377bfcd999SqxqiGEYrFq1ijfffNPbodQ6eXl5vPnmm4wePVqJVS3w7bffMmbMGCVWIlJvqOdKRETqvaSkJL755hvef/99Pv74YzZu3FhmqfHaIjs7+7Tzz6Kios542XERESmbeq5ERKTe27JlCzfeeCPR0dG88MILtT6xAnj++edLreJ2sr179xIXF3dmAhIRkdNSz5WIiEgttGfPHvbs2VPuPgMHDiQgIOAMRSQiIqfj9XWuXnrpJeLi4ggICCA+Pr7cydd2u52nnnqKdu3aERAQQM+ePVm6dGm1jikiIlIbtW3blsGDB5f7o8RKRKR28WpytXjxYqZMmcL06dPZuHEjPXv2ZNiwYSQlJZW6/+OPP86rr77Kiy++yJYtW7jrrru46qqr2LRpU5WPKSIiIiIi4gleHRYYHx/POeec41r4z+l00rJlS+69914effTREvs3a9aMv/3tb9xzzz2ubaNHjyYwMNBVFauyxyyN0+nkyJEjhIaGYrFYqnuaIiIiIiJSRxmGQVZWFs2aNcNqLb9vymsFLQoKCtiwYQNTp051bbNarQwePJg1a9aU+pj8/PwSQyACAwP58ccfq3zM4uPm5+e7bh8+fJiuXbtW6bxERERERKT+OXjwIC1atCh3H68lVykpKTgcjhLr3MTExLBt27ZSHzNs2DBmz57NBRdcQLt27VixYgUffvghDoejyscEmDVrVqkVmf773/9qHRQRERERkQYsNzeX2267jdDQ0NPuW6dKsf/73//m9ttvp3PnzlgsFtq1a8fEiROZP39+tY47depUpkyZ4rqdmZlJy5YtGTVqFGFhYdUNu1rsdjvLly9nyJAh+Pr6ejUWqX3UPqQsahtSHrUPKYvahpSnobaPzMxMbrvttgpNF/JachUZGYnNZiMxMdFte2JiIrGxsaU+Jioqio8//pi8vDxSU1Np1qwZjz76KG3btq3yMQH8/f3x9/cvsd3X17fWNJzaFIvUPmofUha1DSmP2oeURW1DytPQ2kdlztVr1QL9/Pzo27cvK1ascG1zOp2sWLGC/v37l/vYgIAAmjdvTmFhIR988AFXXnlltY8pIiIiIiJSHV4dFjhlyhTGjx/P2WefTb9+/ZgzZw45OTlMnDgRgHHjxtG8eXNmzZoFwLp16zh8+DC9evXi8OHDPPnkkzidTh5++OEKH1NERERERKQmeDW5uv7660lOTmbatGkkJCTQq1cvli5d6ipIceDAAbdyh3l5eTz++OPs2bOHkJAQLrvsMt544w0aN25c4WOKiIiIiIjUBK8XtJg8eTKTJ08u9b5Vq1a53R40aBBbtmyp1jFFRERERERqgtfmXImIiIiIiNQnSq5EREREREQ8QMmViIiIiIiIByi5EhERERER8QAlVyIiIiIiIh6g5EpERERERMQDlFyJiIiIiIh4gJIrERERERERD1ByJSIiIiIi4gFKrkRERERERDxAyZWIiIiIiIgHKLkSEREREZFaw+5wsuCnvWxLyMQwDG+HUylKrkREREREpNb443AGMz7bwpjX1lLHcislVyIiIiIiUnus2Z0KQP+2TbBaLV6OpnKUXImIiIiISK2xencKAP3bNfFyJJWn5EpERERERGqF/EIHv+w7BsAAJVciIiIiIiJVs+lAOvmFTqJC/WkXFeLtcCpNyZWIiIiIiNQKq0+ab2Wx1K35VqDkSkREREREaom1RclVXRwSCEquRERERESkFsgtKGTTweL5VpFejqZqlFyJiIiIiIjX/bLvGHaHQfPGgbSMCPR2OFWi5EpERERERLxuzZ6i+Vbt6uZ8K1ByJSIiIiIitcDqOj7fCpRciYiIiIiIl2Xm2fnjUDpQNxcPLqbkSkREREREvOrnvWk4DWgTGUzTRnVzvhUouRIRERERES8rHhJ4btu622sFSq5ERERERMTL6sN8K1ByJSIiIiIiXnQsp4CtRzMB9VyJiIiIiIhU2dqiEuwdY0KICvX3cjTVo+RKRERERES8pnh9qwHtIr0cSfUpuRIREREREa8pnm9Vl0uwF1NyJSIiIiIiXpGUmceupGwsFji3jZIrERERERGRKikeEtitWRiNgny9HE31KbkSERERERGvWLO7/sy3AiVXIiIiIiLiJa75VnW8BHsxJVciIiIiInLGHTqWy4G0XGxWC+e0ifB2OB6h5EpERERERM644iGBPVs0IsTfx8vReIaSKxEREREROePW1KMS7MWUXImIiIiIyBllGEa9Wjy4mJIrERERERE5o/al5nI0Iw8/m5W+rcO9HY7HKLkSEREREZEzavXuFAB6t2pMgK/Ny9F4jteTq5deeom4uDgCAgKIj49n/fr15e4/Z84cOnXqRGBgIC1btuTBBx8kLy/Pdf+TTz6JxWJx++ncuXNNn4aIiIiIiFRQfVvfqphXy3IsXryYKVOmMHfuXOLj45kzZw7Dhg1j+/btREdHl9j/7bff5tFHH2X+/PkMGDCAHTt2MGHCBCwWC7Nnz3bt161bN7755hvXbR+f+lF9RERERESkrjMM40Ry1b7+FLMAL/dczZ49m9tvv52JEyfStWtX5s6dS1BQEPPnzy91/9WrV3Peeedxww03EBcXx9ChQxk7dmyJ3i4fHx9iY2NdP5GR9SsjFhERERGpq3YkZpOaU0Cgr42eLRp7OxyP8lqXTkFBARs2bGDq1KmubVarlcGDB7NmzZpSHzNgwADefPNN1q9fT79+/dizZw9ffvklN998s9t+O3fupFmzZgQEBNC/f39mzZpFq1atyowlPz+f/Px81+3MzEwA7HY7dru9OqdZbcXP7+04pHZS+5CyqG1IedQ+pCxqG1IeT7WPH3cmAdC3dWMshgO73VHt2GpSZc7XYhiGUYOxlOnIkSM0b96c1atX079/f9f2hx9+mO+++45169aV+rgXXniBhx56CMMwKCws5K677uKVV15x3f/VV1+RnZ1Np06dOHr0KDNmzODw4cNs3ryZ0NDQUo/55JNPMmPGjBLb3377bYKCgqp5piIiIiIiUuy/26z8cczKyFYOBjf3SipSKbm5udxwww1kZGQQFhZW7r51ajLSqlWreOaZZ3j55ZeJj49n165d3H///cycOZMnnngCgOHDh7v279GjB/Hx8bRu3Zr33nuPW2+9tdTjTp06lSlTprhuZ2Zm0rJlS4YOHXraF7Cm2e12li9fzpAhQ/D19fVqLFL7qH1IWdQ2pDxqH1IWtQ0pjyfah8Np8MSmb4FCxg8fQM8WjTwbZA0oHtVWEV5LriIjI7HZbCQmJrptT0xMJDY2ttTHPPHEE9x8883cdtttAHTv3p2cnBzuuOMO/va3v2G1lpxC1rhxYzp27MiuXbvKjMXf3x9/f/8S2319fWvNB0ttikVqH7UPKYvahpRH7UPKorYh5alO+9h+OIPMvEJC/X3o1SoCH5vXi5efVmXO1Wtn4+fnR9++fVmxYoVrm9PpZMWKFW7DBE+Wm5tbIoGy2cy6+GWNbszOzmb37t00bdrUQ5GLiIiIiEhVFK9vFd+2biRWleXVYYFTpkxh/PjxnH322fTr1485c+aQk5PDxIkTARg3bhzNmzdn1qxZAIwcOZLZs2fTu3dv17DAJ554gpEjR7qSrIceeoiRI0fSunVrjhw5wvTp07HZbIwdO9Zr5ykiIiIiIrC6qAT7uW3rVwn2Yl5Nrq6//nqSk5OZNm0aCQkJ9OrVi6VLlxITEwPAgQMH3HqqHn/8cSwWC48//jiHDx8mKiqKkSNH8ve//921z6FDhxg7diypqalERUUxcOBA1q5dS1RU1Bk/PxERERERMdkdTn7emwbUv8WDi3m9oMXkyZOZPHlyqfetWrXK7baPjw/Tp09n+vTpZR7v3Xff9WR4IiIiIiLiAb8fyiCnwEF4kC+dY0uv4l3X1b+BjiIiIiIiUuus3XNiSKDVavFyNDVDyZWIiIiIiNS44mIWA9rVz/lWoORKRERERERqWH6hg1/2HQOgfz2dbwVKrkREREREpIZtOpBOfqGTqFB/2kUFezucGqPkSkREREREalRxCfYB7ZpgsdTP+Vag5EpERERERGrYmqL5Vv3r6fpWxZRciYiIiIhIjcktKOTXg+lA/V3fqpiSKxERERERqTG/7DuG3WHQvHEgLSMCvR1OjVJyJSIiIiIiNaZ4vlX/ej7fCpRciYiIiIhIDVqz50Qxi/pOyZWIiIiIiNSIzDw7fxxKB8yeq/pOyZWIiIiIiNSI9XvScBrQJjKYpo3q93wrUHIlIiIiIiI1pHhIYKV7rTKPgNNRAxHVLCVXIiIiIiJSI05ePLjCUnbC6xfDx5PqXIKl5EpERERERDwuLaeArUczATi3oosHJ++AhZdD1lFI+B3yM2swQs/z8XYAIiIiIiJS/6wrGhLYKSaUyBD/0z8gebuZWOUkQcxZMO4TCAyv4Sg9S8mViIiIiIh43MnrW51W0jZYdDnkJENsd7j5Ewiue9UFlVyJiIiIiIjHrd6dAlQguUrcAotGQm4KxPYwe6yCIs5AhJ6nOVciIiIiIuJRSZl57E7OwWKBc9uUk1wl/mn2WOWmQNOedTqxAvVciYiIiIiIhxWXYD+rWSMaBfmWvlPCH7DoCjieBs16w80f1bk5VqdSciUiIiIiIh61etdp5lsd/R3+dwUcPwbN+hQlVo3PXIA1RMmViIiIiIh4VLmLBx/5Ff53JeSlQ/Oz4eYPIaDRGY2vpmjOlYiIiIiIeMyhY7kcSMvFx2rhnLhT5k8d2WT2WOWlQ4t+Zo9VPUmsQMmViIiIiIh40JqiEuw9WjQixP+kgXKHN8CiKyEvA1rGw00fQECYl6KsGRoWKCIiIiIiHlOcXA1oF3li46Ff4I2rID8TWvWHG5eAf6iXIqw56rkSERERERGPMAzDtXjwgOL5VgfXn0isWp8HN75fLxMrUM+ViIiIiIh4yL7UXBIy8/CzWenTOhwOrIM3R0NBFsSdDzcsBr9gb4dZY9RzJSIiIiIiHrF6dwoAfVo3JuDIenjz6gaTWIGSKxERERER8ZDiIYHXRB4s6rHKhjaD4Ib36n1iBUquRERERETEAwzDYO3uVOItW7lqy/1gz4G2FxX1WAV5O7wzQnOuRERERESk2nYkZtPx+Cbm+T2PrTAf2l0MY94G30Bvh3bGKLkSEREREZFq27v+C+b7PkegpQDaD4br3wLfAG+HdUZpWKCIiIiIiFTP7m+5eNO9BFoK2B8xsEEmVqDkSkREREREqmPXCox3xuBnFPCNozcZV8xvkIkVKLkSEREREZGq2vkNvDMWS2Eeyx19edj6EF1bRnk7Kq9RciUiIiIiIpW3Yxm8OxYc+eyNvIhJ9vvp0zYGH1vDTTEa7pmLiIiIiEjVbF8Ki28ERwF0GcnTQQ9jx4f+7SK9HZlXKbkSEREREZEKs+z4ChbfZCZWXa/EftU81uzLBKB/2yZejs67lFyJiIiIiEiFxKZvwPbBLeC0Q7erYPQ8fj+aS26Bg/AgXzrHhno7RK/SOlciIiIiInJalm2fc87e/2DBAWeNhqteA5sPa3anANC/XROsVouXo/Qu9VyJiIiIiEj5krdj++g2rDhwdjuRWAGs3p0KaEgg1ILk6qWXXiIuLo6AgADi4+NZv359ufvPmTOHTp06ERgYSMuWLXnwwQfJy8ur1jFFRERERKQcB9dhcRZyLKgtjitediVWeXYHG/YfA2jwxSzAy8nV4sWLmTJlCtOnT2fjxo307NmTYcOGkZSUVOr+b7/9No8++ijTp09n69atzJs3j8WLF/PYY49V+ZgiIiIiInIaOebQv6yAZmC1uTZvOpBOfqGT6FB/2kUFeyu6WsOrydXs2bO5/fbbmThxIl27dmXu3LkEBQUxf/78UvdfvXo15513HjfccANxcXEMHTqUsWPHuvVMVfaYIiIiIiJyGrnm0L8CH/eCFSfPt7JYGvZ8K/BiQYuCggI2bNjA1KlTXdusViuDBw9mzZo1pT5mwIABvPnmm6xfv55+/fqxZ88evvzyS26++eYqHxMgPz+f/Px81+3MTLOUpN1ux263V+s8q6v4+b0dh9ROah9SFrUNKY/ah5RFbUPKYstJwQrk+4S6tY/VRclVfFzjettuKnNeXkuuUlJScDgcxMTEuG2PiYlh27ZtpT7mhhtuICUlhYEDB2IYBoWFhdx1112uYYFVOSbArFmzmDFjRonty5YtIygoqLKnViOWL1/u7RCkFlP7kLKobUh51D6kLGobcqr4fVuJxey5Km4f+Q7YeMAGWMjb/ztfJv7u1RhrSm5uboX3rVOl2FetWsUzzzzDyy+/THx8PLt27eL+++9n5syZPPHEE1U+7tSpU5kyZYrrdmZmJi1btmTo0KGEhYV5IvQqs9vtLF++nCFDhuDr6+vVWKT2UfuQsqhtSHnUPqQsahtSFtuCOZBpJlfF7eOHnSk412+keeMAbr76Am+HWGOKR7VVhNeSq8jISGw2G4mJiW7bExMTiY2NLfUxTzzxBDfffDO33XYbAN27dycnJ4c77riDv/3tb1U6JoC/vz/+/v4ltvv6+taaD5baFIvUPmofUha1DSmP2oeURW1DSiiac5VvC3W1j/X7MwAY0C6yXreXypyb1wpa+Pn50bdvX1asWOHa5nQ6WbFiBf379y/1Mbm5uVit7iHbbGa1EsMwqnRMERERERE5jdw0AAp8QlybiotZDGiv9a2KeXVY4JQpUxg/fjxnn302/fr1Y86cOeTk5DBx4kQAxo0bR/PmzZk1axYAI0eOZPbs2fTu3ds1LPCJJ55g5MiRriTrdMcUEREREZFKKMyHgiwACnzMKTOZeXb+OGz2XPVvq/Wtink1ubr++utJTk5m2rRpJCQk0KtXL5YuXeoqSHHgwAG3nqrHH38ci8XC448/zuHDh4mKimLkyJH8/e9/r/AxRURERESkEoqGBBoWG3ZbIADr96ThNKBtZDCxjQK8GV2t4vWCFpMnT2by5Mml3rdq1Sq32z4+PkyfPp3p06dX+ZgiIiIiIlIJRckVQU3AYnZ8rN5tbuvfTkMCT+bVRYRFRERERKSWyzHnVhEU4dq0Zo+Sq9IouRIRERERkbIVDwsMMhOptJwCth41y5Of21bJ1cmUXImIiIiISNmKhwUGmonUur1m5cDOsaFEhpRczqghU3IlIiIiIiJlc/VcmcMC1+09BqjXqjRKrkREREREpGwnF7QA1uwxe64GaL5VCUquRERERESkbK6CFk3IKIA9KTlYLRCvnqsSlFyJiIiIiEjZTiposTPDAkC3Zo1oFOjrzahqJSVXIiIiIiJStpMKWuzMNJMrDQksnZIrEREREREp20kFLYp7rrS+VemUXImIiIiISOkMw5VcHbWHkJpvwcdq4Zy4iNM8sGFSciUiIiIiIqXLywBnIQBrEsxNPVo0Itjfx4tB1V5KrkREREREpHTF8638Qli9PweAc9uo16osSq5ERERERKR0J823WrvXXN/q3Lbh3oyoVlNyJSIiIiIipStKrvL9IkjMzMfHYtC7ZWPvxlSLKbkSEREREZHSFS0gnE4oAK1CIMDX5s2IajUlVyIiIiIiUrqinqtMaxgA4f6GN6Op9ZRciYiIiIhI6YqSqzTDTK7CfL0ZTO2n5EpEREREREpXlFylOEMACPNTz1V5lFyJiIiIiEjpipKrI/ZgQD1Xp6PkSkRERERESldU0OJwfhAAoX7eDKb2U3IlIiIiIiKlK+q52p8XCECYr4YFlkfJlYiIiIiIlK4ouTrgSq68GUztp+RKRERERERKKiyA/EwA0oxQfG0Wgny8HFMtp+RKRERERERKOp4GgGGxkkEwkSH+WCxejqmWU3IlIiIiIiIlFRWzsPs1xsBKVIiqWZyOkisRERERESmpaL5Vrm84AJEh/t6Mpk5QciUiIiIiIiXlmj1X2dZGAESpDvtpKbkSEREREZGScs05V+mWUACi1HN1WkquRERERESkpKJhgalOM7mKDFVydTpKrkREREREpKSighZJjmAAFbSoACVXIiIiIiJSUlHP1RF7cXKlnqvTUXIlIiIiIiIlFRW0OJgXBECkClqclpIrEREREREpqaigRaIjBFDPVUUouRIRERERkZKK5lylGaGEBvgQ4GvzckC1n5IrERERERFxZxiuOVfHjFCiVCmwQpRciYiIiIiIu/wscNoBSCNUQwIrSMmViIiIiIi4KypmYbcGkIe/eq4qSMmViIiIiIi4KypmkePTGIDo0AAvBlN3KLkSERERERF3RcUssqyNANRzVUFKrkRERERExF1xMQtCASVXFaXkSkRERERE3BUlV8nFa1wpuaqQWpFcvfTSS8TFxREQEEB8fDzr168vc98LL7wQi8VS4mfEiBGufSZMmFDi/ksvvfRMnIqIiIiISN1XVNAisTAY0ALCFeXj7QAWL17MlClTmDt3LvHx8cyZM4dhw4axfft2oqOjS+z/4YcfUlBQ4LqdmppKz549ufbaa932u/TSS1mwYIHrtr+/GoSIiIiISIUU9VwdtpvJVXSYrqUrwuvJ1ezZs7n99tuZOHEiAHPnzuWLL75g/vz5PProoyX2j4iIcLv97rvvEhQUVCK58vf3JzY2tkIx5Ofnk5+f77qdmZkJgN1ux263V+p8PK34+b0dh9ROah9SFrUNKY/ah5RFbUOK2bKTsQJpRig2q4UQX0uDbR+VOV+vJlcFBQVs2LCBqVOnurZZrVYGDx7MmjVrKnSMefPmMWbMGIKDg922r1q1iujoaMLDw7n44ot5+umnadKkSanHmDVrFjNmzCixfdmyZQQFBVXijGrO8uXLvR2C1GJqH1IWtQ0pj9qHlEVtQ84/spsIIM0II9jm5OulX7nua2jtIzc3t8L7ejW5SklJweFwEBMT47Y9JiaGbdu2nfbx69evZ/PmzcybN89t+6WXXsrVV19NmzZt2L17N4899hjDhw9nzZo12Gy2EseZOnUqU6ZMcd3OzMykZcuWDB06lLCwsCqenWfY7XaWL1/OkCFD8PX19WosUvuofUhZ1DakPGofUha1DSnms2865Jg9Vy0iw7jssv4Ntn0Uj2qrCK8PC6yOefPm0b17d/r16+e2fcyYMa7/d+/enR49etCuXTtWrVrFJZdcUuI4/v7+pc7J8vX1rTUNpzbFIrWP2oeURW1DyqP2IWVR2xCOm4sIpxFKy7AAt/bQ0NpHZc7Vq9UCIyMjsdlsJCYmum1PTEw87XypnJwc3n33XW699dbTPk/btm2JjIxk165d1YpXRERERKTec9ghLwMwe66iVYa9wryaXPn5+dG3b19WrFjh2uZ0OlmxYgX9+/cv97FLliwhPz+fm2666bTPc+jQIVJTU2natGm1YxYRERERqddyzV4rJxYyCNEaV5Xg9XWupkyZwuuvv86iRYvYunUrd999Nzk5Oa7qgePGjXMreFFs3rx5jBo1qkSRiuzsbP7617+ydu1a9u3bx4oVK7jyyitp3749w4YNOyPnJCIiIiJSZxWVYc+xheHEqjWuKsHrc66uv/56kpOTmTZtGgkJCfTq1YulS5e6ilwcOHAAq9U9B9y+fTs//vgjy5YtK3E8m83G77//zqJFi0hPT6dZs2YMHTqUmTNnaq0rEREREZHTKVpAOAOzsFtUaIA3o6lTvJ5cAUyePJnJkyeXet+qVatKbOvUqROGYZS6f2BgIF9//bUnwxMRERERaTiKeq7SjBAADQusBK8PCxQRERERkVqkKLlKdJjJlQpaVJySKxEREREROSHHTK6SHeq5qiwlVyIiIiIickLxsEDCCPKzEexfK2YS1QlKrkRERERE5ISighbHjFD1WlWSkisRERERETmhqOcq1QhTGfZKUnIlIiIiIiInFM25OkYo0WFKripDyZWIiIiIiJzgKsUeqp6rSlJyJSIiIiIiJsNwT64056pSlFyJiIiIiIipIBsc+QCkoeSqspRciYiIiIiIqajXKg9/jhOg5KqSlFyJiIiIiIipqJhFOqEARIcGeDOaOkfJlYiIiIiImIp6rlKcIQDquaokJVciIiIiImI6qZiFxQIRwX5eDqhuUXIlIiIiIiKm3BTALGYREeSHr03pQmXo1RIREREREZOr5ypMQwKrQMmViIiIiIiYcop6rrTGVZUouRIREREREVNuGgBpqOeqKpRciYiIiIiIKVc9V9Wh5EpERERERExFc66OGaFEhSi5qiwlVyIiIiIiYipKrlJRz1VVKLkSERERERFwFMLxY4DZcxUdGuDlgOoeJVciIiIiIuJKrJxYSCdEPVdVoORKRERERERcxSwyjGAc2JRcVYGSKxEREREROWkB4VD8fKyEBfh4OaC6R8mViIiIiIicSK4IJTrUH4vF4uWA6h4lVyIiIiIiAjnmsMBjWuOqypRciYiIiIgI5KYBkGqEaY2rKlJyJSIiIiIiroIWx7TGVZUpuRIRERERkRMLCGtYYJUpuRIREREREbc5V1pAuGqUXImIiIiIiFu1QPVcVY2SKxERERERcRW0SDPClFxVkZIrEREREZGGzjAwigpaqOeq6pRciYiIiIg0dPZcLIV5gNlzFRni5+WA6iYlVyIiIiIiDV1RMYt8wxe/wBD8fWxeDqhuUnIlIiIiItLQuRWzUKXAqlJyJSIiIiLS0LmKWWi+VXUouRIRERERaeiKi1kouaqWSidXcXFxPPXUUxw4cKAm4hERERERkTPNNSwwjKgQJVdVVenk6oEHHuDDDz+kbdu2DBkyhHfffZf8/PyaiE1ERERERM6EnBM9V9FhSq6qqkrJ1a+//sr69evp0qUL9957L02bNmXy5Mls3LixSkG89NJLxMXFERAQQHx8POvXry9z3wsvvBCLxVLiZ8SIEa59DMNg2rRpNG3alMDAQAYPHszOnTurFJuIiIiISL1X3HOlYYHVUuU5V3369OGFF17gyJEjTJ8+nf/+97+cc8459OrVi/nz52MYRoWOs3jxYqZMmcL06dPZuHEjPXv2ZNiwYSQlJZW6/4cffsjRo0ddP5s3b8Zms3Httde69nn22Wd54YUXmDt3LuvWrSM4OJhhw4aRl5dX1dMVEREREam/ipKrY4QSFaJqgVVV5eTKbrfz3nvvccUVV/CXv/yFs88+m//+97+MHj2axx57jBtvvLFCx5k9eza33347EydOpGvXrsydO5egoCDmz59f6v4RERHExsa6fpYvX05QUJAruTIMgzlz5vD4449z5ZVX0qNHD/73v/9x5MgRPv7446qeroiIiIhI/aWeK4/wqewDNm7cyIIFC3jnnXewWq2MGzeOf/3rX3Tu3Nm1z1VXXcU555xz2mMVFBSwYcMGpk6d6tpmtVoZPHgwa9asqVA88+bNY8yYMQQHBwOwd+9eEhISGDx4sGufRo0aER8fz5o1axgzZkyJY+Tn57vNG8vMzATMBNJut1cojppS/PzejkNqJ7UPKYvahpRH7UPKorbRcNmyU7BiFrRoHGAttQ001PZRmfOtdHJ1zjnnMGTIEF555RVGjRqFr69viX3atGlTahJzqpSUFBwOBzExMW7bY2Ji2LZt22kfv379ejZv3sy8efNc2xISElzHOPWYxfedatasWcyYMaPE9mXLlhEUFHTaOM6E5cuXezsEqcXUPqQsahtSHrUPKYvaRsMzLOMoAUAGIaxe9Q1WS9n7NrT2kZubW+F9K51c7dmzh9atW5e7T3BwMAsWLKjsoStt3rx5dO/enX79+lXrOFOnTmXKlCmu25mZmbRs2ZKhQ4cSFhZW3TCrxW63s3z5coYMGVJqIisNm9qHlEVtQ8qj9iFlUdtooJwOfDblAGAJjuLyEZeVultDbR/Fo9oqotLJVVJSEgkJCcTHx7ttX7duHTabjbPPPrvCx4qMjMRms5GYmOi2PTExkdjY2HIfm5OTw7vvvstTTz3ltr34cYmJiTRt2tTtmL169Sr1WP7+/vj7lxxb6uvrW2saTm2KRWoftQ8pi9qGlEftQ8qittHA5GQAZjE6/7DI0/7uG1r7qMy5VrqgxT333MPBgwdLbD98+DD33HNPpY7l5+dH3759WbFihWub0+lkxYoV9O/fv9zHLlmyhPz8fG666Sa37W3atCE2NtbtmJmZmaxbt+60xxQRERERaXCKillkGEFEhAZ7OZi6rdI9V1u2bKFPnz4ltvfu3ZstW7ZUOoApU6Ywfvx4zj77bPr168ecOXPIyclh4sSJAIwbN47mzZsza9Yst8fNmzePUaNG0aRJE7ftFouFBx54gKeffpoOHTrQpk0bnnjiCZo1a8aoUaMqHZ+IiIiISL1WlFylGmGqFFhNlU6u/P39SUxMpG3btm7bjx49io9PpQ/H9ddfT3JyMtOmTSMhIYFevXqxdOlSV0GKAwcOYLW6d7Bt376dH3/8kWXLlpV6zIcffpicnBzuuOMO0tPTGThwIEuXLiUgQDX7RURERETc5KQA5hpX0UquqqXS2dDQoUOZOnUqn3zyCY0aNQIgPT2dxx57jCFDhlQpiMmTJzN58uRS71u1alWJbZ06dSp3kWKLxcJTTz1VYj6WiIiIiIicwrXGlXquqqvSydXzzz/PBRdcQOvWrenduzcAv/76KzExMbzxxhseD1BERERERGpQrtlzpQWEq6/SyVXz5s35/fffeeutt/jtt98IDAxk4sSJjB07tkFVDRERERERqRdy0wBII5T2Sq6qpfKTpDDXsbrjjjs8HYuIiIiIiJxhRk4KFop6rkJUo6A6qpRcgVk18MCBAxQUFLhtv+KKK6odlIiIiIiInBmO7BR8MAtaaFhg9VQ6udqzZw9XXXUVf/zxBxaLxVVYwmKxAOBwODwboYiIiIiI1JjCouQq1yecQD+bt8Op0yq9iPD9999PmzZtSEpKIigoiD///JPvv/+es88+u9TKfiIiIiIiUntZigpaEBTh3UDqgUr3XK1Zs4aVK1cSGRmJ1WrFarUycOBAZs2axX333cemTZtqIk4REREREakBtrxjAFhDorwcSd1X6Z4rh8NBaGgoAJGRkRw5cgSA1q1bs337ds9GJyIiIiIiNacgFx/HcQD8w5RcVVele67OOussfvvtN9q0aUN8fDzPPvssfn5+vPbaa7Rt27YmYhQRERERkZpQtIBwgWEjrFG4l4Op+yqdXD3++OPk5OQA8NRTT3H55Zdz/vnn06RJExYvXuzxAEVEREREpIYUJVdphBEVpjLs1VXp5GrYsGGu/7dv355t27aRlpZGeHi4q2KgiIiIiIjUAUXFLI4ZoUSFqAx7dVVqzpXdbsfHx4fNmze7bY+IiFBiJSIiIiJS1+SmAZBqaI0rT6hUcuXr60urVq20lpWIiIiISH2QU9RzpQWEPaLS1QL/9re/8dhjj5GWllYT8YiIiIiIyBnizDHnXKUaYUSHas5VdVV6ztV//vMfdu3aRbNmzWjdujXBwcFu92/cuNFjwYmIiIiISM3Jz0gkEEgnlIhgP2+HU+dVOrkaNWpUDYQhIiIiIiJnWkFWCoFAgV84NqtqKFRXpZOr6dOn10QcIiIiIiJyhhlFc64cgU28HEn9UOk5VyIiIiIiUj9YjptzrizBSq48odI9V1artdyy66okKCIiIiJSN/jmHzP/DY3yciT1Q6WTq48++sjttt1uZ9OmTSxatIgZM2Z4LDAREREREalBTicB9gwAAhpFezmY+qHSydWVV15ZYts111xDt27dWLx4MbfeeqtHAhMRERERkRqUl44VJwDB4UquPMFjc67OPfdcVqxY4anDiYiIiIhITco151tlGkFENgrxcjD1g0eSq+PHj/PCCy/QvHlzTxxORERERERqWlGlwDQjlKgQfy8HUz9UelhgeHi4W0ELwzDIysoiKCiIN99806PBiYiIiIhIDSnquUojlOiwAC8HUz9UOrn617/+5ZZcWa1WoqKiiI+PJzw83KPBiYiIiIhIzcjPTMIfs+eqY6h6rjyh0snVhAkTaiAMERERERE5k3LTzeQqw9KIYD+bt8OpFyo952rBggUsWbKkxPYlS5awaNEijwQlIiIiIiI1Kz8jyfzXr3G569hKxVU6uZo1axaRkZEltkdHR/PMM894JCgREREREalZjmyzoEVhQISXI6k/Kp1cHThwgDZt2pTY3rp1aw4cOOCRoEREREREpGYZRQUtCGri3UDqkUonV9HR0fz+++8ltv/22280aaJfjIiIiIhIXeBz3EyubCElR6VJ1VQ6uRo7diz33Xcf3377LQ6HA4fDwcqVK7n//vsZM2ZMTcQoIiIiIiIe5leQDoBvaLR3A6lHKl0tcObMmezbt49LLrkEHx/z4U6nk3HjxmnOlYiIiIhIHRFUeMz8t7GSK0+pdHLl5+fH4sWLefrpp/n1118JDAyke/futG7duibiExERERERT7MfJ8DIAyAkItbLwdQflU6uinXo0IEOHTp4MhYRERERETkTctMAsBs2mkRozpWnVHrO1ejRo/nHP/5RYvuzzz7Ltdde65GgRERERESk5jizkwE4RihRYQFejqb+qHRy9f3333PZZZeV2D58+HC+//57jwQlIiIiIiI1J/tYIgCpRihNQvy8HE39UenkKjs7Gz+/kr8AX19fMjMzPRKUiIiIiIjUnOxjCea/1kb42iqdEkgZKv1Kdu/encWLF5fY/u6779K1a1ePBCUiIiIiIjXneLo5LDDXt7F3A6lnKl3Q4oknnuDqq69m9+7dXHzxxQCsWLGCt99+m/fff9/jAYqIiIiIiGfZs5LMf/3DvRxJ/VLp5GrkyJF8/PHHPPPMM7z//vsEBgbSs2dPVq5cSURERE3EKCIiIiIiHuTITjX/DdD1uydVqRT7iBEjGDFiBACZmZm88847PPTQQ2zYsAGHw+HRAEVERERExLMsx83kyhKsMuyeVOXZa99//z3jx4+nWbNm/POf/+Tiiy9m7dq1lT7OSy+9RFxcHAEBAcTHx7N+/fpy909PT+eee+6hadOm+Pv707FjR7788kvX/U8++SQWi8Xtp3PnzpWOS0RERESkvvLNM9e58glRcuVJleq5SkhIYOHChcybN4/MzEyuu+468vPz+fjjj6tUzGLx4sVMmTKFuXPnEh8fz5w5cxg2bBjbt28nOjq6xP4FBQUMGTKE6Oho3n//fZo3b87+/ftp3Lix237dunXjm2++OXGSPlVeK1lEREREpN4JsKcD4N+45DW3VF2Fs46RI0fy/fffM2LECObMmcOll16KzWZj7ty5VX7y2bNnc/vttzNx4kQA5s6dyxdffMH8+fN59NFHS+w/f/580tLSWL16Nb6+vgDExcWV2M/Hx4fY2NgqxyUiIiIiUp+FONIBCG4c491A6pkKJ1dfffUV9913H3fffTcdOnSo9hMXFBSwYcMGpk6d6tpmtVoZPHgwa9asKfUxn376Kf379+eee+7hk08+ISoqihtuuIFHHnkEm83m2m/nzp00a9aMgIAA+vfvz6xZs2jVqlWZseTn55Ofn++6Xbxel91ux263V/dUq6X4+b0dh9ROah9SFrUNKY/ah5RFbaOBMJyEGlkABDeKqvDvu6G2j8qcb4WTqx9//JF58+bRt29funTpws0338yYMWOqFCBASkoKDoeDmBj3bDkmJoZt27aV+pg9e/awcuVKbrzxRr788kt27drFpEmTsNvtTJ8+HYD4+HgWLlxIp06dOHr0KDNmzOD8889n8+bNhIaGlnrcWbNmMWPGjBLbly1bRlBQUJXP0ZOWL1/u7RCkFlP7kLKobUh51D6kLGob9VxBDlfiBGDjb5vZsnV7pR7e0NpHbm5uhfe1GIZhVObgOTk5LF68mPnz57N+/XocDgezZ8/mlltuKTN5Kc2RI0do3rw5q1evpn///q7tDz/8MN999x3r1q0r8ZiOHTuSl5fH3r17XT1Vs2fP5rnnnuPo0aOlPk96ejqtW7dm9uzZ3HrrraXuU1rPVcuWLUlJSSEsLKzC51QT7HY7y5cvZ8iQIa6hkCLF1D6kLGobUh61DymL2kbDkLjvT1q8NYhsIxC/vx3AYrFU6HENtX1kZmYSGRlJRkbGaXODSld6CA4O5pZbbuGWW25h+/btzJs3j//7v//j0UcfZciQIXz66acVOk5kZCQ2m43ExES37YmJiWXOl2ratCm+vr5uQwC7dOlCQkICBQUF+Pn5lXhM48aN6dixI7t27SozFn9/f/z9/Uts9/X1rTUNpzbFIrWP2oeURW1DyqP2IWVR26jfctNTAMiwhtG8lOvn02lo7aMy51rlUuwAnTp14tlnn+XQoUO88847lXqsn58fffv2ZcWKFa5tTqeTFStWuPVkney8885j165dOJ1O17YdO3bQtGnTUhMrgOzsbHbv3k3Tpk0rFZ+IiIiISH2UcyzB/NfWyMuR1D/VSq6K2Ww2Ro0aVeFeq2JTpkzh9ddfZ9GiRWzdupW7776bnJwcV/XAcePGuRW8uPvuu0lLS+P+++9nx44dfPHFFzzzzDPcc889rn0eeughvvvuO/bt28fq1au56qqrsNlsjB071hOnKiIiIiJSp+VlJpv/+oV7OZL6x6sLQF1//fUkJyczbdo0EhIS6NWrF0uXLnUVuThw4ABW64n8r2XLlnz99dc8+OCD9OjRg+bNm3P//ffzyCOPuPY5dOgQY8eOJTU1laioKAYOHMjatWuJioo64+cnIiIiIlLbOLLM5MruH+HlSOofr6+uO3nyZCZPnlzqfatWrSqxrX///qxdu7bM47377rueCk1EREREpN4xclPNfwOVXHmaR4YFioiIiIhI3WA7ngaANUQjuzxNyZWIiIiISAPiV3AMAP+wSC9HUv8ouRIRERERaUAC7ekABDSO8W4g9ZCSKxERERGRBsIwDMKcGQCEhiu58jQlVyIiIiIiDUTm8UIakwVAo0itA+tpSq5ERERERBqI5IwMQi3HAfAPU0ELT1NyJSIiIiLSQKSnJADgwAr+jbwcTf2j5EpEREREpIHISks0/7U2AqtSAU/TKyoiIiIi0kAcTzeTq1wf9VrVBCVXIiIiIiINREFmivmvf4SXI6mflFyJiIiIiDQQzuxkABwBSq5qgpIrEREREZEGwnI8zfw3qImXI6mflFyJiIiIiDQQtjwzufIJVRn2mqDkSkRERESkgQiwHwPAv5GSq5qg5EpEREREpAGwO5yEFGYAENQ4xsvR1E9KrkREREREGoDU7AIiLFkABCu5qhFKrkREREREGoDkrHxXcmUNifRyNPWTkisRERERkQYgKfM44ZjJFaoWWCOUXImIiIiINADpx1LwtTjMG0quaoSSKxERERGRBiDnWBIA+dZA8A3wcjT1k5IrEREREZEGID/TTK7yfBt7N5B6TMmViIiIiEgDYM9KNv/1j/ByJPWXkisRERERkQbAyEkBwBmo+VY1RcmViIiIiEgDYD2eZv4bouSqpii5EhERERGp5wzDwC//GAB+odFejqb+UnIlIiIiIlLP5RQ4CHNmABDQOMrL0dRfSq5EREREROq55Kx8wi3mAsLquao5Sq5EREREROq5pMw8mhQlV1pAuOYouRIRERERqeeSs/MJpyi5Co70bjD1mJIrEREREZF6Ljkrnwj1XNU4JVciIiIiIvVcakY2YZZc84aSqxqj5EpEREREpJ7LSU8CwIkVAhp7N5h6TMmViIiIiEg9Z89MBqDArzFYlQLUFL2yIiIiIiL1nCM7xfw3IMLLkdRvSq5EREREROo5y/FU8z+ab1WjlFyJiIiIiNRjDqeBb14aALZQlWGvSUquRERERETqsdScfBoXrXHlFxbt5WjqNyVXIiIiIiL1mLnGVSYAVg0LrFFKrkRERERE6jG3BYSDNSywJim5EhERERGpx5Kz8okoGhaoghY1S8mViIiIiEg9lpx9Us+Vkqsa5fXk6qWXXiIuLo6AgADi4+NZv359ufunp6dzzz330LRpU/z9/enYsSNffvlltY4pIiIiIlJfJWXmE67k6ozwanK1ePFipkyZwvTp09m4cSM9e/Zk2LBhJCUllbp/QUEBQ4YMYd++fbz//vts376d119/nebNm1f5mCIiIiIi9VlyVh4RmAUtlFzVLK8mV7Nnz+b2229n4sSJdO3alblz5xIUFMT8+fNL3X/+/PmkpaXx8ccfc9555xEXF8egQYPo2bNnlY8pIiIiIlKfZWcew8/iMG8ouapRPt564oKCAjZs2MDUqVNd26xWK4MHD2bNmjWlPubTTz+lf//+3HPPPXzyySdERUVxww038Mgjj2Cz2ap0TID8/Hzy8/NdtzMzzczebrdjt9ure6rVUvz83o5Daie1DymL2oaUR+1DyqK2UT8VZpojuBy2QJwWX6ji77ehto/KnK/XkquUlBQcDgcxMTFu22NiYti2bVupj9mzZw8rV67kxhtv5Msvv2TXrl1MmjQJu93O9OnTq3RMgFmzZjFjxowS25ctW0ZQUFAVzs7zli9f7u0QpBZT+5CyqG1IedQ+pCxqG/WLPSsJfCDXEszKU2oVVEVDax+5ubkV3tdryVVVOJ1OoqOjee2117DZbPTt25fDhw/z3HPPMX369Cofd+rUqUyZMsV1OzMzk5YtWzJ06FDCwsI8EXqV2e12li9fzpAhQ/D19fVqLFL7qH1IWdQ2pDxqH1IWtY3653iBg0/WPQdAYJNmXHbZZVU+VkNtH8Wj2irCa8lVZGQkNpuNxMREt+2JiYnExsaW+pimTZvi6+uLzWZzbevSpQsJCQkUFBRU6ZgA/v7++Pv7l9ju6+tbaxpObYpFah+1DymL2oaUR+1DyqK2UX8czbS7yrDbQqKweOD32tDaR2XO1WsFLfz8/Ojbty8rVqxwbXM6naxYsYL+/fuX+pjzzjuPXbt24XQ6Xdt27NhB06ZN8fPzq9IxRURERETqq+TsPMKLFhC2BEd6OZr6z6vVAqdMmcLrr7/OokWL2Lp1K3fffTc5OTlMnDgRgHHjxrkVp7j77rtJS0vj/vvvZ8eOHXzxxRc888wz3HPPPRU+poiIiIhIQ5GclU8TrXF1xnh1ztX1119PcnIy06ZNIyEhgV69erF06VJXQYoDBw5gtZ7I/1q2bMnXX3/Ngw8+SI8ePWjevDn3338/jzzySIWPKSIiIiLSUCRn5bt6rpRc1TyvF7SYPHkykydPLvW+VatWldjWv39/1q5dW+VjioiIiIg0FElZ+fSwaAHhM8WrwwJFRERERKTmJGfluwpaoDlXNU7JlYiIiIhIPaVhgWeWkisRERERkXoqOTufJhoWeMYouRIRERERqafSMnNoZMk1bwRpWGBNU3IlIiIiIlIPOZ0GhdmpABhYILCxdwNqAJRciYiIiIjUQ+nH7YQZxUMCI8Bq825ADYCSKxERERGReshcQNhMriyab3VGKLkSEREREamHVCnwzFNyJSIiIiJSDyVn551Y40rJ1Rmh5EpEREREpB5KyswnQj1XZ5SSKxERERGReig5K5/w4p6rYJVhPxOUXImIiIiI1ENaQPjMU3IlIiIiIlIPuRe0UM/VmaDkSkRERESkHkrOyldBizNMyZWIiIiISD2U5JZcRXg3mAZCyZWIiIiISD2TX+gg43jBiWqBKmhxRii5EhERERGpZ1KyCwgmD3+L3dygYYFnhJIrEREREZF6xq0Mu08g+AV7N6AGQsmViIiIiEg9k5yVTxNUhv1MU3IlIiIiIlLPJGXlnei5UjGLM0bJlYiIiIhIPZOcla9iFl6g5EpEREREpJ7RGlfeoeRKRERERKSecU+u1HN1pii5EhERERGpZ5Kz84lQQYszTsmViIiIiEg9k5R5Us9VsJKrM0XJlYiIiIhIPWIYBsnZJ61zpZ6rM0bJlYiIiIhIPZKZV0hBofNEtUAlV2eMkisRERERkXokOSsfgCZWFbQ405RciYiIiIjUI8lZ+dhw0Jhsc4N6rs4YJVciIiIiIvVIUlbeicQKCwSGezWehkTJlYiIiIhIPeK2xlVgY7D5eDWehkTJlYiIiIhIPWKucaX5Vt6g5EpEREREpB5JzlIZdm9RciUiIiIiUo8kZ+XTxJJp3lBydUYpuRIRERERqUeSs/IJLx4WGKzk6kxSciUiIiIiUo+o58p7lFyJiIiIiNQTdoeTtNyCk+ZcqaDFmaTkSkRERESknkjLKcAwIMKiBYS9QcmViIiIiEg9kZyVD0C0TdUCvUHJlYiIiIhIPZGUlQec1HOlghZnlJIrEREREZF6wuy5MmhsZJgb1HN1RtWK5Oqll14iLi6OgIAA4uPjWb9+fZn7Lly4EIvF4vYTEBDgts+ECRNK7HPppZfW9GmIiIiIiHhVclY+geTjZxSYG1TQ4ozy8XYAixcvZsqUKcydO5f4+HjmzJnDsGHD2L59O9HR0aU+JiwsjO3bt7tuWyyWEvtceumlLFiwwHXb39/f88GLiIiIiNQiZhn2ovlWNn/wC/ZuQA2M13uuZs+eze23387EiRPp2rUrc+fOJSgoiPnz55f5GIvFQmxsrOsnJiamxD7+/v5u+4SHh9fkaYiIiIiIeF1y9skLCEdCKZ0QUnO82nNVUFDAhg0bmDp1qmub1Wpl8ODBrFmzpszHZWdn07p1a5xOJ3369OGZZ56hW7dubvusWrWK6OhowsPDufjii3n66adp0qT0Maf5+fnk5+e7bmdmmouu2e127HZ7dU6x2oqf39txSO2k9iFlUduQ8qh9SFnUNuq+xIw8Iop6rozACAo9+LtsqO2jMufr1eQqJSUFh8NRoucpJiaGbdu2lfqYTp06MX/+fHr06EFGRgbPP/88AwYM4M8//6RFixaAOSTw6quvpk2bNuzevZvHHnuM4cOHs2bNGmw2W4ljzpo1ixkzZpTYvmzZMoKCgjxwptW3fPlyb4cgtZjah5RFbUPKo/YhZVHbqLv2J9o4H7OjIDnXyZovv/T4czS09pGbm1vhfS2GYRg1GEu5jhw5QvPmzVm9ejX9+/d3bX/44Yf57rvvWLdu3WmPYbfb6dKlC2PHjmXmzJml7rNnzx7atWvHN998wyWXXFLi/tJ6rlq2bElKSgphYWFVODPPsdvtLF++nCFDhuDr6+vVWKT2UfuQsqhtSHnUPqQsaht1X8+ZKxjr+IwnfN/E2e1qHKNe89ixG2r7yMzMJDIykoyMjNPmBl7tuYqMjMRms5GYmOi2PTExkdjY2Aodw9fXl969e7Nr164y92nbti2RkZHs2rWr1OTK39+/1IIXvr6+tabh1KZYpPZR+5CyqG1IedQ+pCxqG3VTTn4huQUOInzMnitrcBTWGvg9NrT2UZlz9WpBCz8/P/r27cuKFStc25xOJytWrHDrySqPw+Hgjz/+oGnTpmXuc+jQIVJTU8vdR0RERESkLjPXuIJoW465IVhl2M80r1cLnDJlCq+//jqLFi1i69at3H333eTk5DBx4kQAxo0b51bw4qmnnmLZsmXs2bOHjRs3ctNNN7F//35uu+02wCx28de//pW1a9eyb98+VqxYwZVXXkn79u0ZNmyYV85RRERERKSmJRUlVzE+RclVUIQXo2mYvL7O1fXXX09ycjLTpk0jISGBXr16sXTpUleRiwMHDmC1nsgBjx07xu23305CQgLh4eH07duX1atX07VrVwBsNhu///47ixYtIj09nWbNmjF06FBmzpypta5EREREpN4q7rmKsmaBAwgqvVK21ByvJ1cAkydPZvLkyaXet2rVKrfb//rXv/jXv/5V5rECAwP5+uuvPRmeiIiIiEitl5yVB3BinasgDQs807w+LFBERERERKovOdvsuQp1Zpgb1HN1xim5EhERERGpB5Kz8rHiJMhhVgtUQYszT8mViIiIiEg9kJSVT2OysVC0jG1guHcDaoCUXImIiIiI1APJWfmEW4rmWwU0BlvDWYuqtlByJSIiIiJSDyRn5RPhKmah+VbeoORKRERERKSOczgNUnMKiLAUzbdScuUVSq5EREREROq4Y7kFOJwGTYqHBaqYhVcouRIRERERqeOSMs0y7C38c80NQRFejKbhUnIlIiIiIlLHFa9xFeubY27QAsJeoeRKRERERKSOS84yk6toW3FypTlX3qDkSkRERESkjitOriItqhboTUquRERERETquOLkqhFF1QJV0MIrlFyJiIiIiNRxSVl5AIQ6MswN6rnyCiVXIiIiIiJ1XHHPVYA93dyg5MorlFyJiIiIiNRxydn5BJCPj+O4uUHJlVcouRIRERERqeOSs/KJoKiYhc0P/EO9G1ADpeRKRERERKQOy7M7yMorJPzkSoEWi3eDaqCUXImIiIiI1GHF861ifbLNDRoS6DVKrkRERERE6rCkouSqVYDmW3mbkisRERERkTqsuOeqhX+uuUHJldcouRIRERERqcOSs83kqqlPjrlBCwh7jZIrEREREZE6rLjnKtKmOVfepuRKRERERKQOS87KAyCCTHODkiuvUXIlIiIiIlKHFfdchTqVXHmbkisRERERkTqsOLkKdqSbG5RceY2SKxERERGROqw4ufIvSDc3qKCF1yi5EhERERGpowzDIDk7HwtOfPKPmRvVc+U1Sq5EREREROqo9Fw7dodBI3KwGE5zo5Irr1FyJSIi0tAkb8fPnuntKETEA4rXuGodeNzc4N8IbL5ejKhh8/F2ACIiUscd3gDbl8LZEyGsmbejkfI47PD13/Bd/yqXYsFIWwAdh0GHIdC0F1j1natItaUfhN/fhV43QVjTGn+64vlWbQLzIBcIiqjx55SyKbkSEZGq27EM3rsZCvNg3aswdCb0GQcWi7cjk1NlJ8GSCbD/JwAsGFiObIAjG2DVMxAcbSZZHYZA24sgsLFXwxWpkzIOw8LLIP0AbPsCbl1e471IxclVq8DjZnKlYhZepeRKRESqZvOH8OHt4CyEgMaQlw6f3QebP4ArXoDwOC8HKC6HN8DimyHzMPiFUnjFS6zYmsYlrQ189qyAPasgJwl+fcv8sdig1bnQYaj5E91FCbPI6eSkwBujzMQK4Mgm+P55uGhqjT5tcXLVzDfH3KD5Vl6l/n8RabjSD8K8YfCfc2D961CQ6+2I6o6N/4MPbjUTq7NGw1+2w5CZ4BMAe7+Dl/vD2lfA6fB2pLLxDZg/3EysmnSA21didLqMPL8IjN43w5i34OG9MO5T6D8ZIjuC4TB7uL6ZDq/0h3+dBZ89ANu/goIcb5+R1AfH0+Gju+Ff3WH3Sm9HU315GfDGVZCyA8JamJ+HAN8/B4c21OhTJ2XlARBjyzY3BKnnypuUXMkJe3+AL/8Kx/Z7OxKRmndgLbx+ERxca/4x/PIhmHMWrPo/yEn1dnS125qX4dN7wXBC3wlw9evgGwDn3Qd3r4bW54E9F5Y+CguGQ/J2b0dc6xmGgcNpePaghQXw+RT4dDI48qHTCLh9JUR1LLmvjx+0HQTD/g6Tf4b7foXLnjd7rXwCIPMQbFgA74yBf8SZF5FrX4HU3Z6NWRqGvT/AK+fBb29DxgF4+3pz3mYNyrM72JGYhWF4+H0G5hdzb18PCb+bic24j83Pw7NGm19UfHRnjX55V9xz1cRanFxpzpU3aVigmH5fAh/fZX4L/cf7cM18aHdRjT2dYRgcOnacPLuDQqd5UVHoNCh0ON1uO5xOCh0n3X/K7ZP3sztOeZzTwOEwb1sscF67SAZ1isLXpu8UGryNb8DnD4LTDrHdoccYWP8apO+HVbPgxznQ+ybofw9EtPF2tLWHYcB3/zBfI4AB95rfzp48XKxJOxj/OWyYD8unw8F1MHcgDHoEzru/1lewyskvZH9qLgfSctifmsuR9OMUOEr73HHicBonfe443e93FH1enXT71M+nwpMeW5xXdW0axuAu0VzcJYYezRthtVZxKF5WIrw3zvzyAAtc9Bic/1DFC1ZEtIF+t5s/Bbmw70fYuQx2fm0Oedq90vxZ+ihEtCsaPjjETKx9A6oWs9R/hfmwcias/g9gQHgb8zNj1zew+Ebz2qPrlR57OsMw2LD/GB9sPMTnvx8lK6+Qq/s05/+u7oGfj4euBQrzYfFNcGCNWaXv5o8gsoN532XPw/7VkLoTvnkSLnvWM895iuJqgY2NogqgGhboVUquxJyE/tXD5v8Dw+F4Grx5NQx5yhwi4sFx9g6nwdLNCby8ahd/HjmzZYAX/LSPyBA/rujZnNF9m9OtWaMz+vz1nWEY5NmdZOcXkltQSE6+g5yCQnLyT/w/N7+QnAIHOfmF5BY43Pctuq/4dusmQYzt14rLezQlwNfmmSAdhbD8CVj7snm765Uw6hXwC4b4u2DrJ/DTC3D0V/j5dfhlnrnPgPugeR/PxFBXGQZ8/TdY+5J5+6LH4YKHSv98sFrhnNugwzD4/AHzwmnlTNjyCVz5EjTtcUZDP5lhGKTmFLglUAdSc9mflsv+1BxSsgu8FhvAlqOZbDmayQsrdxEZ4s/FnaO4uHMM53eIJNi/gn+yD/5sFhnJOgr+YWbPYqdLqx6UXxB0HGr+GM9Byk4zydq5zLxwTNsN614xf3yDoO2FZqLVfgg0bln15xUAjmYcZ83uVIL8fBjaNabqCbe3JW4x52gmbjZv9xkPw54BH3+zZ2fzB7BkIlz1KvS4tlpPdTAtlw83HubDTYfYn+reY/ThxsMcST/OqzedTaOgan7Z4yiED26D3SvMtn/jEvfPt6AIuPI/8OZoWP+q+T5sd3H1nrMUxT1XIc4Mc4MKWniVkquGzDDg22fg+6JvUvrdCYOfNIdH/foWLHvcnIx5xYvmxWc1FBQ6+XjTYeZ+t5s9KeZ4fV+bhdAAX2xWCz5Wyyn/WvGxud+2WS342E7s52O1YrOd+lir67av7cTtzDw7X/6RQEp2PvN/2sv8n/bSOTaU0X1acGXvZkSH6pvW8uxNyWHxzwc5nH68KFkqLEqWihMo819PjrZIyc5nw/5jzPx8C9f2bcGN57amTWQ12uHxY+Yf7j3fmrcvfAwu+OuJb/JtPuYQjm5Xw97vYfULZlLw50fmT9z5Zs9L+8ENb2K/0wGf3Q+b3jBvX/oPOPeu0z+ucUu48X347V2zhyPhd3Mo5nkPmK99DfVwOJwGR9KPcyAtl32pOWbyVJRAHUjNIaeg/HlgjYN8aR0RRKsmwbQMDyTQ1+b6rCn+bCrtM8fHasHHZi35eXbSZ9GJz7WS+xU4nPy0K5WV2xL5fkcKKdn5vPfLId775RB+NivntmvCJZ2jubhzNC0jgkoPfsNC+OIhs1c2qjNc/xZEtvfci2uxmMMKozqaPZd5meYcux1fw87lkJ0A2780fwCiu5qJVqcR0OIclXqvgJTsfNbuSWX17lTW7E5lb8qJOW4XdIzin9f2JCrU34sRVpLTaSbe38wwh6cGRZrXFZ0vO7HP1a+Dzd8cJvjh7eZ+vW+q1NNk5xfy5R9H+WDDIdbtTXNtD/KzMfyspozu25z8Qif3vr2JtXvSuOqVn1g4oR+tmpTxXqrIeX12P2z9FGx+5tzFVvEl92s/2Pyy6ef/wsf3wKTV5hfZHlScXAXZ080N6rnyKotRI4NP67bMzEwaNWpERkYGYWFhXo3Fbrfz5Zdfctlll+Hr68HhNE6HmUT9Mt+8fdHfzIsdi8VMun7+r3kx5CyE6G7mh0YVhkcdL3Dw7s8HeO37PRzNMCdcNgr0ZcKAOCYMiCM82M9z53QahQ4n3+9M5oMNh1m+JZECh7mKuc1q4YIOkYzu24LBXWI810tyBtRY+wCcToPvdiaz8Kd9fLcjuVKPDfKzEezvQ7CfjSA/H0L8fQjytxHs50Owf2nbivb19yHE34a/j43vdiTz9roDHE4/7jruwPaR3HRuawZ3icanMsM7k3fAO9dD2h7z28WrXoWuV5z+cQmbYfWLsPl9870A5vthwL1mIuZz5tpveTLz7OxOymZnUja7k7LZlZTNzqQssnNyGdu/HeMHtCE6rIqJTGEBfHSHmWBarHDFf6D3jZU/Tlai+Zmz9VPzdmRHsxerZb8qhZVnd3AgrShpSs1x/f9AWi6HjuVid5T9p81igaZhAbRqEkTriGDz35P+3yjQ+0MXCwqdrN+bxoptiazYmsSBNPdv3zvFhHJxl2gu6RxN71bh2JwF5giEDQvNHbqMNHtl/UNLPX6NfHYYBiT8UTR8cDkcWm/OyysW1gK6jTK/wGjep+5/SeEoBKut2ueRcdzO+r1prN6dwprdqWxLyHK732qBs5o3YkdiFnl2J5Eh/vzr+p6c3yGqWs9bFo+2jYzD8PHdZgIOZm/2lf+BkOiS+zqd8MUUc24fwIh/mklJORxOg9W7U/hw42GWbk7guN384sRigQHtmjC6TwsuPSuWIL8TfQlbj2Zyy8KfOZqRR5NgP14ffzZ9WlUy2TEMWDrVTBotNrhukfmeK0tBDsw93+zl7X4djH69cs9XjoJCJx0f/wqA3TGPYss4ALd+Ay3P8dhznKwmrztqs8rkBkquSlHvk6vCfPjwDtjyMWCBEc+X/gG2fzW8N94szxvQGK6ZZ34DUwEZx+28sWYf83/aR1qOOcwmOtSf289vy9j4VoRUdHhLDcnItfPZ70f4cOMhNh5Id20PC/Dh8p7NGN2nBX1aNcZSy//410T7yMyz8/4vh3hj7X7XN6YWC1zUKZrz2kcScnJyVJxEFSVHwf4+BPraPDZsxeE0WLU9iTfX7mfVjmRXz1hsWABj+rVkzDmtiG10mqRh53J4/xbIz4RGrWDs2+Y8q8rIOGRO3t+wEAqKJgyHNYdz7zaHtgTU/OeEYRikZBewKymbXcnZ7ErMMv9NyiYxM7/cx/raLFzeoxkTz4ujR4vGFX9S+3Fz3s7OZWD1hdH/NS+Oq2PLJ2bPSk4SYDGHY17yRIV6xzcfzuDdnw+wYmuS68uasvjZrLSICKR1RBCtmwTTKqIogWoSRIvwoDr1JYphGOxOzmHF1kRWbEtiw/5jbsUvOgZm8VrAv4k7vgUDC5ZLnoCBU8q96D8jF0i5aea8rB1LzWIFBSclDY1bQberzESraU+PJFrpuQXM/2kf6bkFtI0Mpm1UCG2jgmnWKNBzQ+nSD55IHvd+Z7bbQY+YhV0qOJ8wt6CQX/YdK+qZSuGPwxk4T7kS6xwbyoB2kQxo14R+bSMIC/BlR2IWk9/eyI7EbCwWuGtQO6YM6ejxecQeaxubPzDntuZlgE+gWSzl7FvK/12fnLSAOWyw/z0ldtuVlM0HGw/x8abDbp8FbSODGd23BaN6N6d548AynyYxM49bFv7Mn0cy8fexMvu6XozoUYnFfr99xpx/CjBqLvQae/rHHPwZ5g81v3C4dqHZ/j3gSPpxBvzfSnxtFnYE3YbFngP3bjTnstUAJVdKrqqkXidX+VnmxMs9q8yLpatfg7OuLnv/zCPm2iiHfzG/tb5kmjmkp4wPx+SsfOb9uJc31+4nO9/8pr9VRBB3DWrH1X2a18oLmj3J2ebY7I2HOHLSh3SbyGCu7t2cq/o0p0V4FYcN1DBPto9dSdn8b80+PthwyDVsKtTfh+vOacnN57YmrjpD8jzgYFoub68/wHs/HyS1KGG3WS0M6RLDTee2ZkC7Ju4XUIZh9jotnwYY0GoAXPc/CKnGt73Hj8EvC2DdXMhONLf5N4KzJ5qJVmhs1Y9dxOk0OJJx3K0XaldRr1TGcXuZj4sJ86d9dAjto0JoHx1CXEQgK35cxx/5Tdhw0hcIZ7cOZ+J5bRjWLab83r+8THhnLOz/0bwwuv5N6FCxL1dOKzcNvn4MfnvHvN24tbkuVtsLS+yalWfn09+O8O76g/xxOMPtvlB/H1o1CSKuSVHvU0RQUS9UMLFhAdjq6tyU00jPLeC7Hcms2JpE+vbved6YTbQlnQwjiAcL7yUv7mIu7hzN4C4xZb5vz/gFkj2vaJjth2aiZT+pnHtE26JE6yqIOavSiVahw8k76w/wz+U7SM8t+R4J8LXSJtJMtNoVJV3tokJoExV8+i/6HHazKEtxQpW0pfT9mnQw5yl3Gl4i/vxCB78eSHcN89t08FiJntW2kcH0b9eEAe0iObdtBE1CSh/2l2d3MPPzLby1zlxHqXerxrwwpnfZw0SroNptIy/DrDz8+2LzdrM+5rC/ig5PNQxYMQN+/Jd5++In4IKHSM8t4LPfjvD+xsP8djDdtXtYgA8jezZjdN8W9G5Z8S9Fc/ILuf/dTXyzNQmAR4d35s4L2p7+8av/A8v+Zv7/sufNoi8VtfJpszR7YDhMWuuRvxm/HUznypd+Ii7MwqqCoiTv0QMQUDPzypVcKbmqknqbXOWkwlvXwJGN4BtsDvWrSEXAwnxzOM/G/5m3u14JV74M/iGuXQ4dy+W17/ew+OeD5Beaw0A6xYQy6aJ2jOjetHJDuLzE6TRYuyeV9zceYunmBHJPmpfRv20TRvdtwfCzYis+qfwMqG77cDoNvt2exMLV+/hhZ4pre/voEMYPiOPq3s1r1fmCeaGydHMCb609wPp9J8bVt4kM5sb4VlzTtwWNfYvGwv/+rnlnn/HmH0FPDeMrzDcvHH56wawCBeaY+x7XmcUvojqd9hB2h5P9qbnsSspmd3I2O4t6onYn5biGtpzKYoGW4UG0jw6hQ3QI7aLNRKpdVEiJoWwnt42tiTks+Gkfn/9+xHVR16xRAOMGxDHmnJY0DjrldcktKmpzZJNZEOGGxdB6QOVfp9PZudxcOynzkHm7z3gYOhPDP4xNB9N5d/0BPv/9qOu96GuzMKxbLNee3ZLuzRsRHuRb63uXa4xhwC/zML56FIvTTlJgO6ZY/8qPqe5/s9pGBRfN04rh7LhwVy+HVy+QCnLNZOXPD2HHMig8MfSXJh3MJOusq82Fi09j9e4Unvpsi2soXaeYUC7sHMXe5Bz2pOSwPzWn3CGiMWH+tC1OvIp6ujoE5dI0+Uesu5bD7m8h/6Sk3mKFFv2KCnYMhkM/m9Uzc4uWb4g7n8LBT7HZaOsa5vfzvjTy7E63523eOLAomWpC/3ZNaNqo7F6W0nz5x1Ee+eB3svIKCQ3w4R+je3BZ90r0vJSjWm1j34/w0V2QcdB8rS74q/lT2Sqhp1Qm/SL8Zh5MuoyCot+lzWrhwo5RjO7bgos7R1f5i1uH02Dm51tYuHofAGP7teKpK7uV3Ru4YZG5UDq4kr5KKSyA/15izj9tP8QsgFHNz7BvtiRy2/9+4eKmduYfGw9WH3gipcaG3Sq5qiPJ1UsvvcRzzz1HQkICPXv25MUXX6Rfv9LH4S9cuJCJEye6bfP39ycv70SPg2EYTJ8+nddff5309HTOO+88XnnlFTp06FCheOplcpV+0FyXJHUnBEbATe9D876VO8YvC8xvo5x2iOoCY95ilyOal1ft5tNfj1BYNK6hd6vG3HNhey7uHF1nqxrl5BeydHMCH2w8xJo9qa7haEF+Ni49K5Zr+rTg3LZNvH5+VW0fGcftLPnlIP9bs981l8NigUs6xzBhQBzntW9SJy5atydk8eba/Xy06bCrp7SFTwZvh75Aq+NbMSw2LJf+n/nNYk2cj9NpDnn66d9FJa+LdBxuFr9odS4OA/an5rAtIYttCVlmEpWUzb5yLvp8bRbaRAa7eqLaRYfQITqUtlHBFb6IKK1tJGXm8eba/by17oCr9y/A18rVfVowcUAcHWJCISsB/jcKkreanxU3fwjNelfrZSpXfpZZovjn/wKQ4x/NP2x38r+0ExfWbaOCGXtOK67u07zMb/QbFHsefPkX2PSmebvbVeZcOP8Q9qXksGJbEiu3JbJuT5rrcxnMb/gHdYpmcJdoBrQJZ/Wq5d6/QMrPNt9Df35kJtuOk4a4RnU5kWhFuv/9PpiWy9+/2MrSPxMAswjJX4Z0ZGy/Vm5f5hU6nBw6dpzdydnsSc5hT0o2u5Nz2JOcQ0pR+WorTnpY9nCR7VcutP5KT+set+fK9WlMSuz5ONsPJaLnpYSFu88Xcuamk7bsWRr//l98nOYxP3QM5Hn7dRzBrNoWGeJH/6JhfgPaNaFVRFC1P2MPpuVy/7ubXEPbb4hvxbTLu1Z7hEiV/q4U5sO3fze/cMKA8Dizt6oKcyoNw+DPI5l8sPEQ4Rtf4j7jLQBeLRzBx5F3MbpvC67s1dyjRT0W/LSXpz7fgmHA+R0iefnGPoQGnHLumz+A928FDPPzffCMqv1dSdoKrw4y2/rlc8yRD1WUlWfnbx9t5tPfjjCxbQbTj9wNITHw0I4qH/N0lFzVgeRq8eLFjBs3jrlz5xIfH8+cOXNYsmQJ27dvJzq65ITHhQsXcv/997N9+4lFKS0WCzExMa7b//jHP5g1axaLFi2iTZs2PPHEE/zxxx9s2bKFgIDTT+qud8lV8nYzsco8bE4ovvmj0heRrIgD68wSv9mJ5FhDuCd/EqscvQDzA2nShe05t21Enbgwr6jD6cf5aOMhPth42K1qU7NGAVzVpzmj+7SgbVRIOUeoOZVtHzsTs1i4eh8fbTrs6g0IC/Dh+nNacvO5cVWvmuRl2fmFfPLrYdb/+A1TM2cSazlGuhHMc42m0n3glVzRq5nbhOYacWAd+d//C79dS7Fgfqxu8+nMS/mX8YW9D85S1mwP8rPRrmgY38k/rSKCqj2Pory2kWd38NlvR5j/0z62Hj2xJMLVbez8PfNxAnMOQmhTuPljiO5crThOxzAM1u1NY/2qz7hi/yziLObF8mfO81jf6WFGDujBOXHh9eozpVoyDptDu49sLBqqPd280Cvl9cnMs/PDjhRWbEtk1fZk1/xXMIskdG3s5JFR/RjYMbp2vL55mWaitflDcwih86QhfjFnQberON7xCl76zeC1H/ZQUOjEZrVwU3wrHhzSsWQPbHly08jdupy8LUsJPvgt/gXH3O7+3dmGb529+dbRi9+Ntm7v36hQf9ecrszjdtbsSSUtp4BmpPCQ73tcbfsRALvFl62tbybokr/SrkXTGnmN7Q4n/1q+g1e+241hQMeYEP5zQx86xpReyKRCx6zsdUfSVvjgdkj8w7zd+2a4dFaZxVTKPExWHp9sOsIHGw+5FfWYHLSch5xFRS763WFWK62BqpPLtyRy3zubOG530Dk2lPkTzqFZ8bytHcvg3bFmYaO+E+Hyf1XvC7vioYW+wXD3j+bQ2EowDIOPfz3MM19uc1UKfKV/BsM33W0WXZq0uuqxnYaSqzqQXMXHx3POOefwn//8BwCn00nLli259957efTRR0vsv3DhQh544AHS09NLPZ5hGDRr1oy//OUvPPSQ2V2bkZFBTEwMCxcuZMyYMaeNqV4lV4c2mEMBj6dBZCfzW+hGLaoUi2EYrN2Txtsr1jHh0DT6WnfiNCx82mQibUZNo2dlq+3UMYZhsPFAurkY4W9HyMwrdN3Xu1VjRvdpwcgezaq/bkYlVKR9OJwGK7YmsmjNPn7alera3jEmhAkD2jCq9xlIPM6E35dgfDoZS2EeCX5x3JjzALsd5hc0oQE+jO7TgpvObUX76KpfdBTLszvYmZjN1oRMtidksT0hi20JmaRkF9DWcoTbbF8w2vYj/hbz4nCfEcsXIddwuPWVtG0aaQ7riwmlaVhAjfV+VqRtFCc283/cy55tG3nDdxZNLWkcscSyduA8hg08t8aGhaZk5/PBhkMs/vmga3kGfwp4utGnjM7/GCtOs2TzZc+aRQ9qw8W/t+37CZaMh5xkc87GNfMrvGaOw2nw68F0VmxNZOW2JLeL165Nw7h1YBtG9mzmuYVVq+t4ulnOffOH5vIJzhOft3844/jc0Z/Elpdy96hL6BRbgfe0YZjrKxWXjD+1kqF/mDlMvsMwHO0u4bA9jN0pZm+X2etl/j8pq/TiMUF+Ns6Ji2BAuyZc3OgI7TfNwrL/p6I7I+HCRytV9KKyftyZwgOLfyUlO58AXyvTR3ZjzDktq5TQVfi6w+k0559+82RRifUmMPIF6HJ5hZ8rz+7gm62JfLDhEN/vTHEVavGzWRnSNYbRfZtzQYcofDYtNItjAPQZZ/b4WD0/h/uPQxncsuhnkrPyiQ71Z974c+he+Ie5TlVhHnS/1qw2W93ndjrhf1fAvh+gZTxM/KrCx9xyJJPpn27m533mFwJtIoOZPrIrF+Z/Bx/eZi4bMuHz6sVXDiVXtTy5KigoICgoiPfff59Ro0a5to8fP5709HQ++eSTEo9ZuHAht912G82bN8fpdNKnTx+eeeYZunXrBsCePXto164dmzZtolevXq7HDRo0iF69evHvf/+7xDHz8/PJzz/xgZmZmUnLli1JSUmpFcnV8uXLGTJkSKUbsWXPKmzvj8diz8HZrA+O6981F7SrJKfT4Nsdycz9fi+/HjTHngdYHcyLXsJ56WZZZWeny3GMfLHS31TVVfl2Byu2JfPRr0f4YVeq6w+Cr83CJZ2j6dOqMS0aB9Ii3PwJDaiZC9Ty2kfGcTtLNhzmrXUHOJRuDpu1WuCSztGMO7cV8W3qSW+A04H1u2ewrTbf2872Q3GMepW0Qn8+2HSYd9Yf4uCxE3M64tuEc8M5LRncJfq0F5JOp8HB9OPsSMhmW2IWOxKz2Z6Qxf603BLVvcC8/m8VHkTHmBD6ROQzOOsT2u57F1uB2TtkBEfh7HsLzp43QZhn5keUpVKfHUd/w/r2tdjy0thltOCG/KkkEU5ogA/X9W3OTfGtaBFeuTkhpXE6DX7ak8p7vxxmxbYk17DIID8bl3eP5bqzW9CjeRjWo5uwfX4/luSt5uM6Dsdx6bNmb1pDZBhYf5mH9ZvHsTgLMaLPovDaRWYhkCracTSDWR+sYUOaD8eL5gNFhfhxU3wrxpzTgogzuEzG6WzZs58fPltEj4xvGWD9Ex/LiaTI2awPRpcrcXYdZVbwPFl+Fpa932PdvRzLrm+wZCe43W1EdcbZfghGu8EYLfpVKPHJyitkX2pO0RDDXPx8rJzbJpzuzRu5f54YBpadX2Nb+SSW1F3mpibtcVw8HaPDpTXyZUFKdj4Pf7CZH4q+RLvsrBievrJryeFtp1Ghz47Mo9g+n4y1qMS6s91gHJf/2xySVgFHM/J45+eDLP7lEGk5J3ooe7dsxKhezRjRPbbEPFLL7+9i+/w+LIYT51nXmtccVs//bT2Sfpzb39jEjqRszvbdy7v+z+BTmIOzwzAcoxd6LkHOOIjPa+djKcjGcdETOAfcX+7umcftzFm5m7fWHcBpQKCvlUmD2jLxvDj8faxYf34N27LHcHa5EsfV8zwTYymqc11al2VmZhIZGVn7k6sjR47QvHlzVq9eTf/+/V3bH374Yb777jvWrVtX4jFr1qxh586d9OjRg4yMDJ5//nm+//57/vzzT1q0aMHq1as577zzOHLkCE2bnvhDfN1112GxWFi8eHGJYz755JPMmDGjxPa3336boKC6OUyq2bF19N0/F6vhICn0LNa3uQ+HrXLr3DgM2JRi4ZsjVo7mmn8IfCwG/aMNLmrmpEkAtEpZRY9D/8NmFJIV0Iz1be4nO6BhXQBlFsCGFAvrk60cyS39D2aQj0ETf2jibxARYP7bxB8iAgwi/MHXg18WH8mFH45a+TnFgt1pcT1//2iDgbFOIurRlBUfx3H67nuF2MxfAdgRczlbm15jDpcq4jRge4aFnxIsbD5mwcB8TUJ9zdekf4z5muTY4UiuhSO5cDTXwpFcC0dzocBZ+u802MegWZBBsyBoGmT+PzYI/E/58tHHcZxWqd/RLulrguzmRY+BhcSwHhxocgEJYb0xauACoaIisrdz7u7Z+DqPkx4Yx7dt/sqPaWF8n2AlOc88dwsG3SMMBsU6aRdW+evCjAJYl2RhTZKVtPwTD24VbL7+fSINAk553SzOQjomfkbHxE+xGg7stiA2Nx/LgYgLGlQvltVZQM+DC2mVZg41OxR+Lr+2uhWH1TNv5Bw7rE6y8MNRKxl283X1tRicE21wYVMnMdXPqassswA+P2BlfbL5vvWzGlzdLJ1rA36mVfp6IrO3uobgAqQFt+dw43gsOInJ+I0mOduxGieKwxRa/UgO6UZSo54khvXguF9kjZ+DxSikdcoqOid8hH+h2VuYHNKFP5uPISOo8mtHno7TgG+PWPj8oBWnYSHC32B8BwdxHvzes9mxdfQ8uBA/Rw6FFj/+bD6GfZGXnPZ9aRiwJwu+T7Dye6oFZ9FncSM/g35RBudEnb69NTu2lr775mLFyeHG/dgQdxeGxfOfn8cLYeW2I/yj4GnCLdns9OvCti5/wWn17JcOLVN/oM+B13FabHzX8Ukyg0p+YeI0YH2yhc/2W8kuNF+zXk2cXNna/e9556Mf0CnhE/ZGXsLvLcd7NE6B3NxcbrjhhvqZXJ3KbrfTpUsXxo4dy8yZM6uUXNW3nivrL/Oxfv0IFgzzG4wrXgafiv8hzi908tGmI7z2w17XN/7B/jZu7NeSCf1bl5hEajm8wewhy07A8A/FccUrGB0vrfhJ1iNbjmay9M9E9qXkcij9OIeOHedYKaWBTxUT6u/q5Sr+aVn0b3klpYvbx0WXXML3u9J5Y90B1u09MXegc0wI4/q34vLuTQn0q31l8Kvl2F583rsJS8p2DJ8AHCPmYJx1TbkPOZqRx7s/H2LJhkMkZ5vzT6wWaBLs57p9Kj8fK+2jgukUE0Kn2FA6xoTQKSaUqBC/yvX8OexYtn6MdeMirCcVvzCCInF2vw5nr5vMhXU9pCKfHZbdK833buFxnK3647jubVfvs7mIdAqL1hzgp90nhpN2iQ1lfP9WXN49Fv9yJs4XOpx8vyuV9345xKodJ4b7hAb4cGXPplzXtwVdmlbgii9pC7bP78d6dJMZV5sLcVw221wnqb7LOITt/fFYE37DsFhxXvIkzn53eyS5PLV9FBQ6+erPRBas3sefR04MGRzUIZKJ57VmwBmcS1tQ6GTR2v28tGoPOflmcjSqZ1P+MrQDsScvhp2diHXbF1i2foTlwFq3RKuYEd7mRO9U6wHgU8XFtKsrLxPrmn9jXTcXS1HRDudZ1+K48G9VHqpfnl8PpvPgkj84dOw4PlYLD1zSntsHxlVoGHKZnx15mdi+fgTr5iVm/LE9cYyaa1Z4LEee3cFnvyfwxtoDbD1pOOo5ceGMO7cVgztHVaqisGXbF9g+ug2L046zw6VmL00lrnEq5Ng+bP8bgTU7kU3O9txUMJXR53biseGdPLvEg2GY7/EdX2JEdaHwlm/czmXz4UxmfLHVNWqobWQw0y7vzHntmpQ4lPWrh7BtXIhj4EM4B5WcVuMp6rmq5clVVYYFlubaa6/Fx8eHd955p0rDAk9VZ+dcnVK6lLNvhcueq/A43sw8O4vXH+T1H/a4xpVHBPtxy3lx3Nw/rkQXvZusRHMuwIE15u0Lp8IFD9fIpNO6Jju/kINpuebPseMcTMvl0LFcDqYd5+CxXLeS76XxsVpo1jiQlhGBtAwPomVEkJl8RQQR5m/l3x98x4aMYNcaXTarhWHdYhjfP45+bepXcRGXPavMBa7z0s2hYmPeqlT1S7vDybI/E3lz7X7W7DmROLSMCKRTTBhdmobSKTaUzrGhxDUJ9vxSAim7YNMb5jpPxetlgVniuc/NZoW0ag6xPe1nx5ZPzMpXTrtZUvq6N8Cv9J76HYlZLPhpHx9tOuQqKR0Z4scN8a256dxWRIeeuGA9dCyX934+yHu/HCIh80QV13PiwhlzTisuq0qi7yiEtS+b1cgK88A36MQCtG0H1dg8Fq/a+z0smWCW+A6MMBcdbTvIY4cvq30YhsH6vWnM+3Evy7cmuiqldo4N5ZaBbbiiZ7MaW6/QMAxWbkvi6S+2uooH9WzRiGkju9G39Wnm9GYeNdv0ts/N9tB+CHQYWvG1lc6U9IOwcuaJNaB8AuDcSTDwQY8vRp6ZZ+exD//g89+PAmbRqdnX9Tptlb1S28a+n+CjO0+UWB84xZxHVs5773D6cd5cu5931x9wfcno72Plqt7NGdc/jq7NqnG+O5aZhV0c+ebn1/Vvgq+Hulkzj8D8YZB+ACO6Kws6vMRTK8zXcHCXGF4Y28uz85Szk+GV/uZcygH3wdCZpOcW8NzX23l7/QEMA4L9bNw/uAMTBrQpezj7e+PM98Dw5yD+Ds/FdwrNuarlyRWYBS369evHiy++CJgFLVq1asXkyZNLLWhxKofDQbdu3bjsssuYPXu2q6DFQw89xF/+8hfAfEGio6Prd0ELpxOWPgLrXzNvD3rU/OA7zYW1w2nww85kPth4mGV/JrjWqGraKIA7LmjLmHNaVfxCqLDAXBj059fN250ug6vm1thCdvWBYRgcy7UXJV4nEi4zATvO4WPHKXA4T38gIDzIl7H9WnHTua1PVDiqbwwD1r8OSx8Fw2EmVNe/Va35S/tTc0jNKaBjTOjpFxT1NIfdnFy/6Q1zon3xECbfYDjrKug9zixl7OlJ6b++DZ/cY07o7zrKLJlcgTXAjuUU8M7PB3hjzX6OFiXzvjYLl/doxoB2Tfjs96P8sDPZdUEeHuTL6D4tGNOvpUcKiZC6Gz69F4oLBYBZ2KHLSDPRijsfbHW8OIthwNpXYNnjZnuI7WF+eeDhnrqK/G3Zl5LDwtX7eO+Xg64vgSJD/Ljp3NbcdG5rIj1YFn9XUjYzP9/CdzuSi57Hn0cu7cToPi28vuRFjTiyCb5+3FykG2qs6IVhGLz3y0Gmf/oneXYnkSH+/Ov6npzfoezF1N3ahsXpXmK9cWu4+jVodW6Zz7dubxqLVu/j6z8TXHNTmzcO5Ob+rbn+7JaEe2o+355V5kLn9lzzvT/2Xbf1N6skJxUWDIeU7WYFv4lLITTm/9u787goy7UP4L9hlWVYhn0HJUUFNxS0zEwNtE0FU1NT1GOL2nnT0lOdU7bY0WPL8TXt1DlviZmW5EJWLsclt9wSdw1U1FhkUZBdnIF53j9uGBjZRhx4Bvl9Px8+MwzjcI3c3DzXvVw3fj6dhTkJJ6Gu0CLMxxFfTukLdwcjzoImbwG+exYSFNgZ+RXm/2avS0hH9vLGGyO6wtOxie+38gnRnmK/BMIaX8VxL5hctYHkat26dZgyZQq++OILREREYOnSpUhISEBycjI8PDwwefJk+Pj4YNEiMRvz3nvvoX///ggODkZBQQE+/PBDJCYmIikpCd26dQMgSrEvXrxYrxT76dOn799S7BVqIPEl4Ox6AApgxJImRy0u5BRjQ1IGNp3I1Kt+9IC7PWY83BGjevs0v2rUiTWiqk/lbbFcYPza5pd+b+e0Wgk5xeUi6bojAcvIL0N2UTm8bSXMjgrFqD5+LTaibBIq1MDWeUBSvPi8x3jgqf8FLGVa5mNsxdliJuvEN0DVBngAYqlg70lAz2cB+7rHUzSkwb7jyBfA1vnifu9JorrXXVa+0lRqsf1cNr46cEV3xk5tDwW7YHw/f0R194C1hZHbpCQBfxwU5yKd/wEoza35mq0r0O1pkWgFPNgi1cRalLpMHH59JkF83mM88NRS443I13I3F0iFtzT47mgaVh28qpsht7Iww+hePpj+cNA9lf0uvKXBsl0XsergVVRoJViaKzBtYBBmPxp814UY2hxJAlK2AjverjmM3OUB4LH3gC4jjLq38GJOMWavPYGUHLEs78VHOuHVqM71Hvmgaxv9OsJy80tAdlWJ9V6TgBGL651Vv6WuxA8nMxF/8KpeJcoBHV0Q91AghnX1MO5yump/HATWjAXUxYBff2BiQvMHdMsLgVVPA1knRXGUadv0BjWS/riJGV8fQ36pGj5ONvgqrp9hlSoNlLd2BlwuJCBd64bh6sXw9XDHuyO7o3/HuksA67WivzifcPIPQMfBRovrTkyu2kByBQDLly/XHSLcq1cvLFu2DJGRkQCAwYMHIzAwEPHx8QCAOXPmYOPGjcjOzoazszPCw8OxcOFC9O5dc8hl9SHC//73v1FQUICBAwfis88+Q+fOhl3gt6nkSl0KrHsOSN0lquaM/qLBEYv8UjU2n8zEhuOZOJNZc+K8s60lnu7pjdhwX4T5OBpnGVnmcTFlX5QJWCnFDNZdlGclw9y+rca2bVuN28mpS8WFfklO1W0uUFJ1a60EVJ0Al47i1sm/dS5gS2+Idp52EIACeOxdsXziflzyKEliee3x1cD5RDEqC4jf787DxRkywcOanKGp03dIErD/I2D3QvGEyJeA6L/f89LdU+kFWPnrFSRnF+PREHeM7+eHABe7e3pNg2krxSzW2Y3A75vFErpq9h5At5Fi+aBff9NdolxxW1y8ZhwTiXXOGUBhLn42kS+0WBtvzgWSplKLrWez8eX+yziVUfM35OEHXDF9YBAe6exm8N+PSq2YUfloe4ruQOthXd3x1ye6Ici1ldqPqajUiEGjPYtq2nDgw0DU+0Y9wLtcU4n3fzqPNUfSAIgjRJaN7w0/lf5yYI36NpJXzUFo9nqxP8xGJQayuj1d5zXT88vE0r/f0lF4S8y02FiaY3QfH0wZEGjU5KNBGceAb2JEcuTdB5i04e4rI6vLRLn1tINikGbq1noHhf/IK8XU+N9w+XoplNYWWDGxDwZ1bngW0BB5JbexZFsKfj6Wgq1Wb8DP7DpSvEej4/Sv7u68ww+DxdLCFw8AnmH3FFNjmFy1keTK1LSZ5KosH1g7Fsj4TexBGLdaXHTVoq7QYndyLjYcz8AvybmoqJqjtzBT4NEQd8T28cWQkKZLUjdLyXWxZ6B62cOg+WIvlqle5LRBBndykiTaS0l10pQj7hfniM91iVQOoC4xPAAzS8A5EHDpBLgEi2UULp1E4uXgY5yfdfYZ4NsJQGGaOIsm9kugc9S9v25bUF4EnNsoEq3MYzWPK73ETFbvSeL/ux56bcPCQoyOH1wmvvjIX8Tv4v2UnFZWAFf3VSVaP4r9eNWU3kD3USLR8u0n3/uWJKAgTfTZGcfEzzTrFFBZq5iKrSswdhUQOLBFQ7mXCyRJkpD0x018eeCK3tKvB9ztMW1gEEb39ml0Fv3olXy8s/kczlcdYB3sbo+3nuyGR+7xIrXNKy8EDvwTOPSZWPkBAD3GAUPeApz8mvealRXid+HWTfE34NZNnL54GduO/Q6biiK4mZdhkK85vK3KxHNu3YRUlg+FRux5Q/AwYOQKQOmpe0lJknAoNQ/xB69i5+85up+/n8oGk/sHYmxfv1Y97xGA+D36epQ409MjDJicCNgZWA2yQi0OCL60E7B2BOJ+BLx6Nvj0gjI1nl+dhKNX8mFupsAHo0IxPuLul+1WaiWsOfIHPtqeojs3c16XG5j5x/+I4izjvwVCHjfsxbRa4H1XsZR4bnKLHvXB5IrJVbO0ieSqMFOM1FxPFnsOJnwP+PUDIDq+M5mF2JCUgc2nrulVqwvzcURsHx883cundc4xqdQA/30LOPIv8fkD0WK9to1Ty3/vdkBTXordPyZgaEQ3WNzKq5lh0pt5yhGPaZuuWqhjaStG/pWeNbd2buKPf/5lsWwt/0rNBUB9LDoAzkFVyVatpMulk0gODLnAPb9ZbKLWlInXePY7wK2L4e/jfpJzXsxsnP5Of4YmYKAogtH1ab2CFLq+Y3g0LP/7OpC0Unwh6gPgwdmtHHwrq9SI/RjnNgG//wTcrpllgaOfmNEKjRGj3C2ZaN0uFrP4mcdEMpXxmxhZvpOtC+DTVyR+vVv+DDTAeBdI6fllWPmr2JdVcltcIKrsxHlZkwYE6BU7ySy4hUVbftcVWFB2sMCcYZ3x3ICAuxuhv98VpIkZ5juLXkTMEAVdym5WJUL5tZKmfL0ESvd5eWHj36sBFWZWUDz2Psz718yelqkrsOlEJlYdvIoLOTWDcAODXTHlwUAMCXFvmaV/hso5D3w9UiwVdgsRy+NqJYX10lYC66eJVQKWtsBzmxrcT1bb7YpKvL7hDDadyAQAvDS4E+ZFdTF4f+Cxq/l4+4eaAYZuXg54b2R39A1UAdv/ChxaLv7mzjxsWJJ46ybwj0Bx/2+5xq+eWAuTKyZXzWLyydWNi8Dq0aJqj9JbdAbuIcguLMemE5nYeDwDF3NrOj53pTVG9/ZBbLjvPa2NvyenvhN7CSrKxQX2+LWAe4g8schFWymW3KlLxO3t4qrPqx+rfrzW/aaeW3vE2xA2qpqEyd4DUHoA9p5Vt7XuG1KpTqsFijJEkYH8VCDvctVtKnDzauPJnKWt/vLC2omXnZsY4d/3IbDn7+L5HQeLamk2TVQMaw8q1EDKFlEE49IuoLr8tLUjEBYrlg1694amogJbf96MJzU/wezcRgAKsbQnvJ2df1JxG0jdLRKt5C1ib0Y1pwAxmxUaIwpH3EuipdWKTfAZv1V9JAG554E7y4ObWYolO779AN++4sM5qNVn04x9gVRUrkHCb+lY+etVZBaIIzyszM3wdC9vTOofgD0pufh8byrKNVooFMCzEf549bHOcDFiUYz7TuZxMThZvfrjXlg7iP7TViVubVSo7OCEI9kSdlxV46ZWCTsnV7wwvC+8PDyx/eApRD85GpaWlkjLK8PXh0QCXT3DYmtljtg+vpjyYIBxitUYy42LYt9U8TXxN2XK5oZL3Wu1wI8vi0ErcysxeBc81OBvJUkSlu68iP/dJfbLPdHDCx8/07PRWdvc4nIs3pqMjcdFUubQwQKvRXfBxMiAmsRUUw7851HRf4Q8KSohNtU/3LgELA8X2zDezDD4PTQHkysmV81i0slV5nFgzRgxcu0SjPLxG7A90xLrkzLw66Ubuul5awszRHf3RGy4Lx7q5GL8UtLNce2k2IdVmA5Y2QOjPhOj7W11aZK2EijOAgozRHndwjRxW5QplnPdmTBV3GqZMGAOhdIDCr1EyVMUP1B61jxm525QRTijqKwQ/x+1E67q24K0mqp49bFSipG6m1fE55EvAVEL234VuJZQmCEq/51YLf5fq3mEorLnBOQe/h5eRSfEfq2YfwOhsfLFago05WLpz7mNQMo2oHrpEyBmRrvHiGTLo3vT/VLJdf0Zqczj+olbNUf/miTKt59I4kygCEtLXSBVVGqx/VwOvjxwud5iJxFBKix4qhu6e7OKrEGqi17sfEck75Z2VUmSsy5JujNp0rtv4yxWijRSgfDAxRuYk3AS14tvw9rCDH97PAT2uafh1CUSa46mY1dyrq4CaICLLSYPCMQzfX3hYKoFR/KviASrME3sC57yo1i+XpskierGhz8TpeWfWVXvnjJDbEjKwOsbT0NTKaGPvxP+M7lvnUGDikotVh36A0t3XEBx1QzvuL5+mD+8S/0DDFmngf8MEYOUo/4F9JrQeBBpR4CvosT7/J9TzXofhmJyxeSqWUw2uUr/FfhuIqAuQalLGD52+wAJv5frlmIA4iyZ2D6+eLyHl2l2fKU3gPVTxRkuAGBuXWsGxaPWUjR3/UTBzq31L6415SJRKkgTCWFBeq3bNHEWhrai6de5k8JclIu1sges7GpurZVVn1c/Vv24vf7nVvZVj9lBo7DGlt0H8PgTT7adTq5CLf5P81PF8sLaM1+F6dCN9JtZAk9+AvSZLGu4bYJWK/YbHV8t9hvVWq4pWXSAYuzXQOdoGQM0Qeoy4OJ/RaJ14b/6gx+unWvO0XIPEW02+0zNrFTmMTE7eydLO8CnT00i5dNX9GEmqDUukI6niX1Z285mw0NpjTef6Ionwrzuz7P3WpokieWuLTRAdqPkNuYmnMK+qlL4SksJxZqan9Ogzm6IezAAgzu7t43S+AXpwNdPi2XsDj7A5M36Z57tWVxzJqghyUsTDqXm4YXVx1BUXgF/lS1WTu2HTm6iLPzhy3lY8MM5XaXGHr6OeG9kKHr5OTX+ovs+EmeiWTsAL/3a+HEMyT8D300Qx5PM2H1P76UpTK6YXDWLKSZXTwRVwDzxRSi0aiSZhWFy2SsohSjP66eyQUxvX8T08Wm9Kl33orIC2PWOOMvF4OREIWYz9JawedS/xK2Bg1DrKC+sSZgKM+omUbUPd22ImQXg4C1Gp538xH4OR18xWlgnYaq6b2FttNm6+66T05SLi9abV8TeKlVHuSNqe8rygTPrIR3/Grfz0mAxfhUsgh+VOyrTdrsEuLBNLB28uEN/L6GTvyj8Umd/oUK0Ud++Nful3Lu2mfLvrdl3FJSpYWtl0TKFk8hotFoJ/3fgMpZsS0GFVoKdtTmeCffDcwMCdIlCm1KUJRKsGxfENcLkzWKw5NBnwPY3xHNGLBFVOY3gUm4JpsYfRXr+LTjaWGJRTBi2nc3G5lPXAABOtpaYHx2Ccf38DNubVlkhztzKOCqqR07e3HCRqONfizMAH4gW5ehb0H133WGgu8kNuM7GxBWXV6Dy8i8wOxEPBSRsqYzAK+WzYGVtg7Fhnojt44t+gaq2MZJUzdxCLPN69G9i42l15bqGqtiV5IplZKXXxUfOmcZf39qh7syXjbP4XrVnn2pvcm+Ipa1ImGonTk7+NY8pvdrMxVSbYNlB/PFrb/vxjMlWBUQ+j4o+U7F9yxY8HtCyVefuC9b24giLsDFiSW/KVpFoXdpZs9yydtEJ375ihooHpBvEybaVliPTPTEzU+D5QZ3QP9AZ67YfwKvjh0ClbMMH0jt4AXFbgNWjgJyzQPzjQN9pYj8vIK5BjJRYAaLq5aaZD2HG18dwIq0AM9ccByDGUidE+OO1qC53d4CyuYU4xubzgcDV/cCRz4EBM+t/bnWRI1sDz8SiFsXkyoRVVmrx7T/nYJb2WwDA2soh2BYwD0vCAxDd3RM2Vm38ot6yg0hUGpvqBsTeprI8/eSroURMUwbcLhIftQ9ibYiNc1Wi5K+fRDn5idkoW1Xb3RNGRHevgwPQc5z4uFUAZCYBqiBZik4QyaGrlxIR7hKUHe6DS0R7N7HnavVocThwdWL14MvAoNeM/u1c7a3x7Yz+eDXhFH4+k4Vefk54f2QownybORDj0kkMRv88V+y76zSk/sHH0hvi9m7P96IWcR/85ty/zCvKMNbiAKAGfvObhiGxf8cEpzY8itRcZuZVM1HujR+MJ0miql71obe6MuQ5Ijmzc6uVSPmK+9ZtcKkDEbUOG6e7qh5GRCbIViWqBn4zRiyxC48DHnu/xQZLOliaY/mE3nj9Zgh8nGzufWVR32miQuylncCm54HpO+vuvSvLF7eGnu1FLYrJlSmztkeHuE04sWUFek1e0q7WtjaLQiFGnTs46G9cJSIiovargyMwdQtwPcWwaqD3SKFQwE9l4P7vpl8MeHo58K8B4rDkfR8CQ/6q/5yy6pkrLgs0BdxdauI6uAUizY2b0YmIiIiazdwS8Axtm8t7HbyAJz4R9/d/LI6AqE2354ozV6aAyRURERERkSkLjQFCx4gCXxufF2doVivlzJUpYXJFRERERGTqnvgIUHqLsyF3LKh5nHuuTAqTKyIiIiIiU2fjDIxaIe7/9h/g0i6g4jagFgcUs1qgaWByRURERETUFnQaAvSbIe7/MAvISxX3FeaANc/eMwVMroiIiIiI2orH3gNcgoHiLGBT1UHIti6AGS/rTQF/CkREREREbYWVLTD6CzFblX1aPMZiFiaDyRURERERUVvi2xd4+NWaz1nMwmQwuSIiIiIiamsemQ949RT3mVyZDCZXRERERERtjbkl8Ew8EBoL9J8pdzRUxULuAIiIiIiIqBlUHYExX8kdBdXCmSsiIiIiIiIjYHJFRERERERkBEyuiIiIiIiIjIDJFRERERERkREwuSIiIiIiIjICJldERERERERGwOSKiIiIiIjICJhcERERERERGQGTKyIiIiIiIiNgckVERERERGQETK6IiIiIiIiMgMkVERERERGRETC5IiIiIiIiMgImV0REREREREbA5IqIiIiIiMgImFwREREREREZAZMrIiIiIiIiI2ByRUREREREZAQWcgdgiiRJAgAUFRXJHAmg0WhQVlaGoqIiWFpayh0OmRi2D2oI2wY1hu2DGsK2QY1pr+2jOieozhEaw+SqHsXFxQAAPz8/mSMhIiIiIiJTUFxcDEdHx0afo5AMScHaGa1Wi2vXrkGpVEKhUMgaS1FREfz8/JCeng4HBwdZYyHTw/ZBDWHboMawfVBD2DaoMe21fUiShOLiYnh7e8PMrPFdVZy5qoeZmRl8fX3lDkOPg4NDu2rEdHfYPqghbBvUGLYPagjbBjWmPbaPpmasqrGgBRERERERkREwuSIiIiIiIjICJlcmztraGgsWLIC1tbXcoZAJYvughrBtUGPYPqghbBvUGLaPprGgBRERERERkRFw5oqIiIiIiMgImFwREREREREZAZMrIiIiIiIiI2ByRUREREREZARMrkzcihUrEBgYiA4dOiAyMhJHjx6VOySS2TvvvAOFQqH3ERISIndYJJN9+/bhqaeegre3NxQKBRITE/W+LkkS3n77bXh5ecHGxgbDhg3DxYsX5QmWWlVTbSMuLq5OXzJ8+HB5gqVWtWjRIvTr1w9KpRLu7u4YNWoUUlJS9J5TXl6OWbNmwcXFBfb29oiNjUVOTo5MEVNrMqR9DB48uE7/8eKLL8oUsWlhcmXC1q1bh7lz52LBggU4fvw4evbsiejoaOTm5sodGsmse/fuyMrK0n0cOHBA7pBIJqWlpejZsydWrFhR79eXLFmCZcuW4fPPP8eRI0dgZ2eH6OholJeXt3Kk1NqaahsAMHz4cL2+5Ntvv23FCEkue/fuxaxZs3D48GHs2LEDGo0GUVFRKC0t1T1nzpw5+PHHH/H9999j7969uHbtGmJiYmSMmlqLIe0DAGbMmKHXfyxZskSmiE0LS7GbsMjISPTr1w/Lly8HAGi1Wvj5+eHll1/G66+/LnN0JJd33nkHiYmJOHnypNyhkIlRKBTYtGkTRo0aBUDMWnl7e+PVV1/Fa6+9BgAoLCyEh4cH4uPjMX78eBmjpdZ0Z9sAxMxVQUFBnRktan+uX78Od3d37N27F4MGDUJhYSHc3Nywdu1ajBkzBgCQnJyMrl274tChQ+jfv7/MEVNrurN9AGLmqlevXli6dKm8wZkgzlyZKLVajaSkJAwbNkz3mJmZGYYNG4ZDhw7JGBmZgosXL8Lb2xsdO3bExIkTkZaWJndIZIKuXLmC7OxsvX7E0dERkZGR7EcIALBnzx64u7ujS5cueOmll5CXlyd3SCSDwsJCAIBKpQIAJCUlQaPR6PUdISEh8Pf3Z9/RDt3ZPqqtWbMGrq6uCA0NxRtvvIGysjI5wjM5FnIHQPW7ceMGKisr4eHhofe4h4cHkpOTZYqKTEFkZCTi4+PRpUsXZGVl4d1338XDDz+Ms2fPQqlUyh0emZDs7GwAqLcfqf4atV/Dhw9HTEwMgoKCkJqaijfffBMjRozAoUOHYG5uLnd41Eq0Wi1eeeUVPPTQQwgNDQUg+g4rKys4OTnpPZd9R/tTX/sAgAkTJiAgIADe3t44ffo0/vKXvyAlJQUbN26UMVrTwOSKqI0ZMWKE7n6PHj0QGRmJgIAAJCQkYPr06TJGRkRtSe1loWFhYejRowc6deqEPXv2YOjQoTJGRq1p1qxZOHv2LPfuUr0aah/PP/+87n5YWBi8vLwwdOhQpKamolOnTq0dpknhskAT5erqCnNz8zqVeXJycuDp6SlTVGSKnJyc0LlzZ1y6dEnuUMjEVPcV7EfIEB07doSrqyv7knZk9uzZ+Omnn/DLL7/A19dX97inpyfUajUKCgr0ns++o31pqH3UJzIyEgDYf4DJlcmysrJCeHg4du3apXtMq9Vi165dGDBggIyRkakpKSlBamoqvLy85A6FTExQUBA8PT31+pGioiIcOXKE/QjVkZGRgby8PPYl7YAkSZg9ezY2bdqE3bt3IygoSO/r4eHhsLS01Os7UlJSkJaWxr6jHWiqfdSnusgW+w8uCzRpc+fOxZQpU9C3b19ERERg6dKlKC0txdSpU+UOjWT02muv4amnnkJAQACuXbuGBQsWwNzcHM8++6zcoZEMSkpK9EYKr1y5gpMnT0KlUsHf3x+vvPIKFi5ciAceeABBQUF466234O3trVc1ju5PjbUNlUqFd999F7GxsfD09ERqairmz5+P4OBgREdHyxg1tYZZs2Zh7dq1+OGHH6BUKnX7qBwdHWFjYwNHR0dMnz4dc+fOhUqlgoODA15++WUMGDCAlQLbgabaR2pqKtauXYvHH38cLi4uOH36NObMmYNBgwahR48eMkdvAiQyaZ9++qnk7+8vWVlZSREREdLhw4flDolkNm7cOMnLy0uysrKSfHx8pHHjxkmXLl2SOyySyS+//CIBqPMxZcoUSZIkSavVSm+99Zbk4eEhWVtbS0OHDpVSUlLkDZpaRWNto6ysTIqKipLc3NwkS0tLKSAgQJoxY4aUnZ0td9jUCuprFwCklStX6p5z69YtaebMmZKzs7Nka2srjR49WsrKypIvaGo1TbWPtLQ0adCgQZJKpZKsra2l4OBgad68eVJhYaG8gZsInnNFRERERERkBNxzRUREREREZARMroiIiIiIiIyAyRUREREREZERMLkiIiIiIiIyAiZXRERERERERsDkioiIiIiIyAiYXBERERERERkBkysiIiIiIiIjYHJFRERERERkBEyuiIjovhMXF4dRo0bJHQYREbUzTK6IiIhamFqtljsEIiJqBUyuiIioXfnkk08QFhYGOzs7+Pn5YebMmSgpKQEAlJaWwsHBAevXr9f7N4mJibCzs0NxcTEAID09HWPHjoWTkxNUKhVGjhyJq1ev6p5fPXP2wQcfwNvbG126dGm190dERPJhckVERO2KmZkZli1bhnPnzmHVqlXYvXs35s+fDwCws7PD+PHjsXLlSr1/s3LlSowZMwZKpRIajQbR0dFQKpXYv38/fv31V9jb22P48OF6M1S7du1CSkoKduzYgZ9++qlV3yMREclDIUmSJHcQRERExhQXF4eCggIkJiY2+dz169fjxRdfxI0bNwAAR48exYMPPoj09HR4eXkhNzcXPj4+2LlzJx555BF88803WLhwIX7//XcoFAoAYtmfk5MTEhMTERUVhbi4OGzbtg1paWmwsrJqybdKREQmhDNXRETUruzcuRNDhw6Fj48PlEolnnvuOeTl5aGsrAwAEBERge7du2PVqlUAgG+++QYBAQEYNGgQAODUqVO4dOkSlEol7O3tYW9vD5VKhfLycqSmpuq+T1hYGBMrIqJ2hskVERG1G1evXsWTTz6JHj16YMOGDUhKSsKKFSsA6Bed+NOf/oT4+HgAYkng1KlTdbNUJSUlCA8Px8mTJ/U+Lly4gAkTJuhew87OrvXeGBERmQQLuQMgIiJqLUlJSdBqtfj4449hZibGFxMSEuo8b9KkSZg/fz6WLVuG8+fPY8qUKbqv9enTB+vWrYO7uzscHBxaLXYiIjJ9nLkiIqL7UmFhYZ3ZJVdXV2g0Gnz66ae4fPkyVq9ejc8//7zOv3V2dkZMTAzmzZuHqKgo+Pr66r42ceJEuLq6YuTIkdi/fz+uXLmCPXv24M9//jMyMjJa8y0SEZGJYXJFRET3pT179qB37956H6tXr8Ynn3yCf/zjHwgNDcWaNWuwaNGiev/99OnToVarMW3aNL3HbW1tsW/fPvj7+yMmJgZdu3bF9OnTUV5ezpksIqJ2jtUCiYiI6rF69WrMmTMH165dY2EKIiIyCPdcERER1VJWVoasrCwsXrwYL7zwAhMrIiIyGJcFEhER1bJkyRKEhITA09MTb7zxhtzhEBFRG8JlgUREREREREbAmSsiIiIiIiIjYHJFRERERERkBEyuiIiIiIiIjIDJFRERERERkREwuSIiIiIiIjICJldERERERERGwOSKiIiIiIjICJhcERERERERGcH/A9O146VFSkJ4AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "probe = 'non_linear'\n",
        "probe_args = {\n",
        "    'hidden_dim1': 256,\n",
        "    'hidden_dim2': 256,\n",
        "}\n",
        "encoder_results = iterate_training_layers('2b', tf_2b_df, num_layers=27, encdec='encoder', probe='non_linear', probe_args=probe_args)\n",
        "decoder_results = iterate_training_layers('2b', tf_2b_df, num_layers=27, encdec='decoder', probe='non_linear', probe_args=probe_args)\n",
        "\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', probe, 'factual', 'encoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', probe, 'factual', 'decoder')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}