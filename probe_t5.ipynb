{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9L0bmfKk_Q-"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAmVjLTRYW5"
      },
      "source": [
        "preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hCfcLCIRRcMR"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hzupOBSRon7",
        "outputId": "905b908a-cc22-48a9-feb0-d5ae49504e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00xoYkRWReqW"
      },
      "source": [
        "download tokenizer and model from hf\n",
        "\n",
        "note: do not download and run both models at the same time, colab has some limitation and it is not guaranteed to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P-W51utcr27g"
      },
      "outputs": [],
      "source": [
        "# login with hf\n",
        "from huggingface_hub import login\n",
        "token = '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'\n",
        "login(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "6hkR4lH07r2Y",
        "outputId": "ac36b216-047f-4632-9a22-3bed23dcd337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "e6f13314bf0449469b7e1996060c7d9d",
            "fa177172de1d488183e6f21f0b01ff8e",
            "153dcb12d56d4f6da2fe63bf9fce22ad",
            "c3f3de9a164847b197faab0d3a583184",
            "1ac5aa5c9f01411a99be47dcbcd7cb34",
            "8cdfb2448cb244af9d72da08b08d1891",
            "6edbd4139fd247389aa4b324a74de9b7",
            "b4def312ba8c4846b2519ad5cc9e8b6d",
            "5d1ebdbecdb64454b168df599433d331",
            "6a7f92eaf5254eed9a8a88620130d0b1",
            "423dfb6ace734448a7079995e932099c",
            "70cd570d93234718b33ba62874c89ed0",
            "b74451c79c5d4077a5d46bceced2c2c3",
            "459f02f97d1448fca73f154cf104cf9a",
            "25ef3b807e504c89ba7d8688d524cff2",
            "03267f7b86a44f43bdb8b0973a0e277a",
            "dcd6e0099cf6402b87e19648ebed90bc",
            "4e81ed00b3da4e2e8eb014106ca7375e",
            "743a252ea0a1414e9dfe6e6b3500b5f0",
            "51175298c9274784a8c7be337caeeb05",
            "1b2cae40c40d40cba5cb43e5d458daaf",
            "cad80c8296b2429f93c3fa3d6a6cbd49",
            "f967b49e764641ddb8fe749a8186eda8",
            "dda84cabc33c40059ea68037990ffd85",
            "38e9d2ec592f46c9a4798ab3d2d6d482",
            "5e174a57179343408c1bda53de71d2fa",
            "108dbc1cc5e7492ca36f3337b8a8ed4f",
            "412edab557744dbbacc5445d0bb4566f",
            "12a4adda8c414bf591b86c1246461a13",
            "2aebbfb7359b4c7c99b37d449e5b41b1",
            "5ef3bb4a8a2a404bb072611eb9b14d1a",
            "789e0b087e864fb28773e3c9af30bdd0",
            "e2d17d0fd4e74905954c4cd978a95886",
            "507f686b4c3040a78cd4b413b14b08c8",
            "bff715282e5444e3b0528f94bd479c72",
            "7a46d00698814b43a2b2dc4102c7404f",
            "c9658fbd80d041ddbe9c820b036434e8",
            "2af94c4c97eb4656b3a1bf7d5424ed68",
            "04d63de812a543b0a20e0f7cd5b5d11b",
            "4d919fd581d3471cbf9962e62194af35",
            "1601e5e256a643b7976e1b7c84278bad",
            "2ddd6263e93340cb8a0a5f2c106b9aba",
            "33ae55d10040422ab283444e44633c9e",
            "149c824d03a947559b14dbeeb199849b",
            "3081a793472d46f1912fd7f3f8c21414",
            "0af102b0cb4b437f80f3b670dfba6bec",
            "d5524d4496644ccaacda9da98d8b1a80",
            "bb34fe96634a41c8acb290be5941e75c",
            "7f0c256e59c64e388880b2e5ed4f19f5",
            "e6bf9039ce644ff7b313e3a14f5eefd2",
            "c17f954288954960bf5ce615504de4c5",
            "bf274fff773e44188e3b2036cc44eba2",
            "76b00bec3f6c41438e548487600736f3",
            "149df6d179fb402ebd1c7690f8c52b13",
            "68f01f05fd204671b6495d0eb34991c4",
            "2493a8500c96450e84e42d91fb42f71e",
            "9c7235f082f547f3ace1b40d02391401",
            "695b0258b96c410f9f2e2bfa22d9636d",
            "6cf87eb4eff44c858ca88fd60af538c3",
            "8b56460dbdf04fe7a84fb432f0f432dc",
            "81e3770234f144a48dbc8ad65f71b87e",
            "cfa19f07fb034730a5d8460a4ec227fe",
            "0e5b4562b2464c1e8b84fd132727fba2",
            "58a3f48027484e608d522be8f036bd30",
            "b3296cccfd4c4c14a3bbd631b16da6bb",
            "bb238ee2614244838ae4c2dd1e5dc65e",
            "266c84ed137a440498b9f43c8b46677c",
            "8060597b43624bb6a145cb3aa9ab526a",
            "6d962e8ee34145d686832dd84018a53b",
            "58ed648c11014250b444cedbef908786",
            "ec336b1d704e49cd87d5653e83762427",
            "b6619604fac949f5bc8d3a17b5067252",
            "c6a2856de55742a4801edd26a3279988",
            "d2ad7abf8f5d47c3a3ffd3d3fd722294",
            "973a629692544d3f8234b1b18e9588e3",
            "96171b33cd5d4874ba5ac251fce048ef",
            "43d1c4a9e621441c93ad95bae7662a68"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6f13314bf0449469b7e1996060c7d9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cd570d93234718b33ba62874c89ed0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f967b49e764641ddb8fe749a8186eda8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "507f686b4c3040a78cd4b413b14b08c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3081a793472d46f1912fd7f3f8c21414"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2493a8500c96450e84e42d91fb42f71e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "266c84ed137a440498b9f43c8b46677c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_id_b=f'google/t5gemma-b-b-ul2'\n",
        "tokenizer_b = AutoTokenizer.from_pretrained(model_id_b)\n",
        "model_b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xh4CfPuSlp2_"
      },
      "outputs": [],
      "source": [
        "model_id_2b=f'google/t5gemma-2b-2b-ul2'\n",
        "tokenizer_2b = AutoTokenizer.from_pretrained(model_id_2b)\n",
        "model_2b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_2b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhoYbqZOVMH8"
      },
      "source": [
        "## extracting the activations from the model\n",
        "\n",
        "We use mean pooling to obtain vector representations of sentences because SentenceBERT has shown that it works better than the CLS token. In our case, there is no CLS token, so this was not even an option. SentenceT5 has confirmed that mean pooling is the strategy that yields the best results for T5-based models when it is necessary to extract the sentence representation.\n",
        "\n",
        "So we use this strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkQE_B8aUUYH"
      },
      "outputs": [],
      "source": [
        "# non batched\n",
        "model_b.eval()\n",
        "\n",
        "text = 'tell me something about the human brain'\n",
        "\n",
        "inputs = tokenizer_b(text, return_tensors=\"pt\").to(model_b.device)\n",
        "\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model_b(\n",
        "        **inputs,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        output_hidden_states=True,\n",
        "    )\n",
        "\n",
        "encoder_hidden_states = torch.stack([e.cpu().squeeze(0) for e in outputs.encoder_hidden_states])\n",
        "decoder_hidden_states = torch.stack([o.cpu().view(-1) for o in outputs.decoder_hidden_states])\n",
        "\n",
        "#print(encoder_hidden_states.shape)\n",
        "#print(decoder_hidden_states.shape)\n",
        "\n",
        "print(len(outputs.encoder_hidden_states), len(outputs.decoder_hidden_states))\n",
        "print(outputs.encoder_hidden_states[0].shape, outputs.decoder_hidden_states[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Kl49XaoSp7Et"
      },
      "outputs": [],
      "source": [
        "# batched function\n",
        "def extract_activations_df(base_df, model, tokenizer, text_column, BATCH_SIZE=1):\n",
        "  df = base_df.copy()\n",
        "  enc_results = {}\n",
        "  dec_results = {}\n",
        "\n",
        "  # mean pooling considering padding and using attention mask to set to 0 pad token representations\n",
        "  def masked_mean_pooling(hidden_states, attention_mask):\n",
        "      mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "      masked_embeddings = hidden_states * mask_expanded\n",
        "      summed = torch.sum(masked_embeddings, dim=1)\n",
        "      count = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "      return summed / count\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_rows = len(df)\n",
        "\n",
        "  print(f\"Start processing {total_rows} sentences...\")\n",
        "\n",
        "  for i in tqdm(range(0, total_rows, BATCH_SIZE)):\n",
        "      batch_texts = df[text_column][i : i + BATCH_SIZE].tolist()\n",
        "      inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "      current_batch_len = inputs.input_ids.shape[0]\n",
        "      start_token_id = tokenizer.bos_token_id\n",
        "      decoder_input_ids = torch.full((current_batch_len, 1), start_token_id, device=model.device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(\n",
        "              **inputs,\n",
        "              decoder_input_ids=decoder_input_ids,\n",
        "              output_hidden_states=True,\n",
        "          )\n",
        "\n",
        "      # encoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      attention_mask = inputs.attention_mask.cpu()\n",
        "      batch_encoder_states = torch.stack([\n",
        "          masked_mean_pooling(e.cpu(), attention_mask)\n",
        "          for e in outputs.encoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float32).numpy()\n",
        "\n",
        "      # decoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      batch_decoder_states = torch.stack([\n",
        "          o.cpu().squeeze(1) for o in outputs.decoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float32).numpy()\n",
        "\n",
        "      num_enc_layers = batch_encoder_states.shape[1]\n",
        "      num_dec_layers = batch_decoder_states.shape[1]\n",
        "\n",
        "      # saving the activation results into the dictionaries\n",
        "      for layer_idx in range(num_enc_layers):\n",
        "          col_name = f'encoder_layer_{layer_idx+1}'\n",
        "          if col_name not in enc_results: enc_results[col_name] = []\n",
        "          vectors = list(batch_encoder_states[:, layer_idx, :])\n",
        "          enc_results[col_name].extend(vectors)\n",
        "\n",
        "      for layer_idx in range(num_dec_layers):\n",
        "          col_name = f'decoder_layer_{layer_idx+1}'\n",
        "          if col_name not in dec_results: dec_results[col_name] = []\n",
        "\n",
        "          vectors = list(batch_decoder_states[:, layer_idx, :])\n",
        "          dec_results[col_name].extend(vectors)\n",
        "\n",
        "  print(\"Saving in the DataFrame...\")\n",
        "  for col_name, vectors in enc_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  for col_name, vectors in dec_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  print(\"Done! Columns added\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I2uhxtHZjvPk"
      },
      "outputs": [],
      "source": [
        "def save_activations_df(df, dataset_name, model_id):\n",
        "  path = f'/content/drive/MyDrive/DTCS_datasets/{dataset_name}_{model_id.split('/')[1]}'\n",
        "  print(f'Saving {dataset_name}_{model_id.split('/')[1]} to GDrive...')\n",
        "  df.to_pickle(path)\n",
        "  print(f'Saved {dataset_name}_{model_id.split(\"/\")[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24jJOMSUTPI5"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mV-dGDMfz0x"
      },
      "source": [
        "## True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KdjyO6T2T9cd"
      },
      "outputs": [],
      "source": [
        "!curl azariaa.com/Content/Datasets/true-false-dataset.zip > true-false-dataset.zip\n",
        "!unzip \"true-false-dataset.zip\" -d \"true-false-dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qwY3ruMm7wKu"
      },
      "outputs": [],
      "source": [
        "# create a dataframe from the csv files\n",
        "dir_path = '/content/true-false-dataset/publicDataset'\n",
        "datasets_names = os.listdir(dir_path)\n",
        "dfs = []\n",
        "\n",
        "for dataset_name in datasets_names:\n",
        "  path = f'{dir_path}/{dataset_name}'\n",
        "  df = pd.read_csv(path)\n",
        "  df.insert(loc=2, column='area', value=dataset_name.replace('_true_false.csv',''), allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "tf_df = pd.concat(dfs, ignore_index=True)\n",
        "tf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWyQ_2Al3qT"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uU1emOEbfGpK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df = extract_activations_df(tf_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_tf_df, 'true-false', model_id_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcnkzN3TkKmp"
      },
      "outputs": [],
      "source": [
        "save_activations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hpgU5El7Li"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DpPU1tWl6sk"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df_2b = extract_activations_df(tf_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_tf_df_2b, 'true-false', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMsDqX2Unz_R"
      },
      "outputs": [],
      "source": [
        "activation_tf_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9XwUt5DhKLs"
      },
      "source": [
        "## CoLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_CCk8YEhK_v",
        "outputId": "aa1d3cbd-0c89-4f3f-8508-425ba402050c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-26 10:32:57--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
            "Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255330 (249K) [application/x-zip-compressed]\n",
            "Saving to: ‘cola_public_1.1.zip’\n",
            "\n",
            "\rcola_public_1.1.zip   0%[                    ]       0  --.-KB/s               \rcola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-11-26 10:32:58 (14.0 MB/s) - ‘cola_public_1.1.zip’ saved [255330/255330]\n",
            "\n",
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
        "!unzip cola_public_1.1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BoH9HrtvhfKo",
        "outputId": "b809d09f-3d91-4cc8-b8a3-20212b949845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 source  label  \\\n",
              "0     out_of_domain_dev      1   \n",
              "1     out_of_domain_dev      1   \n",
              "2     out_of_domain_dev      1   \n",
              "3     out_of_domain_dev      1   \n",
              "4     out_of_domain_dev      1   \n",
              "...                 ...    ...   \n",
              "9589    in_domain_train      0   \n",
              "9590    in_domain_train      0   \n",
              "9591    in_domain_train      1   \n",
              "9592    in_domain_train      1   \n",
              "9593    in_domain_train      1   \n",
              "\n",
              "                                               sentence  \n",
              "0                       Somebody just left - guess who.  \n",
              "1     They claimed they had settled on something, bu...  \n",
              "2             If Sam was going, Sally would know where.  \n",
              "3     They're going to serve the guests something, b...  \n",
              "4                  She's reading. I can't imagine what.  \n",
              "...                                                 ...  \n",
              "9589                   Poseidon appears to own a dragon  \n",
              "9590                     Digitize is my happiest memory  \n",
              "9591                     It is easy to slay the Gorgon.  \n",
              "9592       I had the strangest feeling that I knew you.  \n",
              "9593                What all did you get for Christmas?  \n",
              "\n",
              "[9594 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed6d389f-7989-4b9b-8edd-4985d518bd5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>Somebody just left - guess who.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They claimed they had settled on something, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If Sam was going, Sally would know where.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They're going to serve the guests something, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>She's reading. I can't imagine what.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed6d389f-7989-4b9b-8edd-4985d518bd5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed6d389f-7989-4b9b-8edd-4985d518bd5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed6d389f-7989-4b9b-8edd-4985d518bd5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e38840f7-951b-4973-a5b5-ac8bb6ca4903\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e38840f7-951b-4973-a5b5-ac8bb6ca4903')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e38840f7-951b-4973-a5b5-ac8bb6ca4903 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_00199d95-7ed9-42c9-80b6-be969900f6ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cola_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_00199d95-7ed9-42c9-80b6-be969900f6ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cola_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cola_df",
              "summary": "{\n  \"name\": \"cola_df\",\n  \"rows\": 9594,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"out_of_domain_dev\",\n          \"in_domain_dev\",\n          \"in_domain_train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9553,\n        \"samples\": [\n          \"He figured out that.\",\n          \"The captain sank the boat.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "path = '/content/cola_public/raw/'\n",
        "cola_files = os.listdir(path) # contiene ['out_of_domain_dev.tsv', 'in_domain_train.tsv', 'in_domain_dev.tsv']\n",
        "dfs = []\n",
        "\n",
        "for cf in cola_files:\n",
        "  df = pd.read_csv(f'{path}{cf}', delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "  df.drop(columns=['sentence_source', 'label_notes'], inplace=True)\n",
        "  df.insert(loc=0, column='source', value=cf.split('.')[0], allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "cola_df = pd.concat(dfs, ignore_index=True)\n",
        "cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cqOl6kTmFzR"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i-NK-2DehmTG"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'sentence'\n",
        "\n",
        "activation_cola_df = extract_activations_df(cola_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df, 'cola', model_id_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmcKoW3NiPEm"
      },
      "outputs": [],
      "source": [
        "activation_cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCH6zRgvmpcx"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3PVCeFPRquJJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'sentence'\n",
        "\n",
        "activation_cola_df_2b = extract_activations_df(cola_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GbcWA0pr1ZF"
      },
      "outputs": [],
      "source": [
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v1QYQnRrq6fz"
      },
      "outputs": [],
      "source": [
        "activation_cola_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoT3PwO9q9Of"
      },
      "source": [
        "## UD_English-EWT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NW-Jc9bqrArz"
      },
      "outputs": [],
      "source": [
        "!pip install conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/refs/heads/master/en_ewt-ud-train.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_tTkqzWvUnF"
      },
      "outputs": [],
      "source": [
        "from conllu import parse_incr\n",
        "\n",
        "def load_conllu(path):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for tokenlist in tqdm(parse_incr(f), desc='Parsing conllu'):\n",
        "            yield {\n",
        "                \"text\": tokenlist.metadata.get(\"text\", \"\"),\n",
        "                \"tokens\": [t[\"form\"] for t in tokenlist],\n",
        "                \"token_id\": [t[\"id\"] for t in tokenlist],\n",
        "                \"upos\": [t[\"upostag\"] for t in tokenlist],\n",
        "                #\"xpos\": [t[\"xpostag\"] for t in tokenlist],\n",
        "            }\n",
        "\n",
        "train = list(load_conllu(\"en_ewt-ud-train.conllu\"))\n",
        "\n",
        "items_to_df = {k:[] for k in train[0].keys()}\n",
        "\n",
        "for item in tqdm(train, desc='Converting to DataFrame'):\n",
        "  for k, v in item.items():\n",
        "    items_to_df[k].append(v)\n",
        "\n",
        "ewt_df = pd.DataFrame(items_to_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1oKlVx5WvVvJ"
      },
      "outputs": [],
      "source": [
        "ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zofmGBIYr27l"
      },
      "source": [
        "here we have 2 pos taggings upos (more general) and xpos (more specific).\n",
        "we will consider the upos for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcUn9Q030X33"
      },
      "source": [
        "now we define a function to convert the ewt dataset to a token version where the upos and xpos are more clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rufmBVMUy1Iz"
      },
      "outputs": [],
      "source": [
        "def convert_ewt_to_token(ewt_df):\n",
        "  token_ewt_dict = {\n",
        "      'words': [],\n",
        "      'sentence_id': [],\n",
        "      'upos': [],\n",
        "      'token_id':[]\n",
        "      #'xpos': [],\n",
        "  }\n",
        "\n",
        "  for row in ewt_df.iterrows():\n",
        "    for token, upos, token_id in zip(row[1]['tokens'], row[1]['upos'], row[1]['token_id']):\n",
        "      if isinstance(token_id, int):\n",
        "        token_ewt_dict['words'].append(token)\n",
        "        token_ewt_dict['sentence_id'].append(row[0])\n",
        "        token_ewt_dict['upos'].append(upos)\n",
        "        token_ewt_dict['token_id'].append(token_id)\n",
        "        #token_ewt_dict['xpos'].append(xpos)\n",
        "\n",
        "  return pd.DataFrame(token_ewt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bLtu7mX70qX3"
      },
      "outputs": [],
      "source": [
        "token_ewt_df = convert_ewt_to_token(ewt_df)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dE9O8Wc9WNC"
      },
      "source": [
        "there is a problem of subtokenization, we will use the word_ids provided by the tokenizer and send to it the sentence divided into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpoil2Sv59Ty"
      },
      "outputs": [],
      "source": [
        "num_sentences = token_ewt_df['sentence_id'].nunique()\n",
        "c = 0\n",
        "problematic_indexes = []\n",
        "\n",
        "for index in tqdm(range(num_sentences), desc='Checking sentences'):\n",
        "  words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "  inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "  word_ids = inputs.word_ids()\n",
        "\n",
        "  tokens = tokenizer_b.convert_ids_to_tokens(inputs.input_ids[0])\n",
        "\n",
        "  control = []\n",
        "  for word_idx in range(len(words)):\n",
        "    token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "\n",
        "    if not token_indices: # escape case (should not happen but who knows ...)\n",
        "        continue\n",
        "\n",
        "    subwords = [tokens[i] for i in token_indices]\n",
        "    reconstructed_word = ''.join(subwords)\n",
        "    control.append(reconstructed_word)\n",
        "\n",
        "  if control != words:\n",
        "    c = c+1 # c is the number of sentences where the subtoken aggregation differs from the 'dataset' tokenization\n",
        "    problematic_indexes.append(index) # sentence to be removed later\n",
        "\n",
        "assert(len(problematic_indexes)==c)\n",
        "print(f'\\nProblematic sentences: {c} ({c/(num_sentences)*100:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k41uxGH-9MUl"
      },
      "source": [
        "it works prefectly with all the sentences in the dataset!\n",
        "\n",
        "now let's try to get the word representations at a fixed layer for a fixed sentence: if a token corresponds to a word we will use the representation of the token as the representation of the word, if more token corresponds to a word (we know that thanks to the word_ids) we will calculate the mean (as done previously) to get the word representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtEFSwby4yp4"
      },
      "outputs": [],
      "source": [
        "index = 2\n",
        "layer = 0\n",
        "\n",
        "words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "\n",
        "model_b.eval()\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model_b(**inputs,decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "encoder_hidden_states = outputs.encoder_hidden_states[layer].squeeze(0)\n",
        "\n",
        "word_ids = inputs.word_ids()\n",
        "\n",
        "token_representation = []\n",
        "\n",
        "for word_idx in range(len(words)):\n",
        "  token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "  relevant_vectors = encoder_hidden_states[token_indices] # getting the correspondent hidden states\n",
        "  mean_vector = torch.mean(relevant_vectors, dim=0)\n",
        "  token_representation.append(mean_vector.cpu())\n",
        "\n",
        "print(f\"Original words in the sentence: {len(words)}\")\n",
        "print(f\"Tensor obtained: {len(token_representation)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0E7jX8S-Lgi"
      },
      "source": [
        "now let's put all together into a function to process the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs-Y2yyoDSSB"
      },
      "outputs": [],
      "source": [
        "def get_word_representation_df(model, tokenizer, df, batch_size=1):\n",
        "    sentences_words = df.groupby('sentence_id', sort=False)['words'].apply(list).tolist()\n",
        "    num_encoder_layers = model.config.encoder.num_hidden_layers + 1\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    word_representation_dict = {f'encoder_layer_{e+1}': [] for e in range(num_encoder_layers)}\n",
        "\n",
        "    for i in tqdm(range(0, len(sentences_words), batch_size), desc='Processing batches'):\n",
        "        batch_words = sentences_words[i : i + batch_size]\n",
        "        inputs = tokenizer(batch_words, return_tensors=\"pt\", padding=True, is_split_into_words=True, truncation=False).to(device)\n",
        "\n",
        "        current_batch_size = inputs.input_ids.shape[0]\n",
        "        start_token_id = tokenizer.bos_token_id\n",
        "        decoder_input_ids = torch.full((current_batch_size, 1), start_token_id, device=device, dtype=int) # [batch_size, 1 (<bos>)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "        all_layers_hidden_states = torch.stack(outputs.encoder_hidden_states) # [num_layers, batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # before iterating over batch sentences to calculate word_ids once\n",
        "        for b_idx in range(current_batch_size):\n",
        "            word_ids = inputs.word_ids(batch_index=b_idx)\n",
        "            num_original_words = len(batch_words[b_idx])\n",
        "\n",
        "            sentence_states = all_layers_hidden_states[:, b_idx, :, :] # [num_layers, seq_len, hidden_dim]\n",
        "\n",
        "            # later iterating over words\n",
        "            for word_idx in range(num_original_words):\n",
        "                token_indices = [k for k, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "                relevant_vectors = sentence_states[:, token_indices, :] # [num_layers, num_subtokens (possibily 1), hidden_dim]\n",
        "                mean_vectors = torch.mean(relevant_vectors, dim=1)\n",
        "                mean_vectors_np = mean_vectors.cpu().to(torch.float16).numpy()\n",
        "\n",
        "                # finally iterating over layers\n",
        "                for layer_idx in range(num_encoder_layers):\n",
        "                    word_representation_dict[f'encoder_layer_{layer_idx+1}'].append(mean_vectors_np[layer_idx])\n",
        "\n",
        "\n",
        "    token_representation_df = pd.DataFrame(word_representation_dict)\n",
        "\n",
        "    # safety check\n",
        "    print(f\"Original rows: {len(df)}\")\n",
        "    print(f\"Extracted rows: {len(token_representation_df)}\")\n",
        "\n",
        "    return token_representation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPQa2JlSttTm"
      },
      "source": [
        "now let's consider the labels\n",
        "\n",
        "we will consider the base label, with upos tags and also the control task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfC7lCmy9wsI"
      },
      "outputs": [],
      "source": [
        "# defining the POS tags\n",
        "upos_labels = token_ewt_df['upos'].unique()\n",
        "upos_tags = {u:i for i,u in enumerate(upos_labels)}\n",
        "\n",
        "# inserting the tags in the dataset\n",
        "token_ewt_df['upos_tag']=token_ewt_df['upos'].map(lambda upos: upos_tags[upos])\n",
        "token_ewt_df.drop(columns=['upos', 'token_id'], inplace=True)\n",
        "\n",
        "# defining the control task upos tags\n",
        "unique_words = list(token_ewt_df['words'].unique())\n",
        "np.random.shuffle(unique_words)\n",
        "\n",
        "num_upos_tags = len(upos_tags)\n",
        "token_ct_map_upos={x:i%num_upos_tags for i,x in enumerate(unique_words)}\n",
        "\n",
        "# adding the control task tags to the dataframe\n",
        "token_ewt_df['ct_upos_tag']=token_ewt_df['words'].map(lambda u: token_ct_map_upos[u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmdgN0aZyJb1"
      },
      "source": [
        "optional: xpos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db5e9y3AyLbc"
      },
      "outputs": [],
      "source": [
        "#xpos_labels=token_ewt_df['xpos'].unique()\n",
        "#xpos_tags={x:i for i,x in enumerate(xpos_labels)}\n",
        "#token_ewt_df['xpos_tag']=token_ewt_df['xpos'].map(lambda xpos: xpos_tags[xpos])\n",
        "#token_ewt_df.drop(columns=['xpos'], inplace=True)\n",
        "\n",
        "# control task\n",
        "\n",
        "#num_xpos_tags = len(xpos_tags)\n",
        "#token_ct_map_xpos={x:i%num_xpos_tags for i,x in enumerate(unique_tokens)} # token control task map for xpos\n",
        "#token_ewt_df['ct_xpos_tag']=token_ewt_df['tokens'].map(lambda x: token_ct_map_xpos[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Ou353rtRs8"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebqMzZuLtRs8"
      },
      "outputs": [],
      "source": [
        "token_representation_df = get_word_representation_df(model_b, tokenizer_b, token_ewt_df, 32)\n",
        "token_ewt_df=pd.concat([token_ewt_df, token_representation_df], axis=1)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSmHCgrtRs8"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK5HwVd8tRs8"
      },
      "outputs": [],
      "source": [
        "token_representation_df_2b = get_word_representation_df(model_2b, tokenizer_2b, token_ewt_df, 8)\n",
        "token_ewt_df_2b=pd.concat([token_ewt_df, token_representation_df_2b], axis=1)\n",
        "token_ewt_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfyDPIb1Xul"
      },
      "source": [
        "### previous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NeLhbgoHE2B"
      },
      "source": [
        "now let's define the function to get each token representation.\n",
        "\n",
        "First let's understand how the tokenizer works and how to adapt the tokenizer tokens with the dataset tokens (token at word level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oUGttIV6RRsG"
      },
      "outputs": [],
      "source": [
        "sentence_id = 0\n",
        "text = ewt_df['text'][sentence_id]\n",
        "words = token_ewt_df[token_ewt_df['sentence_id']==sentence_id]['words'].to_list()\n",
        "\n",
        "inputs = tokenizer_b(text, return_tensors=\"pt\").to(model_b.device)\n",
        "tokens = [t.replace('▁','') for t in tokenizer_b.convert_ids_to_tokens(inputs.input_ids[0])]\n",
        "\n",
        "# this dictionary will contain an index and a list of sub tokens that compose the word\n",
        "subtoken_dict = {i:[] for i in range(len(words))}\n",
        "wt_count=0\n",
        "subword=''\n",
        "for i in range(len(tokens)):\n",
        "  if subword+tokens[i] == words[wt_count]:\n",
        "    subtoken_dict[wt_count].append(tokens[i])\n",
        "    wt_count+=1\n",
        "    subword=''\n",
        "  else:\n",
        "    subtoken_dict[wt_count].append(tokens[i])\n",
        "    subword=subword+tokens[i]\n",
        "\n",
        "print(subtoken_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx7y9yA5nzPe"
      },
      "source": [
        "defining a function to handle this behaviour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sw1MqZ0nyqA"
      },
      "outputs": [],
      "source": [
        "def get_subtokenization(sentence_id, tokenizer):\n",
        "\n",
        "    text = ewt_df['text'][sentence_id]\n",
        "    word_tokens = token_ewt_df[token_ewt_df['sentence_id']==sentence_id]['words'].tolist()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model_b.device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
        "    tokens = [t.replace(\"▁\", \"\") for t in tokens]\n",
        "    subtoken_dict = {i: [] for i in range(len(word_tokens))}\n",
        "\n",
        "    wt_count = 0\n",
        "    subword = \"\"\n",
        "\n",
        "    for tok in tokens:\n",
        "        if wt_count >= len(word_tokens):\n",
        "            break\n",
        "\n",
        "        target = word_tokens[wt_count]\n",
        "\n",
        "        subtoken_dict[wt_count].append(tok)\n",
        "        subword += tok\n",
        "\n",
        "        # perfect match -> process next token\n",
        "        if subword == target:\n",
        "            wt_count += 1\n",
        "            subword = \"\"\n",
        "\n",
        "    return subtoken_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHXnlBn3oTXr"
      },
      "source": [
        "let's check if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "luT0KGsgoEmG"
      },
      "outputs": [],
      "source": [
        "num_sentences = len(ewt_df)\n",
        "c = 0\n",
        "problematic_indexes = []\n",
        "\n",
        "for i in tqdm(range(num_sentences), desc='Checking sentences'):\n",
        "  subtoken_dict = get_subtokenization(i, tokenizer_b)\n",
        "\n",
        "  sentence_token_check = []\n",
        "\n",
        "  for k,v in subtoken_dict.items():\n",
        "    subtoken_list = ''.join(v)\n",
        "    sentence_token_check.append(subtoken_list)\n",
        "  word_tokens = token_ewt_df[token_ewt_df['sentence_id']==i]['words'].to_list()\n",
        "  if sentence_token_check != word_tokens:\n",
        "    c=c+1 # c is the number of sentences where the subtoken aggregation differs from the 'dataset' tokenization\n",
        "    problematic_indexes.append(i) # sentence to be removed later\n",
        "\n",
        "assert(len(problematic_indexes)==c)\n",
        "print(f'\\nProblematic sentences: {c} ({c/(num_sentences)*100:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkXNPV6RqZ2e"
      },
      "source": [
        "apparentely 1647 out of the 12543 sentences in the dataset have problems with this subtoken aggregation operation.\n",
        "\n",
        "This happens because the tokenizer does not divide some elements, for example \":]\" is kept by the tokenizer where in the dataset these are two tokens \".\" and \"]\".\n",
        "\n",
        "we can consider removing these sentence as the dataset is still big enough for out scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgNazlEC06G2"
      },
      "outputs": [],
      "source": [
        "# drop these sentences from the original dataset\n",
        "ewt_df.drop(index=problematic_indexes, inplace=True)\n",
        "ewt_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# convert the new dataset in the token version\n",
        "token_ewt_df = convert_ewt_to_token(ewt_df)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdm0gPNlv5sv"
      },
      "source": [
        "finally it's time to get the token representations with the subtoken considerations defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh8aGtk0v-tY"
      },
      "outputs": [],
      "source": [
        "# fixed index and layer to test\n",
        "index = 0\n",
        "layer = 0\n",
        "\n",
        "sentence = ewt_df['text'][index]\n",
        "inputs = tokenizer_b(sentence, return_tensors=\"pt\").to(model_b.device)\n",
        "\n",
        "model_b.eval()\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model_b(\n",
        "        **inputs,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        output_hidden_states=True,\n",
        "    )\n",
        "\n",
        "encoder_hidden_states = [o.cpu() for o in outputs.encoder_hidden_states]\n",
        "decoder_hidden_states = [o.cpu() for o in outputs.decoder_hidden_states]\n",
        "\n",
        "subtokens = get_subtokenization(index, tokenizer_b)\n",
        "token_representation = []\n",
        "encoder_hidden_states = encoder_hidden_states[layer].squeeze(0)\n",
        "\n",
        "token_index = 0\n",
        "for k,v in subtokens.items():\n",
        "  n = len(v)\n",
        "  if n>1:\n",
        "    mean_tensors_list = []\n",
        "    for i in range(n):\n",
        "      mean_tensors_list.append(encoder_hidden_states[token_index+i])\n",
        "    mean = torch.mean(torch.stack(mean_tensors_list), dim=0)\n",
        "    token_representation.append(mean)\n",
        "  else:\n",
        "    token_representation.append(encoder_hidden_states[token_index])\n",
        "  token_index+=n\n",
        "\n",
        "len(token_representation), len(token_ewt_df[token_ewt_df['sentence_id'] == index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cXkrW4Txund"
      },
      "source": [
        "now let's write a function that can do the previous operation to the whole dataset.\n",
        "\n",
        "using a custom logic (for the subtokens joining) it is easier to keep the function not batched, even if it's not efficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOG36d6o3jBC"
      },
      "outputs": [],
      "source": [
        "def get_word_representation_df(model, tokenizer):\n",
        "  sentences = ewt_df['text'].to_list()\n",
        "  num_encoder_layers = model_b.config.encoder.num_hidden_layers+1 # considering also the embedding layer\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  word_representation_dict = {}\n",
        "  for e in range(num_encoder_layers):\n",
        "    word_representation_dict[f'encoder_layer_{e+1}'] = []\n",
        "\n",
        "  print('Starting to process sentences ...')\n",
        "  for sentence_idx, sentence in tqdm(enumerate(sentences), total=len(sentences), desc='Processing sentences to get word representation'):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(model.device)\n",
        "    start_token_id = tokenizer.bos_token_id\n",
        "    decoder_input_ids = torch.tensor([[start_token_id]], device=model.device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model_b(\n",
        "          **inputs,\n",
        "          decoder_input_ids=decoder_input_ids,\n",
        "          output_hidden_states=True,\n",
        "      )\n",
        "    encoder_hidden_states = torch.stack([e.cpu().squeeze(0) for e in outputs.encoder_hidden_states])\n",
        "\n",
        "    subtokens = get_subtokenization(sentence_idx, tokenizer)\n",
        "    for e in range(num_encoder_layers):\n",
        "        token_representation = word_representation_dict[f'encoder_layer_{e+1}']\n",
        "        ehs = encoder_hidden_states[e]\n",
        "        token_index = 0\n",
        "        for k,v in subtokens.items():\n",
        "          n = len(v)\n",
        "          if n>1:\n",
        "            mean_tensors_list = []\n",
        "            for i in range(n):\n",
        "              mean_tensors_list.append(ehs[token_index+i])\n",
        "            mean = torch.mean(torch.stack(mean_tensors_list), dim=0).to(torch.float32).numpy()\n",
        "            token_representation.append(mean)\n",
        "          else:\n",
        "            token_representation.append(ehs[token_index].to(torch.float32).numpy())\n",
        "          token_index+=n\n",
        "\n",
        "  token_representation_df =pd.DataFrame(word_representation_dict)\n",
        "  print('Sentence processed')\n",
        "  return token_representation_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15wnnA4TtRs-"
      },
      "outputs": [],
      "source": [
        "# new function, not batched\n",
        "\n",
        "def get_word_representation_df(model, tokenizer, df):\n",
        "    sentence_ids = df['sentence_id'].unique()\n",
        "    num_encoder_layers = model.config.encoder.num_hidden_layers + 1\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    word_representation_dict = {f'encoder_layer_{e+1}': [] for e in range(num_encoder_layers)}\n",
        "\n",
        "    for sent_id in tqdm(sentence_ids, desc='Processing sentences'):\n",
        "        words = df[df['sentence_id'] == sent_id]['words'].tolist()\n",
        "        inputs = tokenizer(words, return_tensors=\"pt\", is_split_into_words=True).to(model.device)\n",
        "        start_token_id = tokenizer.bos_token_id\n",
        "        decoder_input_ids = torch.tensor([[start_token_id]], device=model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                **inputs,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "                output_hidden_states=True\n",
        "            )\n",
        "\n",
        "        all_encoder_layers = torch.stack(outputs.encoder_hidden_states).squeeze(1)\n",
        "\n",
        "        word_ids = inputs.word_ids()\n",
        "\n",
        "        for word_idx in range(len(words)):\n",
        "            token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "\n",
        "            if not token_indices:\n",
        "                continue\n",
        "\n",
        "            relevant_vectors = all_encoder_layers[:, token_indices, :]\n",
        "            mean_vectors = torch.mean(relevant_vectors, dim=1)\n",
        "            mean_vectors_np = mean_vectors.cpu().to(torch.float32).numpy()\n",
        "\n",
        "            for layer_idx in range(num_encoder_layers):\n",
        "                word_representation_dict[f'encoder_layer_{layer_idx+1}'].append(mean_vectors_np[layer_idx])\n",
        "\n",
        "    first_key = list(word_representation_dict.keys())[0]\n",
        "    print(f\"Total words processed: {len(word_representation_dict[first_key])}\")\n",
        "\n",
        "    token_representation_df = pd.DataFrame(word_representation_dict)\n",
        "    return token_representation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznUQiL6zOdf"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVRDXJHQyDUc"
      },
      "outputs": [],
      "source": [
        "token_representation_ewt_df = get_word_representation_df(model_b, tokenizer_b)\n",
        "token_ewt_df = pd.concat([token_ewt_df, token_representation_ewt_df], axis=1)\n",
        "token_representation_ewt_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6ZvViST2lqR"
      },
      "outputs": [],
      "source": [
        "\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X_IWa5grjfQ"
      },
      "source": [
        "## MultiNLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt-BNFOPrkvG"
      },
      "outputs": [],
      "source": [
        "multinli_dataset = load_dataset(\"nyu-mll/multi_nli\") # one of ['train', 'validation_matched', 'validation_mismatched']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDKt17QttRs-"
      },
      "outputs": [],
      "source": [
        "multinli_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek8VE5z3tRs-"
      },
      "outputs": [],
      "source": [
        "multinli_df = multinli_dataset.to_pandas()\n",
        "multinli_df.drop(columns=['promptID', 'pairID', 'premise_binary_parse', 'premise_parse', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre'], inplace=True)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsNT_6ZtRs-"
      },
      "source": [
        "as shown by [Finetuned Language Models Are Zero-Shot Learners] the model give a better representation if natural language instruction are given\n",
        "\n",
        "that is why here we use the prompt: 'premise: \"{}\", hypothesis: \"{}\"' to get a single sentence, and then use the sentence extraction function as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4UA_ruvtRs-"
      },
      "outputs": [],
      "source": [
        "multinli_df['sentence'] = multinli_df.apply(lambda row: 'premise: \"{}\", hypothesis: \"{}\"'.format(row['premise'], row['hypothesis']), axis=1)\n",
        "multinli_df.drop(columns=['premise', 'hypothesis'], inplace=True)\n",
        "multinli_df = multinli_df[['sentence', 'label']]\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxthbkR3tRs_"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIafZWy-tRs_"
      },
      "outputs": [],
      "source": [
        "multinli_df = extract_activations_df(multinli_df, model_b, tokenizer_b, 'sentence', BATCH_SIZE=16)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ykdxjTrlYm"
      },
      "source": [
        "## ParaRel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic5Kh3dshrG"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/yanaiela/pararel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z46mi70tRs_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "objects_files = os.listdir('/content/pararel/data/trex_lms_vocab')\n",
        "relations_file = os.listdir('/content/pararel/data/pattern_data/graphs_json')\n",
        "\n",
        "# read the jsonl files in objects_files and create a dataframe for each file, then join them all into a single dataframe\n",
        "pararel_dfs = []\n",
        "for obj_file in relations_file:\n",
        "    obj_path = f'/content/pararel/data/trex_lms_vocab/{obj_file}'\n",
        "    obj_df = pd.read_json(obj_path, lines=True)\n",
        "\n",
        "    # read the relations file (same name as obj_file but different path) to get the relation name\n",
        "    relation_path = f'/content/pararel/data/pattern_data/graphs_json/{obj_file}'\n",
        "    with open(relation_path, 'r', encoding='utf-8') as f:\n",
        "        relation = json.loads(f.readline())['extended_lemma']\n",
        "\n",
        "    obj_df['relation'] = relation\n",
        "    pararel_dfs.append(obj_df)\n",
        "pararel_df = pd.concat(pararel_dfs, ignore_index=True)\n",
        "pararel_df.drop(columns=['uuid'], inplace=True)\n",
        "pararel_df.columns = ['first_entity', 'second_entity', 'relation']\n",
        "\n",
        "pararel_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxD1v1eKtRs_"
      },
      "outputs": [],
      "source": [
        "pararel_df['relation'].unique(), pararel_df['relation'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklURMe2tRs_"
      },
      "source": [
        "there are 38 relationships, we want to extract sentences in the form \"What {h1} is to {t1}, {h2} is to {t2}.\"\n",
        "- Random replacement (replace one of the second relation elements with something random)\n",
        "- Reverse direction (reverse the direction of a correct relation)\n",
        "- Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BSNuLeMtRs_"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"What {h1} is to {t1}, {h2} is to {t2}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4f4yn5vtRs_"
      },
      "outputs": [],
      "source": [
        "for i in pararel_df['relation'].unique():\n",
        "    sample = pararel_df[pararel_df['relation']==i].sample(1)\n",
        "    print(f'{sample[\"first_entity\"].values[0]} - {i} - {sample[\"second_entity\"].values[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9bKLNMbtRs_"
      },
      "outputs": [],
      "source": [
        "# ideally the dataset will be 6000 (correct) + 3 (random, reverse, type) * 2000 (wrong) = 12000 sentences\n",
        "total_dataset_len = 12000\n",
        "number_correct_relationships = total_dataset_len//2\n",
        "number_wrong_relationships = total_dataset_len//6\n",
        "\n",
        "number_relationships = pararel_df['relation'].nunique()\n",
        "relationships = pararel_df['relation'].unique()\n",
        "pararel_analogies_dict = {'sentences': [], 'type': []}\n",
        "\n",
        "# correct relationships\n",
        "for r in tqdm(relationships, desc='Extracting correct relationships'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(number_correct_relationships//number_relationships):\n",
        "        if len(rel_df) > 2:\n",
        "            sampled = rel_df.sample(n=2)\n",
        "            row1 = sampled.iloc[0]\n",
        "            row2 = sampled.iloc[1]\n",
        "            rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "            h1 = row1['first_entity']\n",
        "            t1 = row1['second_entity']\n",
        "            h2 = row2['first_entity']\n",
        "            t2 = row2['second_entity']\n",
        "            correct_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t2)\n",
        "            pararel_analogies_dict['sentences'].append(correct_sentence)\n",
        "            pararel_analogies_dict['type'].append(0) # 0 means correct relationship\n",
        "\n",
        "# random replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (random)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 3 and rel_df['first_entity'].nunique()>2 and rel_df['second_entity'].nunique()>2:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=3)\n",
        "\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "\n",
        "                if (h1!=h2 and h1!=h3 and t1!=t2 and t1!=t3 and t2!=t3):\n",
        "                    random_choice = np.random.randint(1,3)\n",
        "                    if random_choice == 1:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t3)\n",
        "                    else:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=t2)\n",
        "\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(1) # 0 means random replacement\n",
        "\n",
        "                    sampled_done = True\n",
        "\n",
        "# reverse replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (reversed)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 2 and rel_df['first_entity'].nunique()>1 and rel_df['second_entity'].nunique()>1:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=2)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                if (h1!=h2 and t1!=t2):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=t2, t2=h2)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(2) # 2 means reverse replacement\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "# type replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (type)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range((number_wrong_relationships//2)//number_relationships):\n",
        "        if len(rel_df) > 4 and rel_df['first_entity'].nunique()>3 and rel_df['second_entity'].nunique()>3:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=4)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "                row4 = sampled.iloc[3]\n",
        "\n",
        "                # correct\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                # to be replaced\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "                h4 = row4['first_entity']\n",
        "                t4 = row4['second_entity']\n",
        "\n",
        "                if (h1!=h3 and h1!=h4 and h2!=h3 and h2!=h4 and t1!=t3 and t1!=t4 and t2!=t3 and t2!=t4 and h3!=h4 and t3!=t4):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "                    random_replacement_sentence_1 = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=h4)\n",
        "                    random_replacement_sentence_2 = PROMPT.format(h1=h2, t1=t2, h2=t3, t2=t4)\n",
        "\n",
        "                    # first wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_1)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "\n",
        "                    # second wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_2)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "pararel_analogies_df = pd.DataFrame(pararel_analogies_dict)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx-4ftA4tRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df.head()['sentences'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybj7KczntRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df['label'] = pararel_analogies_df['type'].apply(lambda x: 1 if x == 0 else 0)\n",
        "pararel_analogies_df = pararel_analogies_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_LMOTzktRtA"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ1LbGEitRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_b, tokenizer_b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2YUuDZdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfkiIbpttRtA"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTo5yHPAtRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_2b, tokenizer_2b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUKE82pdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_2b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6a3H8citRtA"
      },
      "source": [
        "## Perturbations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV1boEqtRtA"
      },
      "source": [
        "here we consider the perturbations on the dataset\n",
        "\n",
        "we have to perturbe just the validation set, for being able to detect the model's strength\n",
        "\n",
        "we can use 2 different perturbation levels: semantic level and syntactic level\n",
        "- for semantic level we can use https://github.com/makcedward/nlpaug (sinonimi)\n",
        "- for syntactic level we can use again nlpaug\n",
        "\n",
        "https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
        "\n",
        "for datasets\n",
        "- true/false: both\n",
        "- CoLA: semantic (syntactic would change the label)\n",
        "- EWT: both\n",
        "- ParaRel: none\n",
        "- MultiNLI: both (with carefuleness about syntactic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq2ymKU_tRtA"
      },
      "source": [
        "# Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCjfsHlk0Pmp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOYYlmAszNzg"
      },
      "outputs": [],
      "source": [
        "class Probe(nn.Module):\n",
        "  def fit(self, train_loader, epochs=10, lr=0.001, device=None):\n",
        "    total_losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    criterion = nn.CrossEntropyLoss() # standard\n",
        "    optimizer = optim.Adam(self.parameters(), lr=lr) # to be defined with hyperparams\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      self.train()\n",
        "      total_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "      # Statistiche di fine epoca\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      acc = correct / total\n",
        "      total_losses.append(avg_loss)\n",
        "      accuracies.append(acc)\n",
        "      #print(f\"Epoca [{epoch+1}/{epochs}] \\t Loss: {avg_loss:.4f} \\t Acc: {acc:.4f}\")\n",
        "\n",
        "    return total_losses, accuracies\n",
        "\n",
        "  def evaluate(self, test_loader, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # torch.no_grad() risparmia memoria e calcoli perché non traccia i gradienti\n",
        "    with torch.no_grad():\n",
        "      for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        outputs = self(batch_x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "class NonLinearProbe(Probe): # architecture from CS2\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(NonLinearProbe, self).__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "class LinearProbe(Probe):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearProbe, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 256)\n",
        "    self.linear2 = nn.Linear(256,128)\n",
        "    self.linear3 = nn.Linear(128,64)\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.linear3(x)\n",
        "    x = self.out(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvgWaCJyRvin"
      },
      "outputs": [],
      "source": [
        "def iterate_training_layers(model_size, df, num_layers, encdec, probe, probe_args={}, split_index=75):\n",
        "  train_accuracy = []\n",
        "  test_accuracy = []\n",
        "\n",
        "  print(f'Training on model {model_size}, considering {encdec}')\n",
        "  for layer in trange(num_layers):\n",
        "    col_name = f'{encdec}_layer_{layer+1}'\n",
        "    num_train_instances = len(df) * split_index // 100\n",
        "    num_test_instances = len(df) - num_train_instances\n",
        "\n",
        "    # shuffle the df\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    train_df = df[:num_train_instances]\n",
        "    test_df = df[num_train_instances:]\n",
        "\n",
        "    X_train_tensor = torch.stack([torch.from_numpy(t) for t in train_df[col_name].tolist()])\n",
        "    y_train_tensor = torch.tensor(train_df['label'].tolist())\n",
        "\n",
        "    X_test_tensor = torch.stack([torch.from_numpy(t) for t in test_df[col_name].tolist()])\n",
        "    y_test_tensor = torch.tensor(test_df['label'].tolist())\n",
        "\n",
        "    # training of the probe\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "    if probe=='linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = LinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim)\n",
        "    elif probe == 'non_linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = NonLinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim, **probe_args)\n",
        "    else:\n",
        "      raise ValueError('Probe must be either linear or non_linear')\n",
        "\n",
        "    results = probe_instance.fit(train_loader, epochs=25, lr=0.001)\n",
        "    train_accuracy.append(results[1][-1])\n",
        "\n",
        "    # evaluating test accuracy\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "    test_acc = probe_instance.evaluate(test_loader)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n",
        "  return train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRHoApyrGUzO"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(train_accuracy, test_accuracy, model, probe, knowledge, encdec):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(train_accuracy, label='Train Accuracy')\n",
        "  plt.plot(test_accuracy, label='Test Accuracy')\n",
        "  plt.xlabel('Layer')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(f'{knowledge}, model {model}, linearity {probe}, encdec {encdec}')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGRKft-YUGP8"
      },
      "source": [
        "model b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Nrdisnnm0diE"
      },
      "outputs": [],
      "source": [
        "tf_b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-b-b-ul2'\n",
        "tf_b_df = pd.read_pickle(tf_b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SleK9ZLCUia_"
      },
      "outputs": [],
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : tf_b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'factual', 'encoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'non_linear', 'factual', 'decoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : tf_b_df,\n",
        "    'probe' : 'linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'linear', 'factual', 'decoder')\n"
      ],
      "metadata": {
        "id": "wik1m6FnjxiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89_0OnHUfPX"
      },
      "source": [
        "model 2b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkL8QH37MUVD"
      },
      "outputs": [],
      "source": [
        "tf_2b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-2b-2b-ul2'\n",
        "tf_2b_df = pd.read_pickle(tf_2b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXbhQ9XRU_SI"
      },
      "outputs": [],
      "source": [
        "config2b = {\n",
        "    'model_size' : '2b',\n",
        "    'df' : tf_2b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'non_linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'non_linear', 'factual', 'decoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config2b = {\n",
        "    'model_size' : '2b',\n",
        "    'df' : tf_2b_df,\n",
        "    'probe' : 'linear',\n",
        "    'num_layers' :27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'linear', 'factual', 'decoder')\n"
      ],
      "metadata": {
        "id": "5mCSPkVtlhad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "linguistic knowledge"
      ],
      "metadata": {
        "id": "FJ0rlNIylpae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cola_b_path = '/content/drive/MyDrive/DTCS_datasets/cola_t5gemma-b-b-ul2'\n",
        "cola_b_df = pd.read_pickle(cola_b_path)"
      ],
      "metadata": {
        "id": "MUu4AeBblyqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cola_b_df"
      ],
      "metadata": {
        "id": "pRYVnVSPookb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : cola_b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'linguistic (cola)', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'non_linear', 'linguistic (cola)', 'decoder')\n"
      ],
      "metadata": {
        "id": "qWE_2HaFmg6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAxDfYXOqZIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cola_2b_path = '/content/drive/MyDrive/DTCS_datasets/cola_t5gemma-2b-2b-ul2'\n",
        "cola_2b_df = pd.read_pickle(cola_b_path)"
      ],
      "metadata": {
        "id": "NiunZRGmqa_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_b_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nC9hQUPCrJf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cola_2b_df"
      ],
      "metadata": {
        "id": "H_4HH6D4qnO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config2b = {\n",
        "    'model_size':'2b',\n",
        "    'df':cola_2b_df,\n",
        "    'probe':'non_linear',\n",
        "    'num_layers':27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'non_linear', 'linguistic (cola)', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'non_linear', 'linguistic (cola)', 'decoder')\n"
      ],
      "metadata": {
        "id": "w6XDRgN_qa_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6f13314bf0449469b7e1996060c7d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa177172de1d488183e6f21f0b01ff8e",
              "IPY_MODEL_153dcb12d56d4f6da2fe63bf9fce22ad",
              "IPY_MODEL_c3f3de9a164847b197faab0d3a583184"
            ],
            "layout": "IPY_MODEL_1ac5aa5c9f01411a99be47dcbcd7cb34"
          }
        },
        "fa177172de1d488183e6f21f0b01ff8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cdfb2448cb244af9d72da08b08d1891",
            "placeholder": "​",
            "style": "IPY_MODEL_6edbd4139fd247389aa4b324a74de9b7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "153dcb12d56d4f6da2fe63bf9fce22ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4def312ba8c4846b2519ad5cc9e8b6d",
            "max": 46437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1ebdbecdb64454b168df599433d331",
            "value": 46437
          }
        },
        "c3f3de9a164847b197faab0d3a583184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a7f92eaf5254eed9a8a88620130d0b1",
            "placeholder": "​",
            "style": "IPY_MODEL_423dfb6ace734448a7079995e932099c",
            "value": " 46.4k/46.4k [00:00&lt;00:00, 2.32MB/s]"
          }
        },
        "1ac5aa5c9f01411a99be47dcbcd7cb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdfb2448cb244af9d72da08b08d1891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edbd4139fd247389aa4b324a74de9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4def312ba8c4846b2519ad5cc9e8b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1ebdbecdb64454b168df599433d331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a7f92eaf5254eed9a8a88620130d0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423dfb6ace734448a7079995e932099c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70cd570d93234718b33ba62874c89ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b74451c79c5d4077a5d46bceced2c2c3",
              "IPY_MODEL_459f02f97d1448fca73f154cf104cf9a",
              "IPY_MODEL_25ef3b807e504c89ba7d8688d524cff2"
            ],
            "layout": "IPY_MODEL_03267f7b86a44f43bdb8b0973a0e277a"
          }
        },
        "b74451c79c5d4077a5d46bceced2c2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd6e0099cf6402b87e19648ebed90bc",
            "placeholder": "​",
            "style": "IPY_MODEL_4e81ed00b3da4e2e8eb014106ca7375e",
            "value": "tokenizer.model: 100%"
          }
        },
        "459f02f97d1448fca73f154cf104cf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743a252ea0a1414e9dfe6e6b3500b5f0",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51175298c9274784a8c7be337caeeb05",
            "value": 4241003
          }
        },
        "25ef3b807e504c89ba7d8688d524cff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2cae40c40d40cba5cb43e5d458daaf",
            "placeholder": "​",
            "style": "IPY_MODEL_cad80c8296b2429f93c3fa3d6a6cbd49",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "03267f7b86a44f43bdb8b0973a0e277a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd6e0099cf6402b87e19648ebed90bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e81ed00b3da4e2e8eb014106ca7375e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "743a252ea0a1414e9dfe6e6b3500b5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51175298c9274784a8c7be337caeeb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b2cae40c40d40cba5cb43e5d458daaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad80c8296b2429f93c3fa3d6a6cbd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f967b49e764641ddb8fe749a8186eda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dda84cabc33c40059ea68037990ffd85",
              "IPY_MODEL_38e9d2ec592f46c9a4798ab3d2d6d482",
              "IPY_MODEL_5e174a57179343408c1bda53de71d2fa"
            ],
            "layout": "IPY_MODEL_108dbc1cc5e7492ca36f3337b8a8ed4f"
          }
        },
        "dda84cabc33c40059ea68037990ffd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412edab557744dbbacc5445d0bb4566f",
            "placeholder": "​",
            "style": "IPY_MODEL_12a4adda8c414bf591b86c1246461a13",
            "value": "tokenizer.json: 100%"
          }
        },
        "38e9d2ec592f46c9a4798ab3d2d6d482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aebbfb7359b4c7c99b37d449e5b41b1",
            "max": 34362429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ef3bb4a8a2a404bb072611eb9b14d1a",
            "value": 34362429
          }
        },
        "5e174a57179343408c1bda53de71d2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_789e0b087e864fb28773e3c9af30bdd0",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d17d0fd4e74905954c4cd978a95886",
            "value": " 34.4M/34.4M [00:00&lt;00:00, 70.0MB/s]"
          }
        },
        "108dbc1cc5e7492ca36f3337b8a8ed4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412edab557744dbbacc5445d0bb4566f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a4adda8c414bf591b86c1246461a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aebbfb7359b4c7c99b37d449e5b41b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef3bb4a8a2a404bb072611eb9b14d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "789e0b087e864fb28773e3c9af30bdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d17d0fd4e74905954c4cd978a95886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507f686b4c3040a78cd4b413b14b08c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bff715282e5444e3b0528f94bd479c72",
              "IPY_MODEL_7a46d00698814b43a2b2dc4102c7404f",
              "IPY_MODEL_c9658fbd80d041ddbe9c820b036434e8"
            ],
            "layout": "IPY_MODEL_2af94c4c97eb4656b3a1bf7d5424ed68"
          }
        },
        "bff715282e5444e3b0528f94bd479c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d63de812a543b0a20e0f7cd5b5d11b",
            "placeholder": "​",
            "style": "IPY_MODEL_4d919fd581d3471cbf9962e62194af35",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "7a46d00698814b43a2b2dc4102c7404f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1601e5e256a643b7976e1b7c84278bad",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ddd6263e93340cb8a0a5f2c106b9aba",
            "value": 636
          }
        },
        "c9658fbd80d041ddbe9c820b036434e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ae55d10040422ab283444e44633c9e",
            "placeholder": "​",
            "style": "IPY_MODEL_149c824d03a947559b14dbeeb199849b",
            "value": " 636/636 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "2af94c4c97eb4656b3a1bf7d5424ed68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d63de812a543b0a20e0f7cd5b5d11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d919fd581d3471cbf9962e62194af35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1601e5e256a643b7976e1b7c84278bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddd6263e93340cb8a0a5f2c106b9aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33ae55d10040422ab283444e44633c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149c824d03a947559b14dbeeb199849b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3081a793472d46f1912fd7f3f8c21414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0af102b0cb4b437f80f3b670dfba6bec",
              "IPY_MODEL_d5524d4496644ccaacda9da98d8b1a80",
              "IPY_MODEL_bb34fe96634a41c8acb290be5941e75c"
            ],
            "layout": "IPY_MODEL_7f0c256e59c64e388880b2e5ed4f19f5"
          }
        },
        "0af102b0cb4b437f80f3b670dfba6bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6bf9039ce644ff7b313e3a14f5eefd2",
            "placeholder": "​",
            "style": "IPY_MODEL_c17f954288954960bf5ce615504de4c5",
            "value": "config.json: 100%"
          }
        },
        "d5524d4496644ccaacda9da98d8b1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf274fff773e44188e3b2036cc44eba2",
            "max": 2540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76b00bec3f6c41438e548487600736f3",
            "value": 2540
          }
        },
        "bb34fe96634a41c8acb290be5941e75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_149df6d179fb402ebd1c7690f8c52b13",
            "placeholder": "​",
            "style": "IPY_MODEL_68f01f05fd204671b6495d0eb34991c4",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 80.6kB/s]"
          }
        },
        "7f0c256e59c64e388880b2e5ed4f19f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bf9039ce644ff7b313e3a14f5eefd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17f954288954960bf5ce615504de4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf274fff773e44188e3b2036cc44eba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b00bec3f6c41438e548487600736f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "149df6d179fb402ebd1c7690f8c52b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f01f05fd204671b6495d0eb34991c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2493a8500c96450e84e42d91fb42f71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c7235f082f547f3ace1b40d02391401",
              "IPY_MODEL_695b0258b96c410f9f2e2bfa22d9636d",
              "IPY_MODEL_6cf87eb4eff44c858ca88fd60af538c3"
            ],
            "layout": "IPY_MODEL_8b56460dbdf04fe7a84fb432f0f432dc"
          }
        },
        "9c7235f082f547f3ace1b40d02391401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e3770234f144a48dbc8ad65f71b87e",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa19f07fb034730a5d8460a4ec227fe",
            "value": "model.safetensors: 100%"
          }
        },
        "695b0258b96c410f9f2e2bfa22d9636d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5b4562b2464c1e8b84fd132727fba2",
            "max": 1183022944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a3f48027484e608d522be8f036bd30",
            "value": 1183022944
          }
        },
        "6cf87eb4eff44c858ca88fd60af538c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3296cccfd4c4c14a3bbd631b16da6bb",
            "placeholder": "​",
            "style": "IPY_MODEL_bb238ee2614244838ae4c2dd1e5dc65e",
            "value": " 1.18G/1.18G [00:14&lt;00:00, 71.7MB/s]"
          }
        },
        "8b56460dbdf04fe7a84fb432f0f432dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e3770234f144a48dbc8ad65f71b87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa19f07fb034730a5d8460a4ec227fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e5b4562b2464c1e8b84fd132727fba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a3f48027484e608d522be8f036bd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3296cccfd4c4c14a3bbd631b16da6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb238ee2614244838ae4c2dd1e5dc65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "266c84ed137a440498b9f43c8b46677c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8060597b43624bb6a145cb3aa9ab526a",
              "IPY_MODEL_6d962e8ee34145d686832dd84018a53b",
              "IPY_MODEL_58ed648c11014250b444cedbef908786"
            ],
            "layout": "IPY_MODEL_ec336b1d704e49cd87d5653e83762427"
          }
        },
        "8060597b43624bb6a145cb3aa9ab526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6619604fac949f5bc8d3a17b5067252",
            "placeholder": "​",
            "style": "IPY_MODEL_c6a2856de55742a4801edd26a3279988",
            "value": "generation_config.json: 100%"
          }
        },
        "6d962e8ee34145d686832dd84018a53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ad7abf8f5d47c3a3ffd3d3fd722294",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_973a629692544d3f8234b1b18e9588e3",
            "value": 156
          }
        },
        "58ed648c11014250b444cedbef908786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96171b33cd5d4874ba5ac251fce048ef",
            "placeholder": "​",
            "style": "IPY_MODEL_43d1c4a9e621441c93ad95bae7662a68",
            "value": " 156/156 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "ec336b1d704e49cd87d5653e83762427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6619604fac949f5bc8d3a17b5067252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a2856de55742a4801edd26a3279988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ad7abf8f5d47c3a3ffd3d3fd722294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "973a629692544d3f8234b1b18e9588e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96171b33cd5d4874ba5ac251fce048ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d1c4a9e621441c93ad95bae7662a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}