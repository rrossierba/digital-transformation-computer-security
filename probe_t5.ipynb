{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9L0bmfKk_Q-"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLAmVjLTRYW5"
      },
      "source": [
        "preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hCfcLCIRRcMR"
      },
      "outputs": [],
      "source": [
        "import torch, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hzupOBSRon7",
        "outputId": "9cccbf70-d42a-4975-f33b-e4780c4d8b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00xoYkRWReqW"
      },
      "source": [
        "download tokenizer and model from hf\n",
        "\n",
        "note: do not download and run both models at the same time, colab has some limitation and it is not guaranteed to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P-W51utcr27g"
      },
      "outputs": [],
      "source": [
        "# login with hf\n",
        "from huggingface_hub import login\n",
        "token = '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'\n",
        "login(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "6hkR4lH07r2Y",
        "outputId": "423cb6d5-cfb4-4bc8-b62b-d476ac62811e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_id_b=f'google/t5gemma-b-b-ul2'\n",
        "tokenizer_b = AutoTokenizer.from_pretrained(model_id_b)\n",
        "model_b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xh4CfPuSlp2_"
      },
      "outputs": [],
      "source": [
        "model_id_2b=f'google/t5gemma-2b-2b-ul2'\n",
        "tokenizer_2b = AutoTokenizer.from_pretrained(model_id_2b)\n",
        "model_2b = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id_2b,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhoYbqZOVMH8"
      },
      "source": [
        "## extracting the activations from the model\n",
        "\n",
        "We use mean pooling to obtain vector representations of sentences because SentenceBERT has shown that it works better than the CLS token. In our case, there is no CLS token, so this was not even an option. SentenceT5 has confirmed that mean pooling is the strategy that yields the best results for T5-based models when it is necessary to extract the sentence representation.\n",
        "\n",
        "So we use this strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kl49XaoSp7Et"
      },
      "outputs": [],
      "source": [
        "# batched function\n",
        "def extract_activations_df(base_df, model, tokenizer, text_column, BATCH_SIZE=1):\n",
        "  df = base_df.copy()\n",
        "  enc_results = {}\n",
        "  dec_results = {}\n",
        "\n",
        "  # mean pooling considering padding and using attention mask to set to 0 pad token representations\n",
        "  def masked_mean_pooling(hidden_states, attention_mask):\n",
        "      mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "      masked_embeddings = hidden_states * mask_expanded\n",
        "      summed = torch.sum(masked_embeddings, dim=1)\n",
        "      count = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
        "      return summed / count\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_rows = len(df)\n",
        "\n",
        "  print(f\"Start processing {total_rows} sentences...\")\n",
        "\n",
        "  for i in tqdm(range(0, total_rows, BATCH_SIZE)):\n",
        "      batch_texts = df[text_column][i : i + BATCH_SIZE].tolist()\n",
        "      inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "      current_batch_len = inputs.input_ids.shape[0]\n",
        "      start_token_id = tokenizer.bos_token_id\n",
        "      decoder_input_ids = torch.full((current_batch_len, 1), start_token_id, device=model.device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(\n",
        "              **inputs,\n",
        "              decoder_input_ids=decoder_input_ids,\n",
        "              output_hidden_states=True,\n",
        "          )\n",
        "\n",
        "      # encoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      attention_mask = inputs.attention_mask.cpu()\n",
        "      batch_encoder_states = torch.stack([\n",
        "          masked_mean_pooling(e.cpu(), attention_mask)\n",
        "          for e in outputs.encoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float16).numpy()\n",
        "\n",
        "      # decoder extraction: final shape[Batch, Num_Layers, Hidden_Dim]\n",
        "      batch_decoder_states = torch.stack([\n",
        "          o.cpu().squeeze(1) for o in outputs.decoder_hidden_states\n",
        "      ], dim=1).cpu().to(torch.float16).numpy()\n",
        "\n",
        "      num_enc_layers = batch_encoder_states.shape[1]\n",
        "      num_dec_layers = batch_decoder_states.shape[1]\n",
        "\n",
        "      # saving the activation results into the dictionaries\n",
        "      for layer_idx in range(num_enc_layers):\n",
        "          col_name = f'encoder_layer_{layer_idx+1}'\n",
        "          if col_name not in enc_results: enc_results[col_name] = []\n",
        "          vectors = list(batch_encoder_states[:, layer_idx, :])\n",
        "          enc_results[col_name].extend(vectors)\n",
        "\n",
        "      for layer_idx in range(num_dec_layers):\n",
        "          col_name = f'decoder_layer_{layer_idx+1}'\n",
        "          if col_name not in dec_results: dec_results[col_name] = []\n",
        "\n",
        "          vectors = list(batch_decoder_states[:, layer_idx, :])\n",
        "          dec_results[col_name].extend(vectors)\n",
        "\n",
        "  print(\"Saving in the DataFrame...\")\n",
        "  for col_name, vectors in enc_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  for col_name, vectors in dec_results.items():\n",
        "      df[col_name] = vectors\n",
        "\n",
        "  print(\"Done! Columns added\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I2uhxtHZjvPk"
      },
      "outputs": [],
      "source": [
        "def save_activations_df(df, dataset_name, model_id):\n",
        "  path = f'/content/drive/MyDrive/DTCS_datasets/{dataset_name}_{model_id.split('/')[1]}.pkl'\n",
        "  print(f'Saving {dataset_name}_{model_id.split('/')[1]} to GDrive...')\n",
        "  df.to_pickle(path)\n",
        "  print(f'Saved {dataset_name}_{model_id.split(\"/\")[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24jJOMSUTPI5"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mV-dGDMfz0x"
      },
      "source": [
        "## True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "KdjyO6T2T9cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e380374c-2fe9-4f1d-fa01-d273baf3cd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 69243  100 69243    0     0   213k      0 --:--:-- --:--:-- --:--:--  213k\n",
            "Archive:  true-false-dataset.zip\n",
            "  inflating: true-false-dataset/publicDataset/animals_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/cities_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/companies_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/elements_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/facts_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/generated_true_false.csv  \n",
            "  inflating: true-false-dataset/publicDataset/inventions_true_false.csv  \n"
          ]
        }
      ],
      "source": [
        "!curl azariaa.com/Content/Datasets/true-false-dataset.zip > true-false-dataset.zip\n",
        "!unzip \"true-false-dataset.zip\" -d \"true-false-dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "qwY3ruMm7wKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8c56baf9-8086-458c-b0db-1d47d1768b81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              statement  label        area\n",
              "0     Boron is used in the production of glass and c...      1    elements\n",
              "1     Praseodymium is used in coins, batteries, and ...      0    elements\n",
              "2     Cobalt is used in strong, permanent magnets an...      1    elements\n",
              "3                    Indium is in the Lanthanide group.      0    elements\n",
              "4                 Zirconium has the atomic number of 6.      0    elements\n",
              "...                                                 ...    ...         ...\n",
              "6325  Chester Carlson invented the programming langu...      0  inventions\n",
              "6326  Willem Einthoven invented the electrocardiogra...      1  inventions\n",
              "6327              George Antheil invented the Band-Aid.      0  inventions\n",
              "6328             John Shepherd-Barron invented the ATM.      1  inventions\n",
              "6329                 Linus Torvalds lived in Stephanie.      0  inventions\n",
              "\n",
              "[6330 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Boron is used in the production of glass and c...</td>\n",
              "      <td>1</td>\n",
              "      <td>elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Praseodymium is used in coins, batteries, and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cobalt is used in strong, permanent magnets an...</td>\n",
              "      <td>1</td>\n",
              "      <td>elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Indium is in the Lanthanide group.</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zirconium has the atomic number of 6.</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6325</th>\n",
              "      <td>Chester Carlson invented the programming langu...</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>Willem Einthoven invented the electrocardiogra...</td>\n",
              "      <td>1</td>\n",
              "      <td>inventions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6327</th>\n",
              "      <td>George Antheil invented the Band-Aid.</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6328</th>\n",
              "      <td>John Shepherd-Barron invented the ATM.</td>\n",
              "      <td>1</td>\n",
              "      <td>inventions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>Linus Torvalds lived in Stephanie.</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6330 rows × 3 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tf_df",
              "summary": "{\n  \"name\": \"tf_df\",\n  \"rows\": 6330,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6309,\n        \"samples\": [\n          \"Human uses for flamingo include tourism, research, zoos.\",\n          \"Taipei is a city in Taiwan\",\n          \"Silver is in the Post-transition metal group.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"inventions\",\n          \"animals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# create a dataframe from the csv files\n",
        "dir_path = '/content/true-false-dataset/publicDataset'\n",
        "datasets_names = os.listdir(dir_path)\n",
        "dfs = []\n",
        "\n",
        "for dataset_name in datasets_names:\n",
        "  path = f'{dir_path}/{dataset_name}'\n",
        "  df = pd.read_csv(path)\n",
        "  df.insert(loc=2, column='area', value=dataset_name.replace('_true_false.csv',''), allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "tf_df = pd.concat(dfs, ignore_index=True)\n",
        "tf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWyQ_2Al3qT"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "uU1emOEbfGpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "231986b0-2a23-4d39-b3b8-b624436d3512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing 6330 sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 50/50 [00:23<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              statement  label        area  \\\n",
              "0     Boron is used in the production of glass and c...      1    elements   \n",
              "1     Praseodymium is used in coins, batteries, and ...      0    elements   \n",
              "2     Cobalt is used in strong, permanent magnets an...      1    elements   \n",
              "3                    Indium is in the Lanthanide group.      0    elements   \n",
              "4                 Zirconium has the atomic number of 6.      0    elements   \n",
              "...                                                 ...    ...         ...   \n",
              "6325  Chester Carlson invented the programming langu...      0  inventions   \n",
              "6326  Willem Einthoven invented the electrocardiogra...      1  inventions   \n",
              "6327              George Antheil invented the Band-Aid.      0  inventions   \n",
              "6328             John Shepherd-Barron invented the ATM.      1  inventions   \n",
              "6329                 Linus Torvalds lived in Stephanie.      0  inventions   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [1.594, -0.3232, 0.01913, 0.3162, -0.33, -1.27...   \n",
              "1     [2.867, -0.0632, 0.454, 0.3157, -0.306, -1.255...   \n",
              "2     [1.794, -0.3086, 0.2605, 0.004673, -0.1708, -1...   \n",
              "3     [1.759, -0.2483, -0.221, 0.4106, -0.3943, -0.7...   \n",
              "4     [2.336, -0.4631, 0.3208, 0.4666, -0.545, -1.10...   \n",
              "...                                                 ...   \n",
              "6325  [2.58, 0.01671, 0.11273, 0.4978, -0.2035, -0.5...   \n",
              "6326  [3.242, -0.4565, 0.1081, -0.1288, -0.1626, 0.2...   \n",
              "6327  [2.555, -0.417, -0.0806, 0.3462, 0.291, -0.673...   \n",
              "6328  [2.031, 0.2261, -0.3557, 0.3281, 0.03876, -1.2...   \n",
              "6329  [2.2, -0.2394, -0.6465, 0.7607, -0.1346, -0.64...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [-0.175, 0.2245, -0.195, -0.4348, -0.5117, 0.0...   \n",
              "1     [0.3206, 0.2805, 0.2157, -0.2847, -0.6133, 0.1...   \n",
              "2     [0.289, 0.0877, 0.05545, -0.5386, -0.4893, 0.2...   \n",
              "3     [-0.04474, 0.498, 0.07385, -0.3625, -0.3167, 0...   \n",
              "4     [0.001269, 0.2698, 0.03085, -0.226, -0.467, 0....   \n",
              "...                                                 ...   \n",
              "6325  [-0.03308, 0.2014, -0.1584, 0.255, -0.2551, 0....   \n",
              "6326  [-0.1495, 0.04892, 0.0594, -0.353, -0.2162, 0....   \n",
              "6327  [-0.32, 0.222, -0.0218, 0.12134, 0.4294, 0.471...   \n",
              "6328  [-0.2783, 0.8823, -0.3345, -0.2235, 0.2595, 0....   \n",
              "6329  [0.11206, 0.2444, -0.814, 0.0599, -0.3281, 0.4...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [-0.151, 0.2274, 0.3025, -0.1472, -0.0689, -0....   \n",
              "1     [0.007187, 0.2308, 0.4438, -0.2084, -0.2263, 0...   \n",
              "2     [0.1296, 0.0861, 0.3347, -0.2142, 0.00715, 0.2...   \n",
              "3     [-0.1902, 0.2515, 0.6636, -0.34, -0.3474, 0.15...   \n",
              "4     [-0.1399, 0.01933, 0.2783, -0.2058, -0.07794, ...   \n",
              "...                                                 ...   \n",
              "6325  [-0.04428, 0.1489, 0.1675, 0.3193, 0.0851, -0....   \n",
              "6326  [-0.1653, 0.2494, 0.463, -0.1686, -0.0418, 0.1...   \n",
              "6327  [-0.47, -0.02766, 0.6523, 0.1521, 0.731, 0.223...   \n",
              "6328  [-0.2986, 0.616, 0.3828, -0.1313, 0.315, 0.098...   \n",
              "6329  [0.11664, 0.3613, -0.3467, -0.001356, -0.23, 0...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.1584, 0.2742, 0.0692, -0.1511, -0.0811, -0...   \n",
              "1     [0.0937, 0.1138, 0.1555, -0.1403, -0.172, 0.10...   \n",
              "2     [0.2142, 0.11633, 0.3093, -0.2554, 0.0714, -0....   \n",
              "3     [-0.0616, 0.2954, 0.639, -0.099, -0.3667, -0.2...   \n",
              "4     [-0.2311, 0.04462, 0.296, -0.2742, -0.198, -0....   \n",
              "...                                                 ...   \n",
              "6325  [-0.11884, 0.03021, -0.1176, 0.1764, 0.1278, -...   \n",
              "6326  [0.1722, 0.04132, 0.1676, -0.2452, 0.2311, 0.0...   \n",
              "6327  [-0.2058, -0.02312, 0.3525, 0.1844, 0.749, 0.1...   \n",
              "6328  [-0.2969, 0.584, -0.01855, 0.004776, 0.3594, -...   \n",
              "6329  [0.4663, 0.1903, -0.6426, -0.1427, 0.01139, 0....   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.1062, 0.2397, 0.02325, -0.1812, 0.269, -0....   \n",
              "1     [-0.1437, 0.231, -0.02036, -0.1841, -0.02399, ...   \n",
              "2     [0.4866, 0.2316, 0.1227, -0.1515, 0.129, -0.03...   \n",
              "3     [0.1963, 0.584, -0.1418, 0.0385, -0.2247, 0.22...   \n",
              "4     [0.1637, 0.2998, 0.1648, 0.09656, 0.05118, 0.1...   \n",
              "...                                                 ...   \n",
              "6325  [0.1963, 0.002495, -0.6924, 0.0436, 0.388, 0.1...   \n",
              "6326  [0.352, 0.2103, 0.1882, -0.3093, 0.458, 0.2786...   \n",
              "6327  [0.2231, -0.03552, 0.2532, 0.0014105, 1.051, 0...   \n",
              "6328  [-0.1214, 0.502, -0.0816, -0.02214, 0.7383, 0....   \n",
              "6329  [0.6636, 0.3298, -0.4436, -0.125, 0.568, 0.275...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [-0.09985, -0.672, 0.06836, -0.2615, -0.05087,...   \n",
              "1     [-0.00354, -0.3713, 0.2361, -0.2153, -0.09064,...   \n",
              "2     [0.3452, -0.2578, 0.28, -0.1854, 0.01409, 0.19...   \n",
              "3     [0.2053, -0.03604, -0.01566, -0.1418, -0.1836,...   \n",
              "4     [0.1797, -0.1589, 0.11523, 0.3179, 0.3647, -0....   \n",
              "...                                                 ...   \n",
              "6325  [-0.07007, -0.4854, -0.0738, -0.0862, -0.02051...   \n",
              "6326  [0.1779, -0.4126, 0.7236, -0.313, 0.2185, -0.1...   \n",
              "6327  [0.0639, -0.395, 0.548, 0.2106, 0.4834, 0.0176...   \n",
              "6328  [-0.2341, -0.08813, 0.3096, -0.11707, 0.1936, ...   \n",
              "6329  [0.2886, -0.0642, -0.1214, -0.3086, 0.09735, 0...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.2229, -0.7314, -0.4043, 0.009766, -0.1787, ...  ...   \n",
              "1     [0.4646, -0.4312, -0.3813, -0.1802, -0.0902, -...  ...   \n",
              "2     [0.737, -0.359, 0.04645, -0.1427, -0.0757, 0.0...  ...   \n",
              "3     [0.957, 0.1431, 0.1304, -0.2057, -0.6045, -0.1...  ...   \n",
              "4     [0.747, -0.5015, -0.5903, -0.0797, 0.0863, -0....  ...   \n",
              "...                                                 ...  ...   \n",
              "6325  [-0.0433, -0.4849, 0.05524, -0.0689, -0.2878, ...  ...   \n",
              "6326  [0.817, -0.1066, 0.1848, -0.1472, -0.2566, -0....  ...   \n",
              "6327  [0.4653, -0.3438, -0.1183, 0.2742, 0.006077, 0...  ...   \n",
              "6328  [0.03516, 0.0, 0.02605, -0.2378, -0.171, -0.06...  ...   \n",
              "6329  [0.325, 0.6313, -0.204, -0.6123, -0.07574, 0.9...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.504, 0.414, 0.3086, 0.5156, -0.455, -0.059...   \n",
              "1     [-0.4844, 0.4238, 0.3066, 0.5195, -0.4531, -0....   \n",
              "2     [-0.4883, 0.42, 0.293, 0.5195, -0.4512, -0.068...   \n",
              "3     [-0.5156, 0.4277, 0.3086, 0.5, -0.4668, -0.065...   \n",
              "4     [-0.508, 0.4297, 0.33, 0.535, -0.4375, -0.0507...   \n",
              "...                                                 ...   \n",
              "6325  [-0.4844, 0.3926, 0.3008, 0.5, -0.4219, -0.059...   \n",
              "6326  [-0.508, 0.4004, 0.3086, 0.508, -0.4434, -0.04...   \n",
              "6327  [-0.5195, 0.3945, 0.3242, 0.5195, -0.4102, -0....   \n",
              "6328  [-0.5, 0.3828, 0.3027, 0.5195, -0.4219, -0.047...   \n",
              "6329  [-0.498, 0.4238, 0.3281, 0.5273, -0.4238, -0.0...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.9375, 0.547, -0.0654, 0.793, -0.914, -0.45...   \n",
              "1     [-0.914, 0.5547, -0.05664, 0.797, -0.9297, -0....   \n",
              "2     [-0.9297, 0.547, -0.07764, 0.797, -0.9297, -0....   \n",
              "3     [-0.961, 0.547, -0.05786, 0.7734, -0.9414, -0....   \n",
              "4     [-0.9375, 0.5586, -0.03076, 0.8125, -0.9062, -...   \n",
              "...                                                 ...   \n",
              "6325  [-0.957, 0.5, -0.0698, 0.7812, -0.8867, -0.474...   \n",
              "6326  [-0.957, 0.508, -0.0698, 0.797, -0.9062, -0.46...   \n",
              "6327  [-0.9727, 0.508, -0.0464, 0.801, -0.871, -0.48...   \n",
              "6328  [-0.9766, 0.4922, -0.06055, 0.797, -0.875, -0....   \n",
              "6329  [-0.965, 0.5273, -0.02551, 0.8086, -0.871, -0....   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.258, 0.0515, 0.166, 0.5938, -1.617, -0.066...   \n",
              "1     [-1.242, 0.063, 0.1787, 0.6055, -1.617, -0.027...   \n",
              "2     [-1.25, 0.04663, 0.1592, 0.5977, -1.617, -0.06...   \n",
              "3     [-1.273, 0.0476, 0.168, 0.578, -1.609, -0.0781...   \n",
              "4     [-1.25, 0.05078, 0.2002, 0.6094, -1.586, -0.07...   \n",
              "...                                                 ...   \n",
              "6325  [-1.305, -0.001709, 0.169, 0.586, -1.586, -0.0...   \n",
              "6326  [-1.297, -0.00903, 0.1514, 0.59, -1.594, -0.07...   \n",
              "6327  [-1.3125, 0.008545, 0.1973, 0.6016, -1.555, -0...   \n",
              "6328  [-1.328, -0.0105, 0.1865, 0.6094, -1.5625, -0....   \n",
              "6329  [-1.305, 0.0359, 0.2119, 0.6133, -1.5625, -0.1...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.203, 0.5625, -0.1904, 0.793, -1.531, -0.39...   \n",
              "1     [-1.1875, 0.578, -0.1758, 0.801, -1.531, -0.35...   \n",
              "2     [-1.195, 0.5586, -0.1992, 0.797, -1.531, -0.39...   \n",
              "3     [-1.227, 0.5625, -0.1836, 0.7734, -1.523, -0.4...   \n",
              "4     [-1.195, 0.5703, -0.1504, 0.8047, -1.5, -0.398...   \n",
              "...                                                 ...   \n",
              "6325  [-1.25, 0.5156, -0.1777, 0.7773, -1.508, -0.42...   \n",
              "6326  [-1.25, 0.504, -0.1992, 0.785, -1.508, -0.4062...   \n",
              "6327  [-1.273, 0.5273, -0.1562, 0.793, -1.469, -0.42...   \n",
              "6328  [-1.273, 0.508, -0.165, 0.801, -1.477, -0.414,...   \n",
              "6329  [-1.266, 0.5547, -0.12305, 0.8086, -1.477, -0....   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [0.04883, 0.10156, 0.04688, 0.8555, -1.625, -0...   \n",
              "1     [0.06445, 0.1133, 0.05664, 0.871, -1.641, 0.00...   \n",
              "2     [0.04883, 0.1006, 0.03125, 0.8633, -1.641, -0....   \n",
              "3     [0.03125, 0.08984, 0.04102, 0.8477, -1.625, -0...   \n",
              "4     [0.05078, 0.0918, 0.0586, 0.875, -1.586, -0.02...   \n",
              "...                                                 ...   \n",
              "6325  [0.001953, 0.05664, 0.03906, 0.8477, -1.617, -...   \n",
              "6326  [0.001953, 0.03516, 0.01953, 0.8555, -1.609, -...   \n",
              "6327  [-0.01172, 0.06836, 0.05273, 0.867, -1.586, -0...   \n",
              "6328  [-0.02539, 0.03613, 0.0547, 0.867, -1.586, -0....   \n",
              "6329  [-0.01953, 0.10156, 0.0586, 0.867, -1.578, -0....   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.0918, -0.1426, -0.418, 1.07, -1.914, 0.212...   \n",
              "1     [-0.0884, -0.1206, -0.4062, 1.086, -1.93, 0.24...   \n",
              "2     [-0.1035, -0.1416, -0.4258, 1.078, -1.914, 0.2...   \n",
              "3     [-0.1357, -0.1377, -0.4219, 1.0625, -1.914, 0....   \n",
              "4     [-0.0962, -0.1367, -0.3926, 1.078, -1.867, 0.2...   \n",
              "...                                                 ...   \n",
              "6325  [-0.1533, -0.168, -0.4336, 1.07, -1.898, 0.193...   \n",
              "6326  [-0.1592, -0.1855, -0.4492, 1.078, -1.914, 0.2...   \n",
              "6327  [-0.1641, -0.1562, -0.42, 1.086, -1.883, 0.193...   \n",
              "6328  [-0.169, -0.1738, -0.4395, 1.07, -1.867, 0.21,...   \n",
              "6329  [-0.1543, -0.103, -0.4238, 1.07, -1.859, 0.197...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.4297, -0.2812, -0.9727, 0.5117, -1.672, 0....   \n",
              "1     [-0.3945, -0.252, -0.957, 0.5312, -1.6875, 0.4...   \n",
              "2     [-0.4238, -0.2695, -0.9883, 0.5117, -1.68, 0.4...   \n",
              "3     [-0.459, -0.2734, -0.9727, 0.4844, -1.672, 0.4...   \n",
              "4     [-0.4219, -0.2617, -0.9297, 0.5273, -1.641, 0....   \n",
              "...                                                 ...   \n",
              "6325  [-0.457, -0.3066, -1.0, 0.5234, -1.656, 0.414,...   \n",
              "6326  [-0.4688, -0.3223, -1.016, 0.5117, -1.68, 0.46...   \n",
              "6327  [-0.4883, -0.3145, -1.008, 0.535, -1.656, 0.40...   \n",
              "6328  [-0.4844, -0.3281, -1.023, 0.4922, -1.633, 0.4...   \n",
              "6329  [-0.4531, -0.2422, -1.047, 0.498, -1.641, 0.40...   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.266, -0.209, -1.156, 0.3926, -2.062, 0.252...   \n",
              "1     [-1.227, -0.1846, -1.172, 0.3887, -2.047, 0.31...   \n",
              "2     [-1.281, -0.1797, -1.203, 0.3633, -2.078, 0.28...   \n",
              "3     [-1.289, -0.1963, -1.18, 0.3848, -2.094, 0.287...   \n",
              "4     [-1.305, -0.1504, -1.148, 0.416, -2.031, 0.254...   \n",
              "...                                                 ...   \n",
              "6325  [-1.352, -0.1943, -1.195, 0.3984, -2.016, 0.24...   \n",
              "6326  [-1.344, -0.254, -1.211, 0.42, -2.047, 0.249, ...   \n",
              "6327  [-1.367, -0.2266, -1.211, 0.4238, -2.047, 0.21...   \n",
              "6328  [-1.367, -0.2354, -1.203, 0.375, -2.031, 0.254...   \n",
              "6329  [-1.3125, -0.1211, -1.195, 0.3652, -2.094, 0.2...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.328, 0.293, -0.2656, 0.11816, -1.055, -0.6...   \n",
              "1     [-1.156, 0.3145, -0.3008, 0.0703, -1.016, -0.6...   \n",
              "2     [-1.336, 0.3047, -0.3008, -0.02246, -1.094, -0...   \n",
              "3     [-1.328, 0.332, -0.3008, 0.02051, -1.148, -0.6...   \n",
              "4     [-1.391, 0.3984, -0.2969, 0.1094, -1.07, -0.64...   \n",
              "...                                                 ...   \n",
              "6325  [-1.516, 0.3926, -0.3867, 0.1006, -1.031, -0.5...   \n",
              "6326  [-1.4375, 0.2773, -0.414, 0.01636, -1.094, -0....   \n",
              "6327  [-1.4375, 0.336, -0.3867, 0.06494, -1.109, -0....   \n",
              "6328  [-1.469, 0.3438, -0.4414, 0.01758, -1.023, -0....   \n",
              "6329  [-1.242, 0.4395, -0.4297, 0.11914, -1.109, -0....   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [30.5, -1.008, 1.602, 0.711, -0.002213, -0.237...  \n",
              "1     [29.0, -2.469, 1.922, -0.252, 2.062, 1.398, -1...  \n",
              "2     [29.12, -2.297, 2.938, -0.1934, -1.93, 2.672, ...  \n",
              "3     [25.12, -1.961, 0.0, 0.1641, 0.4668, 0.91, -4....  \n",
              "4     [31.25, 3.672, -0.75, 1.492, -2.0, -2.86, -5.8...  \n",
              "...                                                 ...  \n",
              "6325  [18.88, -0.672, -1.992, 3.828, -1.023, 2.984, ...  \n",
              "6326  [14.19, -6.28, -0.711, -1.891, 2.281, 7.22, -1...  \n",
              "6327  [21.75, -8.56, 0.2266, 2.734, 1.297, 5.97, -1....  \n",
              "6328  [23.88, -4.562, -1.3125, 2.125, -0.8438, 1.414...  \n",
              "6329  [12.19, -0.9062, -1.297, 2.797, -0.05176, 2.61...  \n",
              "\n",
              "[6330 rows x 29 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>area</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Boron is used in the production of glass and c...</td>\n",
              "      <td>1</td>\n",
              "      <td>elements</td>\n",
              "      <td>[1.594, -0.3232, 0.01913, 0.3162, -0.33, -1.27...</td>\n",
              "      <td>[-0.175, 0.2245, -0.195, -0.4348, -0.5117, 0.0...</td>\n",
              "      <td>[-0.151, 0.2274, 0.3025, -0.1472, -0.0689, -0....</td>\n",
              "      <td>[-0.1584, 0.2742, 0.0692, -0.1511, -0.0811, -0...</td>\n",
              "      <td>[-0.1062, 0.2397, 0.02325, -0.1812, 0.269, -0....</td>\n",
              "      <td>[-0.09985, -0.672, 0.06836, -0.2615, -0.05087,...</td>\n",
              "      <td>[0.2229, -0.7314, -0.4043, 0.009766, -0.1787, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.504, 0.414, 0.3086, 0.5156, -0.455, -0.059...</td>\n",
              "      <td>[-0.9375, 0.547, -0.0654, 0.793, -0.914, -0.45...</td>\n",
              "      <td>[-1.258, 0.0515, 0.166, 0.5938, -1.617, -0.066...</td>\n",
              "      <td>[-1.203, 0.5625, -0.1904, 0.793, -1.531, -0.39...</td>\n",
              "      <td>[0.04883, 0.10156, 0.04688, 0.8555, -1.625, -0...</td>\n",
              "      <td>[-0.0918, -0.1426, -0.418, 1.07, -1.914, 0.212...</td>\n",
              "      <td>[-0.4297, -0.2812, -0.9727, 0.5117, -1.672, 0....</td>\n",
              "      <td>[-1.266, -0.209, -1.156, 0.3926, -2.062, 0.252...</td>\n",
              "      <td>[-1.328, 0.293, -0.2656, 0.11816, -1.055, -0.6...</td>\n",
              "      <td>[30.5, -1.008, 1.602, 0.711, -0.002213, -0.237...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Praseodymium is used in coins, batteries, and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "      <td>[2.867, -0.0632, 0.454, 0.3157, -0.306, -1.255...</td>\n",
              "      <td>[0.3206, 0.2805, 0.2157, -0.2847, -0.6133, 0.1...</td>\n",
              "      <td>[0.007187, 0.2308, 0.4438, -0.2084, -0.2263, 0...</td>\n",
              "      <td>[0.0937, 0.1138, 0.1555, -0.1403, -0.172, 0.10...</td>\n",
              "      <td>[-0.1437, 0.231, -0.02036, -0.1841, -0.02399, ...</td>\n",
              "      <td>[-0.00354, -0.3713, 0.2361, -0.2153, -0.09064,...</td>\n",
              "      <td>[0.4646, -0.4312, -0.3813, -0.1802, -0.0902, -...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4844, 0.4238, 0.3066, 0.5195, -0.4531, -0....</td>\n",
              "      <td>[-0.914, 0.5547, -0.05664, 0.797, -0.9297, -0....</td>\n",
              "      <td>[-1.242, 0.063, 0.1787, 0.6055, -1.617, -0.027...</td>\n",
              "      <td>[-1.1875, 0.578, -0.1758, 0.801, -1.531, -0.35...</td>\n",
              "      <td>[0.06445, 0.1133, 0.05664, 0.871, -1.641, 0.00...</td>\n",
              "      <td>[-0.0884, -0.1206, -0.4062, 1.086, -1.93, 0.24...</td>\n",
              "      <td>[-0.3945, -0.252, -0.957, 0.5312, -1.6875, 0.4...</td>\n",
              "      <td>[-1.227, -0.1846, -1.172, 0.3887, -2.047, 0.31...</td>\n",
              "      <td>[-1.156, 0.3145, -0.3008, 0.0703, -1.016, -0.6...</td>\n",
              "      <td>[29.0, -2.469, 1.922, -0.252, 2.062, 1.398, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cobalt is used in strong, permanent magnets an...</td>\n",
              "      <td>1</td>\n",
              "      <td>elements</td>\n",
              "      <td>[1.794, -0.3086, 0.2605, 0.004673, -0.1708, -1...</td>\n",
              "      <td>[0.289, 0.0877, 0.05545, -0.5386, -0.4893, 0.2...</td>\n",
              "      <td>[0.1296, 0.0861, 0.3347, -0.2142, 0.00715, 0.2...</td>\n",
              "      <td>[0.2142, 0.11633, 0.3093, -0.2554, 0.0714, -0....</td>\n",
              "      <td>[0.4866, 0.2316, 0.1227, -0.1515, 0.129, -0.03...</td>\n",
              "      <td>[0.3452, -0.2578, 0.28, -0.1854, 0.01409, 0.19...</td>\n",
              "      <td>[0.737, -0.359, 0.04645, -0.1427, -0.0757, 0.0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4883, 0.42, 0.293, 0.5195, -0.4512, -0.068...</td>\n",
              "      <td>[-0.9297, 0.547, -0.07764, 0.797, -0.9297, -0....</td>\n",
              "      <td>[-1.25, 0.04663, 0.1592, 0.5977, -1.617, -0.06...</td>\n",
              "      <td>[-1.195, 0.5586, -0.1992, 0.797, -1.531, -0.39...</td>\n",
              "      <td>[0.04883, 0.1006, 0.03125, 0.8633, -1.641, -0....</td>\n",
              "      <td>[-0.1035, -0.1416, -0.4258, 1.078, -1.914, 0.2...</td>\n",
              "      <td>[-0.4238, -0.2695, -0.9883, 0.5117, -1.68, 0.4...</td>\n",
              "      <td>[-1.281, -0.1797, -1.203, 0.3633, -2.078, 0.28...</td>\n",
              "      <td>[-1.336, 0.3047, -0.3008, -0.02246, -1.094, -0...</td>\n",
              "      <td>[29.12, -2.297, 2.938, -0.1934, -1.93, 2.672, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Indium is in the Lanthanide group.</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "      <td>[1.759, -0.2483, -0.221, 0.4106, -0.3943, -0.7...</td>\n",
              "      <td>[-0.04474, 0.498, 0.07385, -0.3625, -0.3167, 0...</td>\n",
              "      <td>[-0.1902, 0.2515, 0.6636, -0.34, -0.3474, 0.15...</td>\n",
              "      <td>[-0.0616, 0.2954, 0.639, -0.099, -0.3667, -0.2...</td>\n",
              "      <td>[0.1963, 0.584, -0.1418, 0.0385, -0.2247, 0.22...</td>\n",
              "      <td>[0.2053, -0.03604, -0.01566, -0.1418, -0.1836,...</td>\n",
              "      <td>[0.957, 0.1431, 0.1304, -0.2057, -0.6045, -0.1...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5156, 0.4277, 0.3086, 0.5, -0.4668, -0.065...</td>\n",
              "      <td>[-0.961, 0.547, -0.05786, 0.7734, -0.9414, -0....</td>\n",
              "      <td>[-1.273, 0.0476, 0.168, 0.578, -1.609, -0.0781...</td>\n",
              "      <td>[-1.227, 0.5625, -0.1836, 0.7734, -1.523, -0.4...</td>\n",
              "      <td>[0.03125, 0.08984, 0.04102, 0.8477, -1.625, -0...</td>\n",
              "      <td>[-0.1357, -0.1377, -0.4219, 1.0625, -1.914, 0....</td>\n",
              "      <td>[-0.459, -0.2734, -0.9727, 0.4844, -1.672, 0.4...</td>\n",
              "      <td>[-1.289, -0.1963, -1.18, 0.3848, -2.094, 0.287...</td>\n",
              "      <td>[-1.328, 0.332, -0.3008, 0.02051, -1.148, -0.6...</td>\n",
              "      <td>[25.12, -1.961, 0.0, 0.1641, 0.4668, 0.91, -4....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zirconium has the atomic number of 6.</td>\n",
              "      <td>0</td>\n",
              "      <td>elements</td>\n",
              "      <td>[2.336, -0.4631, 0.3208, 0.4666, -0.545, -1.10...</td>\n",
              "      <td>[0.001269, 0.2698, 0.03085, -0.226, -0.467, 0....</td>\n",
              "      <td>[-0.1399, 0.01933, 0.2783, -0.2058, -0.07794, ...</td>\n",
              "      <td>[-0.2311, 0.04462, 0.296, -0.2742, -0.198, -0....</td>\n",
              "      <td>[0.1637, 0.2998, 0.1648, 0.09656, 0.05118, 0.1...</td>\n",
              "      <td>[0.1797, -0.1589, 0.11523, 0.3179, 0.3647, -0....</td>\n",
              "      <td>[0.747, -0.5015, -0.5903, -0.0797, 0.0863, -0....</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.508, 0.4297, 0.33, 0.535, -0.4375, -0.0507...</td>\n",
              "      <td>[-0.9375, 0.5586, -0.03076, 0.8125, -0.9062, -...</td>\n",
              "      <td>[-1.25, 0.05078, 0.2002, 0.6094, -1.586, -0.07...</td>\n",
              "      <td>[-1.195, 0.5703, -0.1504, 0.8047, -1.5, -0.398...</td>\n",
              "      <td>[0.05078, 0.0918, 0.0586, 0.875, -1.586, -0.02...</td>\n",
              "      <td>[-0.0962, -0.1367, -0.3926, 1.078, -1.867, 0.2...</td>\n",
              "      <td>[-0.4219, -0.2617, -0.9297, 0.5273, -1.641, 0....</td>\n",
              "      <td>[-1.305, -0.1504, -1.148, 0.416, -2.031, 0.254...</td>\n",
              "      <td>[-1.391, 0.3984, -0.2969, 0.1094, -1.07, -0.64...</td>\n",
              "      <td>[31.25, 3.672, -0.75, 1.492, -2.0, -2.86, -5.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6325</th>\n",
              "      <td>Chester Carlson invented the programming langu...</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "      <td>[2.58, 0.01671, 0.11273, 0.4978, -0.2035, -0.5...</td>\n",
              "      <td>[-0.03308, 0.2014, -0.1584, 0.255, -0.2551, 0....</td>\n",
              "      <td>[-0.04428, 0.1489, 0.1675, 0.3193, 0.0851, -0....</td>\n",
              "      <td>[-0.11884, 0.03021, -0.1176, 0.1764, 0.1278, -...</td>\n",
              "      <td>[0.1963, 0.002495, -0.6924, 0.0436, 0.388, 0.1...</td>\n",
              "      <td>[-0.07007, -0.4854, -0.0738, -0.0862, -0.02051...</td>\n",
              "      <td>[-0.0433, -0.4849, 0.05524, -0.0689, -0.2878, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4844, 0.3926, 0.3008, 0.5, -0.4219, -0.059...</td>\n",
              "      <td>[-0.957, 0.5, -0.0698, 0.7812, -0.8867, -0.474...</td>\n",
              "      <td>[-1.305, -0.001709, 0.169, 0.586, -1.586, -0.0...</td>\n",
              "      <td>[-1.25, 0.5156, -0.1777, 0.7773, -1.508, -0.42...</td>\n",
              "      <td>[0.001953, 0.05664, 0.03906, 0.8477, -1.617, -...</td>\n",
              "      <td>[-0.1533, -0.168, -0.4336, 1.07, -1.898, 0.193...</td>\n",
              "      <td>[-0.457, -0.3066, -1.0, 0.5234, -1.656, 0.414,...</td>\n",
              "      <td>[-1.352, -0.1943, -1.195, 0.3984, -2.016, 0.24...</td>\n",
              "      <td>[-1.516, 0.3926, -0.3867, 0.1006, -1.031, -0.5...</td>\n",
              "      <td>[18.88, -0.672, -1.992, 3.828, -1.023, 2.984, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>Willem Einthoven invented the electrocardiogra...</td>\n",
              "      <td>1</td>\n",
              "      <td>inventions</td>\n",
              "      <td>[3.242, -0.4565, 0.1081, -0.1288, -0.1626, 0.2...</td>\n",
              "      <td>[-0.1495, 0.04892, 0.0594, -0.353, -0.2162, 0....</td>\n",
              "      <td>[-0.1653, 0.2494, 0.463, -0.1686, -0.0418, 0.1...</td>\n",
              "      <td>[0.1722, 0.04132, 0.1676, -0.2452, 0.2311, 0.0...</td>\n",
              "      <td>[0.352, 0.2103, 0.1882, -0.3093, 0.458, 0.2786...</td>\n",
              "      <td>[0.1779, -0.4126, 0.7236, -0.313, 0.2185, -0.1...</td>\n",
              "      <td>[0.817, -0.1066, 0.1848, -0.1472, -0.2566, -0....</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.508, 0.4004, 0.3086, 0.508, -0.4434, -0.04...</td>\n",
              "      <td>[-0.957, 0.508, -0.0698, 0.797, -0.9062, -0.46...</td>\n",
              "      <td>[-1.297, -0.00903, 0.1514, 0.59, -1.594, -0.07...</td>\n",
              "      <td>[-1.25, 0.504, -0.1992, 0.785, -1.508, -0.4062...</td>\n",
              "      <td>[0.001953, 0.03516, 0.01953, 0.8555, -1.609, -...</td>\n",
              "      <td>[-0.1592, -0.1855, -0.4492, 1.078, -1.914, 0.2...</td>\n",
              "      <td>[-0.4688, -0.3223, -1.016, 0.5117, -1.68, 0.46...</td>\n",
              "      <td>[-1.344, -0.254, -1.211, 0.42, -2.047, 0.249, ...</td>\n",
              "      <td>[-1.4375, 0.2773, -0.414, 0.01636, -1.094, -0....</td>\n",
              "      <td>[14.19, -6.28, -0.711, -1.891, 2.281, 7.22, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6327</th>\n",
              "      <td>George Antheil invented the Band-Aid.</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "      <td>[2.555, -0.417, -0.0806, 0.3462, 0.291, -0.673...</td>\n",
              "      <td>[-0.32, 0.222, -0.0218, 0.12134, 0.4294, 0.471...</td>\n",
              "      <td>[-0.47, -0.02766, 0.6523, 0.1521, 0.731, 0.223...</td>\n",
              "      <td>[-0.2058, -0.02312, 0.3525, 0.1844, 0.749, 0.1...</td>\n",
              "      <td>[0.2231, -0.03552, 0.2532, 0.0014105, 1.051, 0...</td>\n",
              "      <td>[0.0639, -0.395, 0.548, 0.2106, 0.4834, 0.0176...</td>\n",
              "      <td>[0.4653, -0.3438, -0.1183, 0.2742, 0.006077, 0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5195, 0.3945, 0.3242, 0.5195, -0.4102, -0....</td>\n",
              "      <td>[-0.9727, 0.508, -0.0464, 0.801, -0.871, -0.48...</td>\n",
              "      <td>[-1.3125, 0.008545, 0.1973, 0.6016, -1.555, -0...</td>\n",
              "      <td>[-1.273, 0.5273, -0.1562, 0.793, -1.469, -0.42...</td>\n",
              "      <td>[-0.01172, 0.06836, 0.05273, 0.867, -1.586, -0...</td>\n",
              "      <td>[-0.1641, -0.1562, -0.42, 1.086, -1.883, 0.193...</td>\n",
              "      <td>[-0.4883, -0.3145, -1.008, 0.535, -1.656, 0.40...</td>\n",
              "      <td>[-1.367, -0.2266, -1.211, 0.4238, -2.047, 0.21...</td>\n",
              "      <td>[-1.4375, 0.336, -0.3867, 0.06494, -1.109, -0....</td>\n",
              "      <td>[21.75, -8.56, 0.2266, 2.734, 1.297, 5.97, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6328</th>\n",
              "      <td>John Shepherd-Barron invented the ATM.</td>\n",
              "      <td>1</td>\n",
              "      <td>inventions</td>\n",
              "      <td>[2.031, 0.2261, -0.3557, 0.3281, 0.03876, -1.2...</td>\n",
              "      <td>[-0.2783, 0.8823, -0.3345, -0.2235, 0.2595, 0....</td>\n",
              "      <td>[-0.2986, 0.616, 0.3828, -0.1313, 0.315, 0.098...</td>\n",
              "      <td>[-0.2969, 0.584, -0.01855, 0.004776, 0.3594, -...</td>\n",
              "      <td>[-0.1214, 0.502, -0.0816, -0.02214, 0.7383, 0....</td>\n",
              "      <td>[-0.2341, -0.08813, 0.3096, -0.11707, 0.1936, ...</td>\n",
              "      <td>[0.03516, 0.0, 0.02605, -0.2378, -0.171, -0.06...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3828, 0.3027, 0.5195, -0.4219, -0.047...</td>\n",
              "      <td>[-0.9766, 0.4922, -0.06055, 0.797, -0.875, -0....</td>\n",
              "      <td>[-1.328, -0.0105, 0.1865, 0.6094, -1.5625, -0....</td>\n",
              "      <td>[-1.273, 0.508, -0.165, 0.801, -1.477, -0.414,...</td>\n",
              "      <td>[-0.02539, 0.03613, 0.0547, 0.867, -1.586, -0....</td>\n",
              "      <td>[-0.169, -0.1738, -0.4395, 1.07, -1.867, 0.21,...</td>\n",
              "      <td>[-0.4844, -0.3281, -1.023, 0.4922, -1.633, 0.4...</td>\n",
              "      <td>[-1.367, -0.2354, -1.203, 0.375, -2.031, 0.254...</td>\n",
              "      <td>[-1.469, 0.3438, -0.4414, 0.01758, -1.023, -0....</td>\n",
              "      <td>[23.88, -4.562, -1.3125, 2.125, -0.8438, 1.414...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>Linus Torvalds lived in Stephanie.</td>\n",
              "      <td>0</td>\n",
              "      <td>inventions</td>\n",
              "      <td>[2.2, -0.2394, -0.6465, 0.7607, -0.1346, -0.64...</td>\n",
              "      <td>[0.11206, 0.2444, -0.814, 0.0599, -0.3281, 0.4...</td>\n",
              "      <td>[0.11664, 0.3613, -0.3467, -0.001356, -0.23, 0...</td>\n",
              "      <td>[0.4663, 0.1903, -0.6426, -0.1427, 0.01139, 0....</td>\n",
              "      <td>[0.6636, 0.3298, -0.4436, -0.125, 0.568, 0.275...</td>\n",
              "      <td>[0.2886, -0.0642, -0.1214, -0.3086, 0.09735, 0...</td>\n",
              "      <td>[0.325, 0.6313, -0.204, -0.6123, -0.07574, 0.9...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.498, 0.4238, 0.3281, 0.5273, -0.4238, -0.0...</td>\n",
              "      <td>[-0.965, 0.5273, -0.02551, 0.8086, -0.871, -0....</td>\n",
              "      <td>[-1.305, 0.0359, 0.2119, 0.6133, -1.5625, -0.1...</td>\n",
              "      <td>[-1.266, 0.5547, -0.12305, 0.8086, -1.477, -0....</td>\n",
              "      <td>[-0.01953, 0.10156, 0.0586, 0.867, -1.578, -0....</td>\n",
              "      <td>[-0.1543, -0.103, -0.4238, 1.07, -1.859, 0.197...</td>\n",
              "      <td>[-0.4531, -0.2422, -1.047, 0.498, -1.641, 0.40...</td>\n",
              "      <td>[-1.3125, -0.1211, -1.195, 0.3652, -2.094, 0.2...</td>\n",
              "      <td>[-1.242, 0.4395, -0.4297, 0.11914, -1.109, -0....</td>\n",
              "      <td>[12.19, -0.9062, -1.297, 2.797, -0.05176, 2.61...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6330 rows × 29 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_tf_df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df = extract_activations_df(tf_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "activation_tf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xcnkzN3TkKmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383f7504-6ad6-4f42-e91f-9a5cec6f5dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving true-false_t5gemma-b-b-ul2 to GDrive...\n",
            "Saved true-false_t5gemma-b-b-ul2\n"
          ]
        }
      ],
      "source": [
        "save_activations_df(activation_tf_df, 'true-false', model_id_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hpgU5El7Li"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DpPU1tWl6sk"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "text_column = 'statement'\n",
        "\n",
        "activation_tf_df_2b = extract_activations_df(tf_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_tf_df_2b, 'true-false', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMsDqX2Unz_R"
      },
      "outputs": [],
      "source": [
        "activation_tf_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9XwUt5DhKLs"
      },
      "source": [
        "## CoLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_CCk8YEhK_v",
        "outputId": "9d023e11-f4f3-4dba-bc47-666e2f2d4558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-26 11:40:45--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
            "Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
            "Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255330 (249K) [application/x-zip-compressed]\n",
            "Saving to: ‘cola_public_1.1.zip’\n",
            "\n",
            "\rcola_public_1.1.zip   0%[                    ]       0  --.-KB/s               \rcola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-26 11:40:45 (17.5 MB/s) - ‘cola_public_1.1.zip’ saved [255330/255330]\n",
            "\n",
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n",
        "!unzip cola_public_1.1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BoH9HrtvhfKo",
        "outputId": "392252f6-177b-4b76-d5da-95c515bb1b54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 source  label  \\\n",
              "0     out_of_domain_dev      1   \n",
              "1     out_of_domain_dev      1   \n",
              "2     out_of_domain_dev      1   \n",
              "3     out_of_domain_dev      1   \n",
              "4     out_of_domain_dev      1   \n",
              "...                 ...    ...   \n",
              "9589    in_domain_train      0   \n",
              "9590    in_domain_train      0   \n",
              "9591    in_domain_train      1   \n",
              "9592    in_domain_train      1   \n",
              "9593    in_domain_train      1   \n",
              "\n",
              "                                               sentence  \n",
              "0                       Somebody just left - guess who.  \n",
              "1     They claimed they had settled on something, bu...  \n",
              "2             If Sam was going, Sally would know where.  \n",
              "3     They're going to serve the guests something, b...  \n",
              "4                  She's reading. I can't imagine what.  \n",
              "...                                                 ...  \n",
              "9589                   Poseidon appears to own a dragon  \n",
              "9590                     Digitize is my happiest memory  \n",
              "9591                     It is easy to slay the Gorgon.  \n",
              "9592       I had the strangest feeling that I knew you.  \n",
              "9593                What all did you get for Christmas?  \n",
              "\n",
              "[9594 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>Somebody just left - guess who.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They claimed they had settled on something, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If Sam was going, Sally would know where.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They're going to serve the guests something, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>She's reading. I can't imagine what.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 3 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cola_df",
              "summary": "{\n  \"name\": \"cola_df\",\n  \"rows\": 9594,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"out_of_domain_dev\",\n          \"in_domain_dev\",\n          \"in_domain_train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9553,\n        \"samples\": [\n          \"I saw the student.\",\n          \"The farmer loaded apples into the cart.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "path = '/content/cola_public/raw/'\n",
        "cola_files = os.listdir(path) # contiene ['out_of_domain_dev.tsv', 'in_domain_train.tsv', 'in_domain_dev.tsv']\n",
        "dfs = []\n",
        "\n",
        "for cf in cola_files:\n",
        "  df = pd.read_csv(f'{path}{cf}', delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "  df.drop(columns=['sentence_source', 'label_notes'], inplace=True)\n",
        "  df.insert(loc=0, column='source', value=cf.split('.')[0], allow_duplicates=True)\n",
        "  dfs.append(df)\n",
        "\n",
        "cola_df = pd.concat(dfs, ignore_index=True)\n",
        "cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cqOl6kTmFzR"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "i-NK-2DehmTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1220cb-b2b1-4e9b-d5b6-90606558fd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing 9594 sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:29<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n",
            "Saving cola_t5gemma-b-b-ul2 to GDrive...\n",
            "Saved cola_t5gemma-b-b-ul2\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'sentence'\n",
        "\n",
        "activation_cola_df = extract_activations_df(cola_df, model_b, tokenizer_b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df, 'cola', model_id_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GmcKoW3NiPEm",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c1b03b9-c015-4d9c-8732-1d6776df99fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 source  label  \\\n",
              "0     out_of_domain_dev      1   \n",
              "1     out_of_domain_dev      1   \n",
              "2     out_of_domain_dev      1   \n",
              "3     out_of_domain_dev      1   \n",
              "4     out_of_domain_dev      1   \n",
              "...                 ...    ...   \n",
              "9589    in_domain_train      0   \n",
              "9590    in_domain_train      0   \n",
              "9591    in_domain_train      1   \n",
              "9592    in_domain_train      1   \n",
              "9593    in_domain_train      1   \n",
              "\n",
              "                                               sentence  \\\n",
              "0                       Somebody just left - guess who.   \n",
              "1     They claimed they had settled on something, bu...   \n",
              "2             If Sam was going, Sally would know where.   \n",
              "3     They're going to serve the guests something, b...   \n",
              "4                  She's reading. I can't imagine what.   \n",
              "...                                                 ...   \n",
              "9589                   Poseidon appears to own a dragon   \n",
              "9590                     Digitize is my happiest memory   \n",
              "9591                     It is easy to slay the Gorgon.   \n",
              "9592       I had the strangest feeling that I knew you.   \n",
              "9593                What all did you get for Christmas?   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [1.543, -0.08734, -0.024, 0.1147, -0.2515, -1....   \n",
              "1     [1.201, -0.573, -0.413, 0.1304, -0.1552, -1.16...   \n",
              "2     [1.43, -0.1954, 0.007423, 0.3733, 0.3796, -1.2...   \n",
              "3     [1.231, -0.0665, -0.411, 0.276, 0.1493, -1.48,...   \n",
              "4     [1.5, 0.2157, -0.2211, 0.828, -0.1641, -1.477,...   \n",
              "...                                                 ...   \n",
              "9589  [2.41, -0.2069, -0.4119, -0.793, 0.2042, -0.42...   \n",
              "9590  [2.676, -1.304, -0.006836, -0.6055, -0.639, 0....   \n",
              "9591  [1.982, 0.01598, -0.4011, 0.43, -0.1137, -1.35...   \n",
              "9592  [1.13, -0.548, -0.1625, 0.2316, -0.1013, -0.89...   \n",
              "9593  [1.306, -0.9287, -0.1448, 0.202, -0.2656, -0.9...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [-0.265, 0.1556, 0.02525, -0.1493, -0.1678, -0...   \n",
              "1     [0.0206, -0.255, -0.1913, -0.1177, -0.2094, 0....   \n",
              "2     [0.2377, -0.06525, -0.3958, -0.341, 0.2098, 0....   \n",
              "3     [-0.02309, 0.1294, -0.3066, -0.2405, -0.01993,...   \n",
              "4     [0.08307, 0.3298, -0.3032, -0.1846, -0.2866, 0...   \n",
              "...                                                 ...   \n",
              "9589  [-0.3777, 0.1925, -0.375, -0.761, -0.113, 0.47...   \n",
              "9590  [-0.3313, -0.4558, 0.1572, -0.577, -0.5938, 0....   \n",
              "9591  [-0.12024, 0.5874, -0.4888, -0.4724, -0.05115,...   \n",
              "9592  [-0.1342, -0.18, -0.0806, -0.03497, -0.1707, 0...   \n",
              "9593  [0.1018, -0.1641, -0.1702, -0.481, -0.5264, 0....   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [-0.387, 0.1759, 0.2291, -0.3171, 0.0395, -0.2...   \n",
              "1     [0.0673, -0.1573, -0.1293, 0.0353, -0.1493, -0...   \n",
              "2     [0.0459, -0.1997, -0.1178, -0.1616, 0.113, 0.1...   \n",
              "3     [-0.188, -0.1611, -0.1403, -0.1069, -0.0785, -...   \n",
              "4     [-0.744, -0.1349, -0.1515, -0.1368, -0.1705, -...   \n",
              "...                                                 ...   \n",
              "9589  [-0.1881, -0.2703, -0.341, -0.751, -0.2664, 0....   \n",
              "9590  [-0.4055, -0.369, 0.07355, -0.7974, -0.4011, 0...   \n",
              "9591  [-0.4553, 0.3398, -0.1569, -0.408, 0.1606, -0....   \n",
              "9592  [-0.2864, -0.2461, 0.1464, -0.02335, 0.00596, ...   \n",
              "9593  [-0.01746, -0.3806, -0.3396, -0.2024, -0.3918,...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.2842, -0.0357, 0.2566, -0.3528, 0.2996, -0...   \n",
              "1     [0.00669, 0.01184, -0.1696, -0.1421, -0.1792, ...   \n",
              "2     [0.0084, 0.1638, -0.4126, -0.05673, 0.1422, 0....   \n",
              "3     [-0.2786, -0.01884, -0.2546, -0.2042, 0.03607,...   \n",
              "4     [-0.3816, -0.1418, -0.539, -0.2898, -0.1924, -...   \n",
              "...                                                 ...   \n",
              "9589  [-0.252, -0.2686, -0.5884, -0.2249, -0.1462, 0...   \n",
              "9590  [-0.4275, -0.638, -0.1849, -0.4626, -0.295, -0...   \n",
              "9591  [-0.3916, 0.3433, -0.3652, -0.2437, 0.4111, -0...   \n",
              "9592  [0.0864, -0.2683, -0.0796, -0.03085, 0.3008, 0...   \n",
              "9593  [0.4673, -0.794, -0.4458, 0.04102, -0.1653, -0...   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.1532, -0.2812, 0.11957, -0.313, 0.6445, -0...   \n",
              "1     [-0.0663, -0.4077, -0.1447, -0.1183, 0.0848, 0...   \n",
              "2     [0.1656, -0.02551, -0.3247, 0.02852, 0.629, 0....   \n",
              "3     [-0.436, -0.4165, -0.449, -0.6597, 0.2482, -0....   \n",
              "4     [-0.0725, -0.02075, -0.4688, -0.4436, -0.107, ...   \n",
              "...                                                 ...   \n",
              "9589  [-0.1239, -0.0907, -0.487, -0.2754, 0.1967, 0....   \n",
              "9590  [-0.0713, -0.2063, -0.1722, -0.5483, 0.3357, -...   \n",
              "9591  [-0.2272, 0.3071, -0.436, -0.3667, 0.318, -0.3...   \n",
              "9592  [0.05167, -0.1395, 0.0824, 0.1548, 0.1958, 0.1...   \n",
              "9593  [0.3572, -1.043, 0.3853, 0.09106, 0.10547, 0.3...   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [-0.00837, -0.3154, 0.4402, -0.06, 0.5654, -0....   \n",
              "1     [0.10596, -0.09106, -0.368, 0.1038, -0.11304, ...   \n",
              "2     [0.2053, -0.10443, -0.010056, -0.0814, 0.1656,...   \n",
              "3     [-0.0707, -0.3406, -0.1775, -0.2096, 0.1655, -...   \n",
              "4     [-0.03726, -0.2256, -0.171, -0.3992, -0.1259, ...   \n",
              "...                                                 ...   \n",
              "9589  [-0.04214, -0.3657, -0.1698, -0.1923, -0.2668,...   \n",
              "9590  [-0.291, -0.1732, -0.1553, -0.4548, -0.01172, ...   \n",
              "9591  [-0.2493, -0.04926, 0.1603, -0.2169, 0.2942, -...   \n",
              "9592  [0.3828, -0.2274, -0.0697, -0.02011, 0.0667, -...   \n",
              "9593  [0.6987, -0.689, 0.1849, -0.2367, -0.352, 0.19...   \n",
              "\n",
              "                                        encoder_layer_7  ...  \\\n",
              "0     [0.02539, -0.4048, 0.1914, -0.2825, 0.6177, -0...  ...   \n",
              "1     [0.2954, -0.1733, -0.423, 0.5835, 0.1013, -0.0...  ...   \n",
              "2     [0.5176, -0.1411, -0.2083, -0.157, 0.104, 0.34...  ...   \n",
              "3     [0.0828, -0.3928, -0.514, -0.2213, 0.1182, 0.1...  ...   \n",
              "4     [0.1411, -0.566, -0.3948, -0.4534, 0.0, -0.432...  ...   \n",
              "...                                                 ...  ...   \n",
              "9589  [0.385, -0.8438, -1.05, -0.2634, -0.4995, 0.03...  ...   \n",
              "9590  [-0.77, -0.6396, -0.966, -0.595, -0.257, -0.08...  ...   \n",
              "9591  [-0.151, -0.46, -0.08856, -0.563, 0.25, -0.063...  ...   \n",
              "9592  [0.1918, -0.903, 0.2683, -0.10126, 0.1006, 0.2...  ...   \n",
              "9593  [0.687, -1.275, 0.4153, -0.5107, -0.1318, 0.08...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.5234, 0.3867, 0.3223, 0.4922, -0.461, -0.1...   \n",
              "1     [-0.4902, 0.3906, 0.332, 0.5195, -0.4727, -0.0...   \n",
              "2     [-0.504, 0.3984, 0.3066, 0.5156, -0.4414, -0.1...   \n",
              "3     [-0.4902, 0.3926, 0.3145, 0.5273, -0.4922, -0....   \n",
              "4     [-0.4746, 0.3965, 0.3027, 0.5117, -0.4492, -0....   \n",
              "...                                                 ...   \n",
              "9589  [-0.5273, 0.4219, 0.3516, 0.5195, -0.4395, -0....   \n",
              "9590  [-0.5234, 0.418, 0.336, 0.4727, -0.4062, -0.08...   \n",
              "9591  [-0.504, 0.3984, 0.3223, 0.5195, -0.4648, -0.1...   \n",
              "9592  [-0.4922, 0.4102, 0.3184, 0.5234, -0.4531, -0....   \n",
              "9593  [-0.5, 0.3691, 0.3262, 0.4883, -0.4453, -0.112...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.992, 0.5, -0.0381, 0.7773, -0.9062, -0.515...   \n",
              "1     [-0.9453, 0.5234, -0.02759, 0.8047, -0.9414, -...   \n",
              "2     [-0.965, 0.508, -0.05298, 0.801, -0.9023, -0.5...   \n",
              "3     [-0.961, 0.5234, -0.04102, 0.801, -0.957, -0.4...   \n",
              "4     [-0.949, 0.5156, -0.05884, 0.797, -0.8984, -0....   \n",
              "...                                                 ...   \n",
              "9589  [-0.996, 0.5312, -0.01001, 0.8047, -0.8984, -0...   \n",
              "9590  [-0.9727, 0.5312, -0.02783, 0.75, -0.8594, -0....   \n",
              "9591  [-0.961, 0.5117, -0.04102, 0.8086, -0.9336, -0...   \n",
              "9592  [-0.9453, 0.5312, -0.04565, 0.8086, -0.91, -0....   \n",
              "9593  [-0.9805, 0.504, -0.03906, 0.7812, -0.91, -0.5...   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.32, 0.002441, 0.2051, 0.5703, -1.609, -0.1...   \n",
              "1     [-1.281, 0.03735, 0.2109, 0.59, -1.641, -0.078...   \n",
              "2     [-1.305, 0.01855, 0.2002, 0.582, -1.586, -0.11...   \n",
              "3     [-1.297, 0.0332, 0.2002, 0.582, -1.656, -0.082...   \n",
              "4     [-1.281, 0.01904, 0.1846, 0.586, -1.594, -0.08...   \n",
              "...                                                 ...   \n",
              "9589  [-1.32, 0.02148, 0.2344, 0.5938, -1.586, -0.10...   \n",
              "9590  [-1.3125, 0.04077, 0.2139, 0.547, -1.5625, -0....   \n",
              "9591  [-1.297, 0.00659, 0.1982, 0.6094, -1.625, -0.0...   \n",
              "9592  [-1.273, 0.0315, 0.1963, 0.5938, -1.609, -0.09...   \n",
              "9593  [-1.32, 0.013916, 0.2168, 0.5547, -1.609, -0.1...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.266, 0.5234, -0.1533, 0.7656, -1.531, -0.4...   \n",
              "1     [-1.234, 0.551, -0.1387, 0.7812, -1.5625, -0.4...   \n",
              "2     [-1.25, 0.539, -0.1484, 0.7734, -1.508, -0.453...   \n",
              "3     [-1.25, 0.539, -0.1621, 0.7734, -1.57, -0.4219...   \n",
              "4     [-1.242, 0.539, -0.168, 0.7773, -1.516, -0.429...   \n",
              "...                                                 ...   \n",
              "9589  [-1.273, 0.539, -0.1138, 0.789, -1.508, -0.445...   \n",
              "9590  [-1.273, 0.5703, -0.1318, 0.7383, -1.492, -0.4...   \n",
              "9591  [-1.25, 0.5195, -0.1562, 0.8047, -1.539, -0.43...   \n",
              "9592  [-1.227, 0.5586, -0.1514, 0.789, -1.531, -0.42...   \n",
              "9593  [-1.281, 0.5273, -0.1299, 0.7383, -1.531, -0.4...   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [-0.02148, 0.0713, 0.04883, 0.828, -1.625, -0....   \n",
              "1     [0.02344, 0.0879, 0.08203, 0.832, -1.648, -0.0...   \n",
              "2     [-0.007812, 0.08887, 0.05664, 0.832, -1.602, -...   \n",
              "3     [-0.00586, 0.0703, 0.06445, 0.832, -1.664, -0....   \n",
              "4     [0.001953, 0.0781, 0.03906, 0.84, -1.609, -0.0...   \n",
              "...                                                 ...   \n",
              "9589  [-0.02539, 0.08984, 0.0664, 0.8555, -1.609, -0...   \n",
              "9590  [-0.03516, 0.11523, 0.0801, 0.797, -1.586, -0....   \n",
              "9591  [0.001953, 0.05664, 0.05664, 0.8633, -1.641, -...   \n",
              "9592  [0.03125, 0.09766, 0.05664, 0.8555, -1.625, -0...   \n",
              "9593  [-0.05078, 0.05078, 0.0918, 0.793, -1.617, -0....   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.1602, -0.1504, -0.3926, 1.047, -1.93, 0.20...   \n",
              "1     [-0.12305, -0.1094, -0.371, 1.047, -1.945, 0.2...   \n",
              "2     [-0.1504, -0.11914, -0.4102, 1.039, -1.898, 0....   \n",
              "3     [-0.1504, -0.1406, -0.3828, 1.039, -1.953, 0.2...   \n",
              "4     [-0.1406, -0.1357, -0.418, 1.055, -1.898, 0.23...   \n",
              "...                                                 ...   \n",
              "9589  [-0.1816, -0.127, -0.3926, 1.078, -1.891, 0.19...   \n",
              "9590  [-0.1777, -0.10156, -0.3906, 1.0, -1.898, 0.20...   \n",
              "9591  [-0.1484, -0.1572, -0.3945, 1.078, -1.922, 0.2...   \n",
              "9592  [-0.1162, -0.0869, -0.4258, 1.078, -1.914, 0.1...   \n",
              "9593  [-0.1934, -0.1699, -0.3828, 1.008, -1.922, 0.2...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.504, -0.295, -0.9688, 0.4805, -1.68, 0.435...   \n",
              "1     [-0.4473, -0.2324, -0.953, 0.496, -1.727, 0.45...   \n",
              "2     [-0.4785, -0.2422, -1.0, 0.4922, -1.68, 0.3887...   \n",
              "3     [-0.4902, -0.2656, -0.961, 0.4844, -1.711, 0.4...   \n",
              "4     [-0.4922, -0.2793, -0.9766, 0.496, -1.641, 0.4...   \n",
              "...                                                 ...   \n",
              "9589  [-0.5234, -0.2676, -0.9883, 0.5234, -1.656, 0....   \n",
              "9590  [-0.5156, -0.2383, -0.965, 0.418, -1.633, 0.45...   \n",
              "9591  [-0.4785, -0.3008, -0.9375, 0.5156, -1.68, 0.4...   \n",
              "9592  [-0.4375, -0.2227, -0.9805, 0.508, -1.6875, 0....   \n",
              "9593  [-0.5273, -0.295, -0.9375, 0.4531, -1.656, 0.4...   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.406, -0.2129, -1.234, 0.3672, -2.094, 0.25...   \n",
              "1     [-1.289, -0.1777, -1.164, 0.3613, -2.125, 0.25...   \n",
              "2     [-1.32, -0.1436, -1.227, 0.33, -2.078, 0.1934,...   \n",
              "3     [-1.297, -0.1602, -1.211, 0.3691, -2.094, 0.19...   \n",
              "4     [-1.328, -0.1904, -1.227, 0.3398, -2.047, 0.22...   \n",
              "...                                                 ...   \n",
              "9589  [-1.406, -0.2188, -1.18, 0.3965, -2.047, 0.130...   \n",
              "9590  [-1.281, -0.125, -1.281, 0.3418, -2.016, 0.198...   \n",
              "9591  [-1.328, -0.2412, -1.148, 0.3906, -2.047, 0.23...   \n",
              "9592  [-1.3125, -0.165, -1.203, 0.3672, -2.062, 0.25...   \n",
              "9593  [-1.383, -0.1934, -1.164, 0.33, -2.047, 0.2031...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.5625, 0.254, -0.3555, 0.03516, -1.016, -0....   \n",
              "1     [-1.359, 0.291, -0.4023, 0.0, -1.094, -0.5156,...   \n",
              "2     [-1.406, 0.3418, -0.539, -0.04932, -1.094, -0....   \n",
              "3     [-1.406, 0.3184, -0.4336, 0.0603, -1.047, -0.5...   \n",
              "4     [-1.453, 0.371, -0.4844, 0.02979, -1.07, -0.58...   \n",
              "...                                                 ...   \n",
              "9589  [-1.453, 0.4414, -0.4336, 0.2207, -1.109, -0.7...   \n",
              "9590  [-1.352, 0.586, -0.414, 0.04175, -1.07, -0.494...   \n",
              "9591  [-1.406, 0.412, -0.3516, 0.002197, -1.094, -0....   \n",
              "9592  [-1.32, 0.377, -0.4023, 0.02563, -1.0625, -0.5...   \n",
              "9593  [-1.57, 0.336, -0.3125, -0.0674, -0.961, -0.65...   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [1.047, -6.406, 2.14, 1.734, -1.234, 0.504, -1...  \n",
              "1     [24.88, -3.531, -1.523, 0.871, -1.336, 0.4395,...  \n",
              "2     [23.62, -4.094, -1.164, 3.234, -0.3027, 2.297,...  \n",
              "3     [22.12, -3.922, -0.169, 3.047, -1.594, -0.2197...  \n",
              "4     [14.5, -2.625, -3.172, 1.953, -0.9375, 0.59, -...  \n",
              "...                                                 ...  \n",
              "9589  [4.875, -1.414, 3.906, -0.3906, -6.062, 0.6562...  \n",
              "9590  [-0.5977, 2.453, 4.22, -0.4238, -4.25, 1.898, ...  \n",
              "9591  [26.88, -0.02686, 3.016, -0.373, -1.672, 0.033...  \n",
              "9592  [22.5, -3.344, 0.754, 4.25, -0.2354, 1.969, -1...  \n",
              "9593  [20.62, -4.188, 4.0, 1.672, 0.2637, 0.2109, -2...  \n",
              "\n",
              "[9594 rows x 29 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>Somebody just left - guess who.</td>\n",
              "      <td>[1.543, -0.08734, -0.024, 0.1147, -0.2515, -1....</td>\n",
              "      <td>[-0.265, 0.1556, 0.02525, -0.1493, -0.1678, -0...</td>\n",
              "      <td>[-0.387, 0.1759, 0.2291, -0.3171, 0.0395, -0.2...</td>\n",
              "      <td>[-0.2842, -0.0357, 0.2566, -0.3528, 0.2996, -0...</td>\n",
              "      <td>[-0.1532, -0.2812, 0.11957, -0.313, 0.6445, -0...</td>\n",
              "      <td>[-0.00837, -0.3154, 0.4402, -0.06, 0.5654, -0....</td>\n",
              "      <td>[0.02539, -0.4048, 0.1914, -0.2825, 0.6177, -0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5234, 0.3867, 0.3223, 0.4922, -0.461, -0.1...</td>\n",
              "      <td>[-0.992, 0.5, -0.0381, 0.7773, -0.9062, -0.515...</td>\n",
              "      <td>[-1.32, 0.002441, 0.2051, 0.5703, -1.609, -0.1...</td>\n",
              "      <td>[-1.266, 0.5234, -0.1533, 0.7656, -1.531, -0.4...</td>\n",
              "      <td>[-0.02148, 0.0713, 0.04883, 0.828, -1.625, -0....</td>\n",
              "      <td>[-0.1602, -0.1504, -0.3926, 1.047, -1.93, 0.20...</td>\n",
              "      <td>[-0.504, -0.295, -0.9688, 0.4805, -1.68, 0.435...</td>\n",
              "      <td>[-1.406, -0.2129, -1.234, 0.3672, -2.094, 0.25...</td>\n",
              "      <td>[-1.5625, 0.254, -0.3555, 0.03516, -1.016, -0....</td>\n",
              "      <td>[1.047, -6.406, 2.14, 1.734, -1.234, 0.504, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They claimed they had settled on something, bu...</td>\n",
              "      <td>[1.201, -0.573, -0.413, 0.1304, -0.1552, -1.16...</td>\n",
              "      <td>[0.0206, -0.255, -0.1913, -0.1177, -0.2094, 0....</td>\n",
              "      <td>[0.0673, -0.1573, -0.1293, 0.0353, -0.1493, -0...</td>\n",
              "      <td>[0.00669, 0.01184, -0.1696, -0.1421, -0.1792, ...</td>\n",
              "      <td>[-0.0663, -0.4077, -0.1447, -0.1183, 0.0848, 0...</td>\n",
              "      <td>[0.10596, -0.09106, -0.368, 0.1038, -0.11304, ...</td>\n",
              "      <td>[0.2954, -0.1733, -0.423, 0.5835, 0.1013, -0.0...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4902, 0.3906, 0.332, 0.5195, -0.4727, -0.0...</td>\n",
              "      <td>[-0.9453, 0.5234, -0.02759, 0.8047, -0.9414, -...</td>\n",
              "      <td>[-1.281, 0.03735, 0.2109, 0.59, -1.641, -0.078...</td>\n",
              "      <td>[-1.234, 0.551, -0.1387, 0.7812, -1.5625, -0.4...</td>\n",
              "      <td>[0.02344, 0.0879, 0.08203, 0.832, -1.648, -0.0...</td>\n",
              "      <td>[-0.12305, -0.1094, -0.371, 1.047, -1.945, 0.2...</td>\n",
              "      <td>[-0.4473, -0.2324, -0.953, 0.496, -1.727, 0.45...</td>\n",
              "      <td>[-1.289, -0.1777, -1.164, 0.3613, -2.125, 0.25...</td>\n",
              "      <td>[-1.359, 0.291, -0.4023, 0.0, -1.094, -0.5156,...</td>\n",
              "      <td>[24.88, -3.531, -1.523, 0.871, -1.336, 0.4395,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>If Sam was going, Sally would know where.</td>\n",
              "      <td>[1.43, -0.1954, 0.007423, 0.3733, 0.3796, -1.2...</td>\n",
              "      <td>[0.2377, -0.06525, -0.3958, -0.341, 0.2098, 0....</td>\n",
              "      <td>[0.0459, -0.1997, -0.1178, -0.1616, 0.113, 0.1...</td>\n",
              "      <td>[0.0084, 0.1638, -0.4126, -0.05673, 0.1422, 0....</td>\n",
              "      <td>[0.1656, -0.02551, -0.3247, 0.02852, 0.629, 0....</td>\n",
              "      <td>[0.2053, -0.10443, -0.010056, -0.0814, 0.1656,...</td>\n",
              "      <td>[0.5176, -0.1411, -0.2083, -0.157, 0.104, 0.34...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.504, 0.3984, 0.3066, 0.5156, -0.4414, -0.1...</td>\n",
              "      <td>[-0.965, 0.508, -0.05298, 0.801, -0.9023, -0.5...</td>\n",
              "      <td>[-1.305, 0.01855, 0.2002, 0.582, -1.586, -0.11...</td>\n",
              "      <td>[-1.25, 0.539, -0.1484, 0.7734, -1.508, -0.453...</td>\n",
              "      <td>[-0.007812, 0.08887, 0.05664, 0.832, -1.602, -...</td>\n",
              "      <td>[-0.1504, -0.11914, -0.4102, 1.039, -1.898, 0....</td>\n",
              "      <td>[-0.4785, -0.2422, -1.0, 0.4922, -1.68, 0.3887...</td>\n",
              "      <td>[-1.32, -0.1436, -1.227, 0.33, -2.078, 0.1934,...</td>\n",
              "      <td>[-1.406, 0.3418, -0.539, -0.04932, -1.094, -0....</td>\n",
              "      <td>[23.62, -4.094, -1.164, 3.234, -0.3027, 2.297,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>They're going to serve the guests something, b...</td>\n",
              "      <td>[1.231, -0.0665, -0.411, 0.276, 0.1493, -1.48,...</td>\n",
              "      <td>[-0.02309, 0.1294, -0.3066, -0.2405, -0.01993,...</td>\n",
              "      <td>[-0.188, -0.1611, -0.1403, -0.1069, -0.0785, -...</td>\n",
              "      <td>[-0.2786, -0.01884, -0.2546, -0.2042, 0.03607,...</td>\n",
              "      <td>[-0.436, -0.4165, -0.449, -0.6597, 0.2482, -0....</td>\n",
              "      <td>[-0.0707, -0.3406, -0.1775, -0.2096, 0.1655, -...</td>\n",
              "      <td>[0.0828, -0.3928, -0.514, -0.2213, 0.1182, 0.1...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4902, 0.3926, 0.3145, 0.5273, -0.4922, -0....</td>\n",
              "      <td>[-0.961, 0.5234, -0.04102, 0.801, -0.957, -0.4...</td>\n",
              "      <td>[-1.297, 0.0332, 0.2002, 0.582, -1.656, -0.082...</td>\n",
              "      <td>[-1.25, 0.539, -0.1621, 0.7734, -1.57, -0.4219...</td>\n",
              "      <td>[-0.00586, 0.0703, 0.06445, 0.832, -1.664, -0....</td>\n",
              "      <td>[-0.1504, -0.1406, -0.3828, 1.039, -1.953, 0.2...</td>\n",
              "      <td>[-0.4902, -0.2656, -0.961, 0.4844, -1.711, 0.4...</td>\n",
              "      <td>[-1.297, -0.1602, -1.211, 0.3691, -2.094, 0.19...</td>\n",
              "      <td>[-1.406, 0.3184, -0.4336, 0.0603, -1.047, -0.5...</td>\n",
              "      <td>[22.12, -3.922, -0.169, 3.047, -1.594, -0.2197...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>out_of_domain_dev</td>\n",
              "      <td>1</td>\n",
              "      <td>She's reading. I can't imagine what.</td>\n",
              "      <td>[1.5, 0.2157, -0.2211, 0.828, -0.1641, -1.477,...</td>\n",
              "      <td>[0.08307, 0.3298, -0.3032, -0.1846, -0.2866, 0...</td>\n",
              "      <td>[-0.744, -0.1349, -0.1515, -0.1368, -0.1705, -...</td>\n",
              "      <td>[-0.3816, -0.1418, -0.539, -0.2898, -0.1924, -...</td>\n",
              "      <td>[-0.0725, -0.02075, -0.4688, -0.4436, -0.107, ...</td>\n",
              "      <td>[-0.03726, -0.2256, -0.171, -0.3992, -0.1259, ...</td>\n",
              "      <td>[0.1411, -0.566, -0.3948, -0.4534, 0.0, -0.432...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4746, 0.3965, 0.3027, 0.5117, -0.4492, -0....</td>\n",
              "      <td>[-0.949, 0.5156, -0.05884, 0.797, -0.8984, -0....</td>\n",
              "      <td>[-1.281, 0.01904, 0.1846, 0.586, -1.594, -0.08...</td>\n",
              "      <td>[-1.242, 0.539, -0.168, 0.7773, -1.516, -0.429...</td>\n",
              "      <td>[0.001953, 0.0781, 0.03906, 0.84, -1.609, -0.0...</td>\n",
              "      <td>[-0.1406, -0.1357, -0.418, 1.055, -1.898, 0.23...</td>\n",
              "      <td>[-0.4922, -0.2793, -0.9766, 0.496, -1.641, 0.4...</td>\n",
              "      <td>[-1.328, -0.1904, -1.227, 0.3398, -2.047, 0.22...</td>\n",
              "      <td>[-1.453, 0.371, -0.4844, 0.02979, -1.07, -0.58...</td>\n",
              "      <td>[14.5, -2.625, -3.172, 1.953, -0.9375, 0.59, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9589</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Poseidon appears to own a dragon</td>\n",
              "      <td>[2.41, -0.2069, -0.4119, -0.793, 0.2042, -0.42...</td>\n",
              "      <td>[-0.3777, 0.1925, -0.375, -0.761, -0.113, 0.47...</td>\n",
              "      <td>[-0.1881, -0.2703, -0.341, -0.751, -0.2664, 0....</td>\n",
              "      <td>[-0.252, -0.2686, -0.5884, -0.2249, -0.1462, 0...</td>\n",
              "      <td>[-0.1239, -0.0907, -0.487, -0.2754, 0.1967, 0....</td>\n",
              "      <td>[-0.04214, -0.3657, -0.1698, -0.1923, -0.2668,...</td>\n",
              "      <td>[0.385, -0.8438, -1.05, -0.2634, -0.4995, 0.03...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5273, 0.4219, 0.3516, 0.5195, -0.4395, -0....</td>\n",
              "      <td>[-0.996, 0.5312, -0.01001, 0.8047, -0.8984, -0...</td>\n",
              "      <td>[-1.32, 0.02148, 0.2344, 0.5938, -1.586, -0.10...</td>\n",
              "      <td>[-1.273, 0.539, -0.1138, 0.789, -1.508, -0.445...</td>\n",
              "      <td>[-0.02539, 0.08984, 0.0664, 0.8555, -1.609, -0...</td>\n",
              "      <td>[-0.1816, -0.127, -0.3926, 1.078, -1.891, 0.19...</td>\n",
              "      <td>[-0.5234, -0.2676, -0.9883, 0.5234, -1.656, 0....</td>\n",
              "      <td>[-1.406, -0.2188, -1.18, 0.3965, -2.047, 0.130...</td>\n",
              "      <td>[-1.453, 0.4414, -0.4336, 0.2207, -1.109, -0.7...</td>\n",
              "      <td>[4.875, -1.414, 3.906, -0.3906, -6.062, 0.6562...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9590</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>0</td>\n",
              "      <td>Digitize is my happiest memory</td>\n",
              "      <td>[2.676, -1.304, -0.006836, -0.6055, -0.639, 0....</td>\n",
              "      <td>[-0.3313, -0.4558, 0.1572, -0.577, -0.5938, 0....</td>\n",
              "      <td>[-0.4055, -0.369, 0.07355, -0.7974, -0.4011, 0...</td>\n",
              "      <td>[-0.4275, -0.638, -0.1849, -0.4626, -0.295, -0...</td>\n",
              "      <td>[-0.0713, -0.2063, -0.1722, -0.5483, 0.3357, -...</td>\n",
              "      <td>[-0.291, -0.1732, -0.1553, -0.4548, -0.01172, ...</td>\n",
              "      <td>[-0.77, -0.6396, -0.966, -0.595, -0.257, -0.08...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5234, 0.418, 0.336, 0.4727, -0.4062, -0.08...</td>\n",
              "      <td>[-0.9727, 0.5312, -0.02783, 0.75, -0.8594, -0....</td>\n",
              "      <td>[-1.3125, 0.04077, 0.2139, 0.547, -1.5625, -0....</td>\n",
              "      <td>[-1.273, 0.5703, -0.1318, 0.7383, -1.492, -0.4...</td>\n",
              "      <td>[-0.03516, 0.11523, 0.0801, 0.797, -1.586, -0....</td>\n",
              "      <td>[-0.1777, -0.10156, -0.3906, 1.0, -1.898, 0.20...</td>\n",
              "      <td>[-0.5156, -0.2383, -0.965, 0.418, -1.633, 0.45...</td>\n",
              "      <td>[-1.281, -0.125, -1.281, 0.3418, -2.016, 0.198...</td>\n",
              "      <td>[-1.352, 0.586, -0.414, 0.04175, -1.07, -0.494...</td>\n",
              "      <td>[-0.5977, 2.453, 4.22, -0.4238, -4.25, 1.898, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9591</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>It is easy to slay the Gorgon.</td>\n",
              "      <td>[1.982, 0.01598, -0.4011, 0.43, -0.1137, -1.35...</td>\n",
              "      <td>[-0.12024, 0.5874, -0.4888, -0.4724, -0.05115,...</td>\n",
              "      <td>[-0.4553, 0.3398, -0.1569, -0.408, 0.1606, -0....</td>\n",
              "      <td>[-0.3916, 0.3433, -0.3652, -0.2437, 0.4111, -0...</td>\n",
              "      <td>[-0.2272, 0.3071, -0.436, -0.3667, 0.318, -0.3...</td>\n",
              "      <td>[-0.2493, -0.04926, 0.1603, -0.2169, 0.2942, -...</td>\n",
              "      <td>[-0.151, -0.46, -0.08856, -0.563, 0.25, -0.063...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.504, 0.3984, 0.3223, 0.5195, -0.4648, -0.1...</td>\n",
              "      <td>[-0.961, 0.5117, -0.04102, 0.8086, -0.9336, -0...</td>\n",
              "      <td>[-1.297, 0.00659, 0.1982, 0.6094, -1.625, -0.0...</td>\n",
              "      <td>[-1.25, 0.5195, -0.1562, 0.8047, -1.539, -0.43...</td>\n",
              "      <td>[0.001953, 0.05664, 0.05664, 0.8633, -1.641, -...</td>\n",
              "      <td>[-0.1484, -0.1572, -0.3945, 1.078, -1.922, 0.2...</td>\n",
              "      <td>[-0.4785, -0.3008, -0.9375, 0.5156, -1.68, 0.4...</td>\n",
              "      <td>[-1.328, -0.2412, -1.148, 0.3906, -2.047, 0.23...</td>\n",
              "      <td>[-1.406, 0.412, -0.3516, 0.002197, -1.094, -0....</td>\n",
              "      <td>[26.88, -0.02686, 3.016, -0.373, -1.672, 0.033...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9592</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>I had the strangest feeling that I knew you.</td>\n",
              "      <td>[1.13, -0.548, -0.1625, 0.2316, -0.1013, -0.89...</td>\n",
              "      <td>[-0.1342, -0.18, -0.0806, -0.03497, -0.1707, 0...</td>\n",
              "      <td>[-0.2864, -0.2461, 0.1464, -0.02335, 0.00596, ...</td>\n",
              "      <td>[0.0864, -0.2683, -0.0796, -0.03085, 0.3008, 0...</td>\n",
              "      <td>[0.05167, -0.1395, 0.0824, 0.1548, 0.1958, 0.1...</td>\n",
              "      <td>[0.3828, -0.2274, -0.0697, -0.02011, 0.0667, -...</td>\n",
              "      <td>[0.1918, -0.903, 0.2683, -0.10126, 0.1006, 0.2...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4922, 0.4102, 0.3184, 0.5234, -0.4531, -0....</td>\n",
              "      <td>[-0.9453, 0.5312, -0.04565, 0.8086, -0.91, -0....</td>\n",
              "      <td>[-1.273, 0.0315, 0.1963, 0.5938, -1.609, -0.09...</td>\n",
              "      <td>[-1.227, 0.5586, -0.1514, 0.789, -1.531, -0.42...</td>\n",
              "      <td>[0.03125, 0.09766, 0.05664, 0.8555, -1.625, -0...</td>\n",
              "      <td>[-0.1162, -0.0869, -0.4258, 1.078, -1.914, 0.1...</td>\n",
              "      <td>[-0.4375, -0.2227, -0.9805, 0.508, -1.6875, 0....</td>\n",
              "      <td>[-1.3125, -0.165, -1.203, 0.3672, -2.062, 0.25...</td>\n",
              "      <td>[-1.32, 0.377, -0.4023, 0.02563, -1.0625, -0.5...</td>\n",
              "      <td>[22.5, -3.344, 0.754, 4.25, -0.2354, 1.969, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9593</th>\n",
              "      <td>in_domain_train</td>\n",
              "      <td>1</td>\n",
              "      <td>What all did you get for Christmas?</td>\n",
              "      <td>[1.306, -0.9287, -0.1448, 0.202, -0.2656, -0.9...</td>\n",
              "      <td>[0.1018, -0.1641, -0.1702, -0.481, -0.5264, 0....</td>\n",
              "      <td>[-0.01746, -0.3806, -0.3396, -0.2024, -0.3918,...</td>\n",
              "      <td>[0.4673, -0.794, -0.4458, 0.04102, -0.1653, -0...</td>\n",
              "      <td>[0.3572, -1.043, 0.3853, 0.09106, 0.10547, 0.3...</td>\n",
              "      <td>[0.6987, -0.689, 0.1849, -0.2367, -0.352, 0.19...</td>\n",
              "      <td>[0.687, -1.275, 0.4153, -0.5107, -0.1318, 0.08...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3691, 0.3262, 0.4883, -0.4453, -0.112...</td>\n",
              "      <td>[-0.9805, 0.504, -0.03906, 0.7812, -0.91, -0.5...</td>\n",
              "      <td>[-1.32, 0.013916, 0.2168, 0.5547, -1.609, -0.1...</td>\n",
              "      <td>[-1.281, 0.5273, -0.1299, 0.7383, -1.531, -0.4...</td>\n",
              "      <td>[-0.05078, 0.05078, 0.0918, 0.793, -1.617, -0....</td>\n",
              "      <td>[-0.1934, -0.1699, -0.3828, 1.008, -1.922, 0.2...</td>\n",
              "      <td>[-0.5273, -0.295, -0.9375, 0.4531, -1.656, 0.4...</td>\n",
              "      <td>[-1.383, -0.1934, -1.164, 0.33, -2.047, 0.2031...</td>\n",
              "      <td>[-1.57, 0.336, -0.3125, -0.0674, -0.961, -0.65...</td>\n",
              "      <td>[20.62, -4.188, 4.0, 1.672, 0.2637, 0.2109, -2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9594 rows × 29 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "activation_cola_df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "activation_cola_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCH6zRgvmpcx"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3PVCeFPRquJJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "text_column = 'sentence'\n",
        "\n",
        "activation_cola_df_2b = extract_activations_df(cola_df, model_2b, tokenizer_2b, text_column, BATCH_SIZE)\n",
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GbcWA0pr1ZF"
      },
      "outputs": [],
      "source": [
        "save_activations_df(activation_cola_df_2b, 'cola', model_id_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v1QYQnRrq6fz"
      },
      "outputs": [],
      "source": [
        "activation_cola_df_2b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoT3PwO9q9Of"
      },
      "source": [
        "## UD_English-EWT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "NW-Jc9bqrArz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d6cdc1-7d3e-49b9-e23e-a537960748c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "--2025-11-26 11:50:15--  https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/refs/heads/master/en_ewt-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15029817 (14M) [text/plain]\n",
            "Saving to: ‘en_ewt-ud-train.conllu.1’\n",
            "\n",
            "en_ewt-ud-train.con 100%[===================>]  14.33M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-11-26 11:50:15 (214 MB/s) - ‘en_ewt-ud-train.conllu.1’ saved [15029817/15029817]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/refs/heads/master/en_ewt-ud-train.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K_tTkqzWvUnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec3e29c-5c2b-4194-b8ce-4922443eda01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parsing conllu: 12544it [00:13, 942.13it/s]\n",
            "Converting to DataFrame: 100%|██████████| 12544/12544 [00:00<00:00, 234414.29it/s]\n"
          ]
        }
      ],
      "source": [
        "from conllu import parse_incr\n",
        "\n",
        "def load_conllu(path):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for tokenlist in tqdm(parse_incr(f), desc='Parsing conllu'):\n",
        "            yield {\n",
        "                \"text\": tokenlist.metadata.get(\"text\", \"\"),\n",
        "                \"tokens\": [t[\"form\"] for t in tokenlist],\n",
        "                \"token_id\": [t[\"id\"] for t in tokenlist],\n",
        "                \"upos\": [t[\"upostag\"] for t in tokenlist],\n",
        "                #\"xpos\": [t[\"xpostag\"] for t in tokenlist],\n",
        "            }\n",
        "\n",
        "train = list(load_conllu(\"en_ewt-ud-train.conllu\"))\n",
        "\n",
        "items_to_df = {k:[] for k in train[0].keys()}\n",
        "\n",
        "for item in tqdm(train, desc='Converting to DataFrame'):\n",
        "  for k, v in item.items():\n",
        "    items_to_df[k].append(v)\n",
        "\n",
        "ewt_df = pd.DataFrame(items_to_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "1oKlVx5WvVvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "a89df0e7-a804-40b7-f6dd-eac82cb8956c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0      Al-Zaman : American forces killed Shaikh Abdul...   \n",
              "1      [This killing of a respected cleric will be ca...   \n",
              "2      DPA: Iraqi authorities announced that they had...   \n",
              "3      Two of them were being run by 2 officials of t...   \n",
              "4      The MoI in Iraq is equivalent to the US FBI, s...   \n",
              "...                                                  ...   \n",
              "12539  Of course, they couldn't call him either to as...   \n",
              "12540  On Monday I called and again it was a big to-d...   \n",
              "12541  Supposedly they will be holding it for me this...   \n",
              "12542  The employees at this Sear's are completely ap...   \n",
              "12543  I will never return there again (and now have ...   \n",
              "\n",
              "                                                  tokens  \\\n",
              "0      [Al, -, Zaman, :, American, forces, killed, Sh...   \n",
              "1      [[, This, killing, of, a, respected, cleric, w...   \n",
              "2      [DPA, :, Iraqi, authorities, announced, that, ...   \n",
              "3      [Two, of, them, were, being, run, by, 2, offic...   \n",
              "4      [The, MoI, in, Iraq, is, equivalent, to, the, ...   \n",
              "...                                                  ...   \n",
              "12539  [Of, course, ,, they, couldn't, could, n't, ca...   \n",
              "12540  [On, Monday, I, called, and, again, it, was, a...   \n",
              "12541  [Supposedly, they, will, be, holding, it, for,...   \n",
              "12542  [The, employees, at, this, Sear's, are, comple...   \n",
              "12543  [I, will, never, return, there, again, (, and,...   \n",
              "\n",
              "                                                token_id  \\\n",
              "0      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "2      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "3      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "4      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "...                                                  ...   \n",
              "12539  [1, 2, 3, 4, (5, -, 6), 5, 6, 7, 8, 9, 10, 11,...   \n",
              "12540  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "12541  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, (13, -...   \n",
              "12542  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, (11, -, 12), 1...   \n",
              "12543  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "\n",
              "                                                    upos  \n",
              "0      [PROPN, PUNCT, PROPN, PUNCT, ADJ, NOUN, VERB, ...  \n",
              "1      [PUNCT, DET, NOUN, ADP, DET, ADJ, NOUN, AUX, A...  \n",
              "2      [PROPN, PUNCT, ADJ, NOUN, VERB, SCONJ, PRON, A...  \n",
              "3      [NUM, ADP, PRON, AUX, AUX, VERB, ADP, NUM, NOU...  \n",
              "4      [DET, PROPN, ADP, PROPN, AUX, ADJ, ADP, DET, P...  \n",
              "...                                                  ...  \n",
              "12539  [ADP, NOUN, PUNCT, PRON, _, AUX, PART, VERB, P...  \n",
              "12540  [ADP, PROPN, PRON, VERB, CCONJ, ADV, PRON, AUX...  \n",
              "12541  [ADV, PRON, AUX, AUX, VERB, PRON, ADP, PRON, D...  \n",
              "12542  [DET, NOUN, ADP, DET, PROPN, AUX, ADV, ADJ, CC...  \n",
              "12543  [PRON, AUX, ADV, VERB, ADV, ADV, PUNCT, CCONJ,...  \n",
              "\n",
              "[12544 rows x 4 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>token_id</th>\n",
              "      <th>upos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al-Zaman : American forces killed Shaikh Abdul...</td>\n",
              "      <td>[Al, -, Zaman, :, American, forces, killed, Sh...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PROPN, PUNCT, PROPN, PUNCT, ADJ, NOUN, VERB, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[This killing of a respected cleric will be ca...</td>\n",
              "      <td>[[, This, killing, of, a, respected, cleric, w...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PUNCT, DET, NOUN, ADP, DET, ADJ, NOUN, AUX, A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DPA: Iraqi authorities announced that they had...</td>\n",
              "      <td>[DPA, :, Iraqi, authorities, announced, that, ...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PROPN, PUNCT, ADJ, NOUN, VERB, SCONJ, PRON, A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two of them were being run by 2 officials of t...</td>\n",
              "      <td>[Two, of, them, were, being, run, by, 2, offic...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[NUM, ADP, PRON, AUX, AUX, VERB, ADP, NUM, NOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The MoI in Iraq is equivalent to the US FBI, s...</td>\n",
              "      <td>[The, MoI, in, Iraq, is, equivalent, to, the, ...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[DET, PROPN, ADP, PROPN, AUX, ADJ, ADP, DET, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12539</th>\n",
              "      <td>Of course, they couldn't call him either to as...</td>\n",
              "      <td>[Of, course, ,, they, couldn't, could, n't, ca...</td>\n",
              "      <td>[1, 2, 3, 4, (5, -, 6), 5, 6, 7, 8, 9, 10, 11,...</td>\n",
              "      <td>[ADP, NOUN, PUNCT, PRON, _, AUX, PART, VERB, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12540</th>\n",
              "      <td>On Monday I called and again it was a big to-d...</td>\n",
              "      <td>[On, Monday, I, called, and, again, it, was, a...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[ADP, PROPN, PRON, VERB, CCONJ, ADV, PRON, AUX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12541</th>\n",
              "      <td>Supposedly they will be holding it for me this...</td>\n",
              "      <td>[Supposedly, they, will, be, holding, it, for,...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, (13, -...</td>\n",
              "      <td>[ADV, PRON, AUX, AUX, VERB, PRON, ADP, PRON, D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12542</th>\n",
              "      <td>The employees at this Sear's are completely ap...</td>\n",
              "      <td>[The, employees, at, this, Sear's, are, comple...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, (11, -, 12), 1...</td>\n",
              "      <td>[DET, NOUN, ADP, DET, PROPN, AUX, ADV, ADJ, CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12543</th>\n",
              "      <td>I will never return there again (and now have ...</td>\n",
              "      <td>[I, will, never, return, there, again, (, and,...</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[PRON, AUX, ADV, VERB, ADV, ADV, PUNCT, CCONJ,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12544 rows × 4 columns</p>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ewt_df",
              "summary": "{\n  \"name\": \"ewt_df\",\n  \"rows\": 12544,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11735,\n        \"samples\": [\n          \"I was moving out from 2 bdr apartment and it took for 3 strong guys 6 hours to load a track (from 2pm-8pm).\",\n          \"I've also considered becoming a teacher, but it's not a job I'm cut out for.\",\n          \"However, if you use a particular logo for the on-line service, that should be registered.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11734,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10386,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zofmGBIYr27l"
      },
      "source": [
        "here we have 2 pos taggings upos (more general) and xpos (more specific).\n",
        "we will consider the upos for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcUn9Q030X33"
      },
      "source": [
        "now we define a function to convert the ewt dataset to a token version where the upos and xpos are more clear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rufmBVMUy1Iz"
      },
      "outputs": [],
      "source": [
        "def convert_ewt_to_token(ewt_df):\n",
        "  token_ewt_dict = {\n",
        "      'words': [],\n",
        "      'sentence_id': [],\n",
        "      'upos': [],\n",
        "      'token_id':[]\n",
        "      #'xpos': [],\n",
        "  }\n",
        "\n",
        "  for row in ewt_df.iterrows():\n",
        "    for token, upos, token_id in zip(row[1]['tokens'], row[1]['upos'], row[1]['token_id']):\n",
        "      if isinstance(token_id, int):\n",
        "        token_ewt_dict['words'].append(token)\n",
        "        token_ewt_dict['sentence_id'].append(row[0])\n",
        "        token_ewt_dict['upos'].append(upos)\n",
        "        token_ewt_dict['token_id'].append(token_id)\n",
        "        #token_ewt_dict['xpos'].append(xpos)\n",
        "\n",
        "  return pd.DataFrame(token_ewt_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "bLtu7mX70qX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "350382a6-c9d2-40db-c2ea-d6d377eb5787"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           words  sentence_id   upos  token_id\n",
              "0             Al            0  PROPN         1\n",
              "1              -            0  PUNCT         2\n",
              "2          Zaman            0  PROPN         3\n",
              "3              :            0  PUNCT         4\n",
              "4       American            0    ADJ         5\n",
              "...          ...          ...    ...       ...\n",
              "204572        on        12543    ADP        22\n",
              "204573        my        12543   PRON        23\n",
              "204574       car        12543   NOUN        24\n",
              "204575         )        12543  PUNCT        25\n",
              "204576         .        12543  PUNCT        26\n",
              "\n",
              "[204577 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d189bd58-b719-40a5-bada-4eb6147f43eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos</th>\n",
              "      <th>token_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204572</th>\n",
              "      <td>on</td>\n",
              "      <td>12543</td>\n",
              "      <td>ADP</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204573</th>\n",
              "      <td>my</td>\n",
              "      <td>12543</td>\n",
              "      <td>PRON</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204574</th>\n",
              "      <td>car</td>\n",
              "      <td>12543</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204575</th>\n",
              "      <td>)</td>\n",
              "      <td>12543</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204576</th>\n",
              "      <td>.</td>\n",
              "      <td>12543</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>204577 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d189bd58-b719-40a5-bada-4eb6147f43eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d189bd58-b719-40a5-bada-4eb6147f43eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d189bd58-b719-40a5-bada-4eb6147f43eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9cc54d15-9e99-4b44-a180-91a112724a83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cc54d15-9e99-4b44-a180-91a112724a83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9cc54d15-9e99-4b44-a180-91a112724a83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3e9ca5e2-1980-4254-982f-fae874215e05\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('token_ewt_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3e9ca5e2-1980-4254-982f-fae874215e05 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('token_ewt_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "token_ewt_df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "token_ewt_df = convert_ewt_to_token(ewt_df)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is a huge dimension dataset, we want to keep things fair with other datasets, that's why we will keep just 600 sentences"
      ],
      "metadata": {
        "id": "cgl-w9BWCEJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_senteces = 600 #int(len(ewt_df)/(len(token_ewt_df)/len(ewt_df)))\n",
        "\n",
        "token_ewt_df = convert_ewt_to_token(ewt_df[:number_of_senteces])\n",
        "token_ewt_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "k5qozJTMCmob",
        "outputId": "a796598f-aef3-41dd-8bfd-b0fbee0196a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          words  sentence_id   upos  token_id\n",
              "0            Al            0  PROPN         1\n",
              "1             -            0  PUNCT         2\n",
              "2         Zaman            0  PROPN         3\n",
              "3             :            0  PUNCT         4\n",
              "4      American            0    ADJ         5\n",
              "...         ...          ...    ...       ...\n",
              "13704        at          599    ADP        12\n",
              "13705       sea          599   NOUN        13\n",
              "13706        to          599    ADP        14\n",
              "13707   Horizon          599  PROPN        15\n",
              "13708         .          599  PUNCT        16\n",
              "\n",
              "[13709 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3f5d52b-e489-4d0a-82c1-276fd1cc9718\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos</th>\n",
              "      <th>token_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13704</th>\n",
              "      <td>at</td>\n",
              "      <td>599</td>\n",
              "      <td>ADP</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13705</th>\n",
              "      <td>sea</td>\n",
              "      <td>599</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13706</th>\n",
              "      <td>to</td>\n",
              "      <td>599</td>\n",
              "      <td>ADP</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13707</th>\n",
              "      <td>Horizon</td>\n",
              "      <td>599</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13708</th>\n",
              "      <td>.</td>\n",
              "      <td>599</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13709 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3f5d52b-e489-4d0a-82c1-276fd1cc9718')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3f5d52b-e489-4d0a-82c1-276fd1cc9718 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3f5d52b-e489-4d0a-82c1-276fd1cc9718');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d88ae212-0da6-4a62-a13d-9a972235557c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d88ae212-0da6-4a62-a13d-9a972235557c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d88ae212-0da6-4a62-a13d-9a972235557c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f0226f5e-af81-45bd-8079-7a6386de38ec\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('token_ewt_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0226f5e-af81-45bd-8079-7a6386de38ec button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('token_ewt_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "token_ewt_df",
              "summary": "{\n  \"name\": \"token_ewt_df\",\n  \"rows\": 13709,\n  \"fields\": [\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3439,\n        \"samples\": [\n          \"Secular\",\n          \"Comex\",\n          \"http://www.nsrl.ttu.edu/chernobyl/wildlifepreserve.htm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170,\n        \"min\": 0,\n        \"max\": 599,\n        \"num_unique_values\": 600,\n        \"samples\": [\n          110,\n          419,\n          565\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"PROPN\",\n          \"PUNCT\",\n          \"DET\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 1,\n        \"max\": 76,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          5,\n          36,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dE9O8Wc9WNC"
      },
      "source": [
        "there is a problem of subtokenization, we will use the word_ids provided by the tokenizer and send to it the sentence divided into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qpoil2Sv59Ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5214f13e-1074-4407-f0ad-c6d97ae2afc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking sentences: 100%|██████████| 600/600 [00:01<00:00, 558.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Problematic sentences: 0 (0.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_sentences = token_ewt_df['sentence_id'].nunique()\n",
        "c = 0\n",
        "problematic_indexes = []\n",
        "\n",
        "for index in tqdm(range(num_sentences), desc='Checking sentences'):\n",
        "  words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "  inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "  word_ids = inputs.word_ids()\n",
        "\n",
        "  tokens = tokenizer_b.convert_ids_to_tokens(inputs.input_ids[0])\n",
        "\n",
        "  control = []\n",
        "  for word_idx in range(len(words)):\n",
        "    token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "\n",
        "    if not token_indices: # escape case (should not happen but who knows ...)\n",
        "        continue\n",
        "\n",
        "    subwords = [tokens[i] for i in token_indices]\n",
        "    reconstructed_word = ''.join(subwords)\n",
        "    control.append(reconstructed_word)\n",
        "\n",
        "  if control != words:\n",
        "    c = c+1 # c is the number of sentences where the subtoken aggregation differs from the 'dataset' tokenization\n",
        "    problematic_indexes.append(index) # sentence to be removed later\n",
        "\n",
        "assert(len(problematic_indexes)==c)\n",
        "print(f'\\nProblematic sentences: {c} ({c/(num_sentences)*100:.2f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k41uxGH-9MUl"
      },
      "source": [
        "it works prefectly with all the sentences in the dataset!\n",
        "\n",
        "now let's try to get the word representations at a fixed layer for a fixed sentence: if a token corresponds to a word we will use the representation of the token as the representation of the word, if more token corresponds to a word (we know that thanks to the word_ids) we will calculate the mean (as done previously) to get the word representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtEFSwby4yp4"
      },
      "outputs": [],
      "source": [
        "index = 2\n",
        "layer = 0\n",
        "\n",
        "words = token_ewt_df[token_ewt_df['sentence_id'] == index]['words'].tolist()\n",
        "inputs = tokenizer_b(words, return_tensors=\"pt\", is_split_into_words=True).to(model_b.device)\n",
        "\n",
        "model_b.eval()\n",
        "start_token_id = tokenizer_b.bos_token_id\n",
        "decoder_input_ids = torch.tensor([[start_token_id]], device=model_b.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model_b(**inputs,decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "encoder_hidden_states = outputs.encoder_hidden_states[layer].squeeze(0)\n",
        "\n",
        "word_ids = inputs.word_ids()\n",
        "\n",
        "token_representation = []\n",
        "\n",
        "for word_idx in range(len(words)):\n",
        "  token_indices = [i for i, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "  relevant_vectors = encoder_hidden_states[token_indices] # getting the correspondent hidden states\n",
        "  mean_vector = torch.mean(relevant_vectors, dim=0)\n",
        "  token_representation.append(mean_vector.cpu())\n",
        "\n",
        "print(f\"Original words in the sentence: {len(words)}\")\n",
        "print(f\"Tensor obtained: {len(token_representation)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0E7jX8S-Lgi"
      },
      "source": [
        "now let's put all together into a function to process the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gs-Y2yyoDSSB"
      },
      "outputs": [],
      "source": [
        "def get_word_representation_df(model, tokenizer, df, batch_size=1):\n",
        "    sentences_words = df.groupby('sentence_id', sort=False)['words'].apply(list).tolist()\n",
        "    num_encoder_layers = model.config.encoder.num_hidden_layers + 1\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    word_representation_dict = {f'encoder_layer_{e+1}': [] for e in range(num_encoder_layers)}\n",
        "\n",
        "    for i in tqdm(range(0, len(sentences_words), batch_size), desc='Processing batches'):\n",
        "        batch_words = sentences_words[i : i + batch_size]\n",
        "        inputs = tokenizer(batch_words, return_tensors=\"pt\", padding=True, is_split_into_words=True, truncation=False).to(device)\n",
        "\n",
        "        current_batch_size = inputs.input_ids.shape[0]\n",
        "        start_token_id = tokenizer.bos_token_id\n",
        "        decoder_input_ids = torch.full((current_batch_size, 1), start_token_id, device=device, dtype=int) # [batch_size, 1 (<bos>)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, decoder_input_ids=decoder_input_ids,output_hidden_states=True)\n",
        "\n",
        "        all_layers_hidden_states = torch.stack(outputs.encoder_hidden_states) # [num_layers, batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # before iterating over batch sentences to calculate word_ids once\n",
        "        for b_idx in range(current_batch_size):\n",
        "            word_ids = inputs.word_ids(batch_index=b_idx)\n",
        "            num_original_words = len(batch_words[b_idx])\n",
        "\n",
        "            sentence_states = all_layers_hidden_states[:, b_idx, :, :] # [num_layers, seq_len, hidden_dim]\n",
        "\n",
        "            # later iterating over words\n",
        "            for word_idx in range(num_original_words):\n",
        "                token_indices = [k for k, w_id in enumerate(word_ids) if w_id == word_idx]\n",
        "                relevant_vectors = sentence_states[:, token_indices, :] # [num_layers, num_subtokens (possibily 1), hidden_dim]\n",
        "                mean_vectors = torch.mean(relevant_vectors, dim=1)\n",
        "                mean_vectors_np = mean_vectors.cpu().to(torch.float16).numpy()\n",
        "\n",
        "                # finally iterating over layers\n",
        "                for layer_idx in range(num_encoder_layers):\n",
        "                    word_representation_dict[f'encoder_layer_{layer_idx+1}'].append(mean_vectors_np[layer_idx])\n",
        "\n",
        "\n",
        "    token_representation_df = pd.DataFrame(word_representation_dict)\n",
        "\n",
        "    # safety check\n",
        "    print(f\"Original rows: {len(df)}\")\n",
        "    print(f\"Extracted rows: {len(token_representation_df)}\")\n",
        "\n",
        "    return token_representation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPQa2JlSttTm"
      },
      "source": [
        "now let's consider the labels\n",
        "\n",
        "we will consider the base label, with upos tags and also the control task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wfC7lCmy9wsI"
      },
      "outputs": [],
      "source": [
        "# defining the POS tags\n",
        "upos_labels = token_ewt_df['upos'].unique()\n",
        "upos_tags = {u:i for i,u in enumerate(upos_labels)}\n",
        "\n",
        "# inserting the tags in the dataset\n",
        "token_ewt_df['upos_tag']=token_ewt_df['upos'].map(lambda upos: upos_tags[upos])\n",
        "token_ewt_df.drop(columns=['upos', 'token_id'], inplace=True)\n",
        "\n",
        "# defining the control task upos tags\n",
        "unique_words = list(token_ewt_df['words'].unique())\n",
        "np.random.shuffle(unique_words)\n",
        "\n",
        "num_upos_tags = len(upos_tags)\n",
        "token_ct_map_upos={x:i%num_upos_tags for i,x in enumerate(unique_words)}\n",
        "\n",
        "# adding the control task tags to the dataframe\n",
        "token_ewt_df['ct_upos_tag']=token_ewt_df['words'].map(lambda u: token_ct_map_upos[u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmdgN0aZyJb1"
      },
      "source": [
        "optional: xpos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db5e9y3AyLbc"
      },
      "outputs": [],
      "source": [
        "#xpos_labels=token_ewt_df['xpos'].unique()\n",
        "#xpos_tags={x:i for i,x in enumerate(xpos_labels)}\n",
        "#token_ewt_df['xpos_tag']=token_ewt_df['xpos'].map(lambda xpos: xpos_tags[xpos])\n",
        "#token_ewt_df.drop(columns=['xpos'], inplace=True)\n",
        "\n",
        "# control task\n",
        "\n",
        "#num_xpos_tags = len(xpos_tags)\n",
        "#token_ct_map_xpos={x:i%num_xpos_tags for i,x in enumerate(unique_tokens)} # token control task map for xpos\n",
        "#token_ewt_df['ct_xpos_tag']=token_ewt_df['tokens'].map(lambda x: token_ct_map_xpos[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Ou353rtRs8"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ebqMzZuLtRs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "7454fe45-479b-4b44-b9c9-b556a1e904dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 19/19 [00:06<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 13709\n",
            "Extracted rows: 13709\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          words  sentence_id  upos_tag  ct_upos_tag  \\\n",
              "0            Al            0         0            4   \n",
              "1             -            0         1           15   \n",
              "2         Zaman            0         0            5   \n",
              "3             :            0         1            4   \n",
              "4      American            0         2            0   \n",
              "...         ...          ...       ...          ...   \n",
              "13704        at          599         6            2   \n",
              "13705       sea          599         3            4   \n",
              "13706        to          599         6            4   \n",
              "13707   Horizon          599         0            9   \n",
              "13708         .          599         1           13   \n",
              "\n",
              "                                         encoder_layer_1  \\\n",
              "0      [1.953, -0.1245, -1.445, 0.2197, -0.1729, -0.3...   \n",
              "1      [0.664, -0.10254, 0.001694, 0.5156, -0.801, -3...   \n",
              "2      [3.438, 0.1245, -1.836, 1.141, 0.8984, -1.547,...   \n",
              "3      [0.2637, -1.844, 0.461, 1.148, -0.1118, -2.36,...   \n",
              "4      [3.375, 1.844, -0.4805, 1.352, 0.879, -0.828, ...   \n",
              "...                                                  ...   \n",
              "13704  [1.773, -0.715, -1.102, 1.859, -0.797, -1.133,...   \n",
              "13705  [3.25, -1.0, -0.4785, 0.547, -2.375, 1.0625, -...   \n",
              "13706  [1.508, 0.4805, -1.039, 1.648, 1.117, -1.25, -...   \n",
              "13707  [5.625, -1.055, 1.305, -0.7656, -1.094, 0.9062...   \n",
              "13708  [0.3906, 0.1377, -0.09375, 1.672, -0.377, -2.6...   \n",
              "\n",
              "                                         encoder_layer_2  \\\n",
              "0      [-0.08594, 0.293, -1.25, -1.5, 0.1885, 1.391, ...   \n",
              "1      [-0.707, 0.6875, -0.0498, -0.6367, -0.875, 0.1...   \n",
              "2      [-0.1777, 0.4453, -1.5625, 0.02734, 0.5625, -0...   \n",
              "3      [-0.332, -0.625, 0.1309, -0.3008, 0.10254, 0.5...   \n",
              "4      [0.0801, 0.914, -0.9414, 0.746, 1.344, -0.248,...   \n",
              "...                                                  ...   \n",
              "13704  [0.7656, -0.07227, -0.828, 1.016, -0.5664, 0.3...   \n",
              "13705  [-1.211, -0.2734, 0.1729, -0.3281, -1.453, 1.0...   \n",
              "13706  [0.10547, 0.291, -0.578, 0.007812, 0.0547, 0.3...   \n",
              "13707  [-0.3633, -0.6836, 0.4062, -0.4355, -1.844, -0...   \n",
              "13708  [-0.1914, 0.625, 0.0249, -0.1133, 0.09814, 0.2...   \n",
              "\n",
              "                                         encoder_layer_3  \\\n",
              "0      [-0.01074, -0.01807, -0.6875, -0.7812, 0.8555,...   \n",
              "1      [-0.801, 0.5547, 0.01758, -0.1855, -0.3242, 0....   \n",
              "2      [-0.4102, -0.4414, -0.9297, 0.4922, 0.6133, -0...   \n",
              "3      [0.2754, -0.547, 0.664, -0.5117, 0.742, 0.1426...   \n",
              "4      [-0.629, 0.4023, -0.75, 0.914, 1.766, -0.1357,...   \n",
              "...                                                  ...   \n",
              "13704  [0.1719, 0.5938, -0.06934, 0.371, -0.5586, 0.1...   \n",
              "13705  [-0.703, -0.3496, 0.455, -0.8125, -1.008, 0.29...   \n",
              "13706  [0.2158, 0.5586, -0.2109, -0.3926, 0.3867, -0....   \n",
              "13707  [-0.6094, -0.535, 0.5117, -0.711, -1.391, -0.8...   \n",
              "13708  [-0.416, 0.248, 0.4941, -0.4727, 0.3145, -0.10...   \n",
              "\n",
              "                                         encoder_layer_4  \\\n",
              "0      [-0.4297, 0.3672, -0.9336, -0.539, 0.9297, 1.2...   \n",
              "1      [-0.3984, 0.4707, -0.3965, -0.25, 0.4453, -0.6...   \n",
              "2      [-0.6875, -0.02148, -1.32, 0.4805, 0.785, -0.4...   \n",
              "3      [0.582, -0.2695, -0.1855, 0.03516, 0.2344, 0.3...   \n",
              "4      [-1.0625, 0.2637, -0.9805, 0.953, 1.734, 0.554...   \n",
              "...                                                  ...   \n",
              "13704  [-0.2695, 0.1465, -0.2422, 0.3184, -0.793, 0.3...   \n",
              "13705  [-0.2695, -0.797, -0.1367, -0.4258, -1.242, 0....   \n",
              "13706  [0.4727, 0.168, -0.9023, -0.0547, -0.336, -0.1...   \n",
              "13707  [0.1445, -0.332, 0.168, -0.8438, -1.594, -0.67...   \n",
              "13708  [-0.0996, 0.3066, -0.06055, -0.2812, -0.09766,...   \n",
              "\n",
              "                                         encoder_layer_5  \\\n",
              "0      [-0.2656, 0.6797, -0.6367, -0.578, 1.266, 1.46...   \n",
              "1      [-1.156, 1.453, -0.05273, -0.6133, 0.6484, -0....   \n",
              "2      [-0.2812, 0.1963, -1.086, 0.5625, 1.156, 0.212...   \n",
              "3      [-0.1348, -0.05664, 0.547, 0.007812, -0.2793, ...   \n",
              "4      [-0.2578, 0.6094, -1.5625, 1.141, 2.14, 0.2461...   \n",
              "...                                                  ...   \n",
              "13704  [0.6875, 0.3438, -0.7656, 0.1367, -1.328, -0.6...   \n",
              "13705  [0.8086, -0.8555, -0.8984, -0.289, -2.078, -0....   \n",
              "13706  [1.453, 0.1641, -0.9805, 0.07324, -0.3965, -0....   \n",
              "13707  [0.03125, -0.2969, -0.5703, -0.9688, -1.0625, ...   \n",
              "13708  [0.2988, 0.2969, 0.4316, -0.2695, -0.1934, 0.2...   \n",
              "\n",
              "                                         encoder_layer_6  \\\n",
              "0      [-1.0, 0.3984, 0.04004, -0.1738, 1.516, 1.242,...   \n",
              "1      [-1.305, 1.227, 0.59, -0.459, 1.0625, -0.4766,...   \n",
              "2      [-0.295, -0.3535, -0.1133, 0.832, 0.6484, 0.87...   \n",
              "3      [-0.3027, -0.8203, 0.10156, -0.1846, -0.463, 0...   \n",
              "4      [-0.2969, -0.03906, -1.477, 0.9805, 1.609, 1.2...   \n",
              "...                                                  ...   \n",
              "13704  [1.07, 0.09863, -1.125, -0.5273, -1.266, -0.55...   \n",
              "13705  [0.742, -1.469, -1.156, 0.0957, -2.344, -0.457...   \n",
              "13706  [1.711, -0.7617, -0.4785, -0.04102, 0.1992, -0...   \n",
              "13707  [0.4727, -1.133, 0.0332, -1.172, -1.484, -0.71...   \n",
              "13708  [-0.2617, -0.1299, 0.2432, -0.8438, -0.8438, -...   \n",
              "\n",
              "                                         encoder_layer_7  \\\n",
              "0      [-0.6797, 0.4727, 0.7773, 0.4727, 0.9766, 1.62...   \n",
              "1      [-1.969, 0.832, 0.9414, -1.6875, 1.352, 0.4941...   \n",
              "2      [-0.416, 0.08203, 0.2041, 1.148, -0.7344, 1.64...   \n",
              "3      [0.03125, -0.5625, 0.9062, 0.2578, -1.547, 1.2...   \n",
              "4      [0.7773, 0.7188, 0.535, 1.297, 1.5625, 0.8164,...   \n",
              "...                                                  ...   \n",
              "13704  [1.016, 0.03516, -0.5117, -0.461, -1.648, -0.5...   \n",
              "13705  [0.629, -1.156, -0.6797, 0.103, -2.844, -0.672...   \n",
              "13706  [2.344, -0.1992, -1.0625, 0.4727, -0.4414, 0.4...   \n",
              "13707  [0.2695, -0.11523, -1.359, -0.953, -2.844, -0....   \n",
              "13708  [-0.00586, 1.156, -0.11816, -1.422, -1.633, -0...   \n",
              "\n",
              "                                         encoder_layer_8  \\\n",
              "0      [-1.008, 0.8633, -0.02344, 0.617, 0.914, 1.406...   \n",
              "1      [-1.422, 0.5586, 1.016, -0.836, 0.4883, -2.0, ...   \n",
              "2      [-1.242, 0.1807, 0.001953, 0.922, -0.7305, 1.0...   \n",
              "3      [-0.1118, -0.2012, -1.023, -0.0503, -1.305, 0....   \n",
              "4      [0.703, -0.01758, 0.582, 1.078, 1.531, 1.844, ...   \n",
              "...                                                  ...   \n",
              "13704  [0.3926, 0.586, -0.5273, -0.996, -1.781, -1.18...   \n",
              "13705  [0.1543, -0.504, -0.8516, -0.1738, -3.078, 0.3...   \n",
              "13706  [1.641, 0.289, -0.9297, -0.4668, -0.10205, -1....   \n",
              "13707  [-1.273, 0.2334, -2.11, -1.609, -2.469, 0.0, -...   \n",
              "13708  [-1.5625, -0.3203, -0.9375, -1.672, -1.172, -1...   \n",
              "\n",
              "                                         encoder_layer_9  \\\n",
              "0      [-0.5156, 0.0957, -0.8047, -0.629, 1.906, 2.15...   \n",
              "1      [-1.0625, 3.078, -2.0, -1.18, 0.2031, -0.02344...   \n",
              "2      [-0.7266, 0.252, 0.3926, 0.9883, 0.12256, 1.73...   \n",
              "3      [2.094, -2.11, -0.4883, -0.4648, -1.969, 0.277...   \n",
              "4      [1.828, -1.117, 1.484, 1.117, 1.695, 2.156, 0....   \n",
              "...                                                  ...   \n",
              "13704  [1.406, -1.414, -0.543, -2.516, -1.453, -0.017...   \n",
              "13705  [0.8125, -1.109, -0.01172, -0.1328, -3.36, 0.4...   \n",
              "13706  [3.156, -0.2031, -2.281, -0.2734, -0.0537, -1....   \n",
              "13707  [-0.4414, -0.5625, -2.938, -1.75, -2.203, -0.4...   \n",
              "13708  [-0.6055, -2.25, -1.602, -2.344, -1.125, -1.62...   \n",
              "\n",
              "                                        encoder_layer_10  \\\n",
              "0      [-2.062, 0.02734, -1.156, -0.6953, 1.625, 2.29...   \n",
              "1      [0.04688, 1.953, -1.32, -1.594, 0.2441, 1.961,...   \n",
              "2      [-2.062, 0.1719, -0.84, 1.453, -0.05566, 1.141...   \n",
              "3      [1.398, -1.094, -0.461, -1.039, -1.852, 0.5, 0...   \n",
              "4      [1.375, -0.5117, 0.2734, 1.0, 2.25, 1.867, -0....   \n",
              "...                                                  ...   \n",
              "13704  [1.422, -1.898, -0.918, -2.484, -1.547, -2.031...   \n",
              "13705  [-0.1367, -1.273, -0.8594, -0.5195, -3.828, 0....   \n",
              "13706  [4.03, -1.93, -1.859, -0.371, 0.1113, -3.172, ...   \n",
              "13707  [-1.32, -1.367, -2.562, -2.125, -2.656, -0.812...   \n",
              "13708  [-1.219, -1.125, -2.062, -2.688, -1.828, -3.61...   \n",
              "\n",
              "                                        encoder_layer_11  \\\n",
              "0      [-1.453, 0.1357, -0.547, -0.5625, 2.25, 3.11, ...   \n",
              "1      [2.078, 3.5, 0.4414, -1.773, -1.508, 1.445, 0....   \n",
              "2      [-1.594, 0.1816, -0.375, 1.93, 0.707, 2.25, -0...   \n",
              "3      [2.062, -1.133, 0.8945, 0.338, -1.219, 2.14, 1...   \n",
              "4      [2.89, -0.633, 1.133, 0.8945, 2.734, 3.0, -0.3...   \n",
              "...                                                  ...   \n",
              "13704  [1.969, -2.531, 0.578, -1.602, -0.3047, -1.687...   \n",
              "13705  [1.156, -1.5625, -1.297, -0.4297, -3.875, 1.0,...   \n",
              "13706  [5.03, -2.156, -1.484, -1.047, 1.016, -2.156, ...   \n",
              "13707  [-0.2227, -1.336, -2.734, -3.062, -3.016, -0.5...   \n",
              "13708  [0.4922, -1.195, -2.219, -3.281, -0.5312, -3.2...   \n",
              "\n",
              "                                        encoder_layer_12  \\\n",
              "0      [-2.156, 1.406, -0.3574, 0.715, 2.766, 2.797, ...   \n",
              "1      [4.688, 5.28, 3.344, -0.6367, -5.97, 2.89, -1....   \n",
              "2      [-1.852, 1.344, 0.2227, 3.625, 1.352, 1.961, -...   \n",
              "3      [2.719, -0.02344, 2.562, 0.7227, -1.281, 1.594...   \n",
              "4      [1.3125, -0.5312, 2.281, 2.766, 2.625, 2.031, ...   \n",
              "...                                                  ...   \n",
              "13704  [1.93, -2.281, 1.547, -0.4688, 0.4082, -2.203,...   \n",
              "13705  [0.0547, -1.523, -1.016, 0.7344, -4.438, -0.00...   \n",
              "13706  [5.72, -2.844, -2.484, -0.1113, -0.2471, -3.25...   \n",
              "13707  [-0.707, -1.57, -2.688, -2.375, -3.547, -1.187...   \n",
              "13708  [1.461, -1.3125, -0.9453, -4.125, -1.195, -5.1...   \n",
              "\n",
              "                                        encoder_layer_13  \n",
              "0      [-3.922, 2.219, -1.922, -2.25, 7.562, 5.78, -3...  \n",
              "1      [4.094, 2.594, 1.25, -0.3145, -4.094, 2.64, -0...  \n",
              "2      [-3.781, 3.031, -0.922, 6.062, 3.938, 5.75, -3...  \n",
              "3      [4.844, 0.2119, 5.812, -2.188, -1.734, 4.78, 2...  \n",
              "4      [3.25, -2.328, 2.344, 3.734, 5.406, 4.125, -2....  \n",
              "...                                                  ...  \n",
              "13704  [2.64, -4.844, 0.7227, -3.328, 0.926, -3.531, ...  \n",
              "13705  [1.375, -4.156, -4.22, -1.047, -9.19, 0.625, 1...  \n",
              "13706  [14.0, -5.312, -7.5, -2.875, 0.4922, -5.344, -...  \n",
              "13707  [-0.4727, -4.25, -7.72, -6.22, -6.5, -1.594, -...  \n",
              "13708  [4.562, -1.609, -2.812, -9.69, -0.9023, -6.938...  \n",
              "\n",
              "[13709 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b84976f-3686-4886-a991-273f171a7ac1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>upos_tag</th>\n",
              "      <th>ct_upos_tag</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>encoder_layer_8</th>\n",
              "      <th>encoder_layer_9</th>\n",
              "      <th>encoder_layer_10</th>\n",
              "      <th>encoder_layer_11</th>\n",
              "      <th>encoder_layer_12</th>\n",
              "      <th>encoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>[1.953, -0.1245, -1.445, 0.2197, -0.1729, -0.3...</td>\n",
              "      <td>[-0.08594, 0.293, -1.25, -1.5, 0.1885, 1.391, ...</td>\n",
              "      <td>[-0.01074, -0.01807, -0.6875, -0.7812, 0.8555,...</td>\n",
              "      <td>[-0.4297, 0.3672, -0.9336, -0.539, 0.9297, 1.2...</td>\n",
              "      <td>[-0.2656, 0.6797, -0.6367, -0.578, 1.266, 1.46...</td>\n",
              "      <td>[-1.0, 0.3984, 0.04004, -0.1738, 1.516, 1.242,...</td>\n",
              "      <td>[-0.6797, 0.4727, 0.7773, 0.4727, 0.9766, 1.62...</td>\n",
              "      <td>[-1.008, 0.8633, -0.02344, 0.617, 0.914, 1.406...</td>\n",
              "      <td>[-0.5156, 0.0957, -0.8047, -0.629, 1.906, 2.15...</td>\n",
              "      <td>[-2.062, 0.02734, -1.156, -0.6953, 1.625, 2.29...</td>\n",
              "      <td>[-1.453, 0.1357, -0.547, -0.5625, 2.25, 3.11, ...</td>\n",
              "      <td>[-2.156, 1.406, -0.3574, 0.715, 2.766, 2.797, ...</td>\n",
              "      <td>[-3.922, 2.219, -1.922, -2.25, 7.562, 5.78, -3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>[0.664, -0.10254, 0.001694, 0.5156, -0.801, -3...</td>\n",
              "      <td>[-0.707, 0.6875, -0.0498, -0.6367, -0.875, 0.1...</td>\n",
              "      <td>[-0.801, 0.5547, 0.01758, -0.1855, -0.3242, 0....</td>\n",
              "      <td>[-0.3984, 0.4707, -0.3965, -0.25, 0.4453, -0.6...</td>\n",
              "      <td>[-1.156, 1.453, -0.05273, -0.6133, 0.6484, -0....</td>\n",
              "      <td>[-1.305, 1.227, 0.59, -0.459, 1.0625, -0.4766,...</td>\n",
              "      <td>[-1.969, 0.832, 0.9414, -1.6875, 1.352, 0.4941...</td>\n",
              "      <td>[-1.422, 0.5586, 1.016, -0.836, 0.4883, -2.0, ...</td>\n",
              "      <td>[-1.0625, 3.078, -2.0, -1.18, 0.2031, -0.02344...</td>\n",
              "      <td>[0.04688, 1.953, -1.32, -1.594, 0.2441, 1.961,...</td>\n",
              "      <td>[2.078, 3.5, 0.4414, -1.773, -1.508, 1.445, 0....</td>\n",
              "      <td>[4.688, 5.28, 3.344, -0.6367, -5.97, 2.89, -1....</td>\n",
              "      <td>[4.094, 2.594, 1.25, -0.3145, -4.094, 2.64, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zaman</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>[3.438, 0.1245, -1.836, 1.141, 0.8984, -1.547,...</td>\n",
              "      <td>[-0.1777, 0.4453, -1.5625, 0.02734, 0.5625, -0...</td>\n",
              "      <td>[-0.4102, -0.4414, -0.9297, 0.4922, 0.6133, -0...</td>\n",
              "      <td>[-0.6875, -0.02148, -1.32, 0.4805, 0.785, -0.4...</td>\n",
              "      <td>[-0.2812, 0.1963, -1.086, 0.5625, 1.156, 0.212...</td>\n",
              "      <td>[-0.295, -0.3535, -0.1133, 0.832, 0.6484, 0.87...</td>\n",
              "      <td>[-0.416, 0.08203, 0.2041, 1.148, -0.7344, 1.64...</td>\n",
              "      <td>[-1.242, 0.1807, 0.001953, 0.922, -0.7305, 1.0...</td>\n",
              "      <td>[-0.7266, 0.252, 0.3926, 0.9883, 0.12256, 1.73...</td>\n",
              "      <td>[-2.062, 0.1719, -0.84, 1.453, -0.05566, 1.141...</td>\n",
              "      <td>[-1.594, 0.1816, -0.375, 1.93, 0.707, 2.25, -0...</td>\n",
              "      <td>[-1.852, 1.344, 0.2227, 3.625, 1.352, 1.961, -...</td>\n",
              "      <td>[-3.781, 3.031, -0.922, 6.062, 3.938, 5.75, -3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.2637, -1.844, 0.461, 1.148, -0.1118, -2.36,...</td>\n",
              "      <td>[-0.332, -0.625, 0.1309, -0.3008, 0.10254, 0.5...</td>\n",
              "      <td>[0.2754, -0.547, 0.664, -0.5117, 0.742, 0.1426...</td>\n",
              "      <td>[0.582, -0.2695, -0.1855, 0.03516, 0.2344, 0.3...</td>\n",
              "      <td>[-0.1348, -0.05664, 0.547, 0.007812, -0.2793, ...</td>\n",
              "      <td>[-0.3027, -0.8203, 0.10156, -0.1846, -0.463, 0...</td>\n",
              "      <td>[0.03125, -0.5625, 0.9062, 0.2578, -1.547, 1.2...</td>\n",
              "      <td>[-0.1118, -0.2012, -1.023, -0.0503, -1.305, 0....</td>\n",
              "      <td>[2.094, -2.11, -0.4883, -0.4648, -1.969, 0.277...</td>\n",
              "      <td>[1.398, -1.094, -0.461, -1.039, -1.852, 0.5, 0...</td>\n",
              "      <td>[2.062, -1.133, 0.8945, 0.338, -1.219, 2.14, 1...</td>\n",
              "      <td>[2.719, -0.02344, 2.562, 0.7227, -1.281, 1.594...</td>\n",
              "      <td>[4.844, 0.2119, 5.812, -2.188, -1.734, 4.78, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>American</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[3.375, 1.844, -0.4805, 1.352, 0.879, -0.828, ...</td>\n",
              "      <td>[0.0801, 0.914, -0.9414, 0.746, 1.344, -0.248,...</td>\n",
              "      <td>[-0.629, 0.4023, -0.75, 0.914, 1.766, -0.1357,...</td>\n",
              "      <td>[-1.0625, 0.2637, -0.9805, 0.953, 1.734, 0.554...</td>\n",
              "      <td>[-0.2578, 0.6094, -1.5625, 1.141, 2.14, 0.2461...</td>\n",
              "      <td>[-0.2969, -0.03906, -1.477, 0.9805, 1.609, 1.2...</td>\n",
              "      <td>[0.7773, 0.7188, 0.535, 1.297, 1.5625, 0.8164,...</td>\n",
              "      <td>[0.703, -0.01758, 0.582, 1.078, 1.531, 1.844, ...</td>\n",
              "      <td>[1.828, -1.117, 1.484, 1.117, 1.695, 2.156, 0....</td>\n",
              "      <td>[1.375, -0.5117, 0.2734, 1.0, 2.25, 1.867, -0....</td>\n",
              "      <td>[2.89, -0.633, 1.133, 0.8945, 2.734, 3.0, -0.3...</td>\n",
              "      <td>[1.3125, -0.5312, 2.281, 2.766, 2.625, 2.031, ...</td>\n",
              "      <td>[3.25, -2.328, 2.344, 3.734, 5.406, 4.125, -2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13704</th>\n",
              "      <td>at</td>\n",
              "      <td>599</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.773, -0.715, -1.102, 1.859, -0.797, -1.133,...</td>\n",
              "      <td>[0.7656, -0.07227, -0.828, 1.016, -0.5664, 0.3...</td>\n",
              "      <td>[0.1719, 0.5938, -0.06934, 0.371, -0.5586, 0.1...</td>\n",
              "      <td>[-0.2695, 0.1465, -0.2422, 0.3184, -0.793, 0.3...</td>\n",
              "      <td>[0.6875, 0.3438, -0.7656, 0.1367, -1.328, -0.6...</td>\n",
              "      <td>[1.07, 0.09863, -1.125, -0.5273, -1.266, -0.55...</td>\n",
              "      <td>[1.016, 0.03516, -0.5117, -0.461, -1.648, -0.5...</td>\n",
              "      <td>[0.3926, 0.586, -0.5273, -0.996, -1.781, -1.18...</td>\n",
              "      <td>[1.406, -1.414, -0.543, -2.516, -1.453, -0.017...</td>\n",
              "      <td>[1.422, -1.898, -0.918, -2.484, -1.547, -2.031...</td>\n",
              "      <td>[1.969, -2.531, 0.578, -1.602, -0.3047, -1.687...</td>\n",
              "      <td>[1.93, -2.281, 1.547, -0.4688, 0.4082, -2.203,...</td>\n",
              "      <td>[2.64, -4.844, 0.7227, -3.328, 0.926, -3.531, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13705</th>\n",
              "      <td>sea</td>\n",
              "      <td>599</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[3.25, -1.0, -0.4785, 0.547, -2.375, 1.0625, -...</td>\n",
              "      <td>[-1.211, -0.2734, 0.1729, -0.3281, -1.453, 1.0...</td>\n",
              "      <td>[-0.703, -0.3496, 0.455, -0.8125, -1.008, 0.29...</td>\n",
              "      <td>[-0.2695, -0.797, -0.1367, -0.4258, -1.242, 0....</td>\n",
              "      <td>[0.8086, -0.8555, -0.8984, -0.289, -2.078, -0....</td>\n",
              "      <td>[0.742, -1.469, -1.156, 0.0957, -2.344, -0.457...</td>\n",
              "      <td>[0.629, -1.156, -0.6797, 0.103, -2.844, -0.672...</td>\n",
              "      <td>[0.1543, -0.504, -0.8516, -0.1738, -3.078, 0.3...</td>\n",
              "      <td>[0.8125, -1.109, -0.01172, -0.1328, -3.36, 0.4...</td>\n",
              "      <td>[-0.1367, -1.273, -0.8594, -0.5195, -3.828, 0....</td>\n",
              "      <td>[1.156, -1.5625, -1.297, -0.4297, -3.875, 1.0,...</td>\n",
              "      <td>[0.0547, -1.523, -1.016, 0.7344, -4.438, -0.00...</td>\n",
              "      <td>[1.375, -4.156, -4.22, -1.047, -9.19, 0.625, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13706</th>\n",
              "      <td>to</td>\n",
              "      <td>599</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>[1.508, 0.4805, -1.039, 1.648, 1.117, -1.25, -...</td>\n",
              "      <td>[0.10547, 0.291, -0.578, 0.007812, 0.0547, 0.3...</td>\n",
              "      <td>[0.2158, 0.5586, -0.2109, -0.3926, 0.3867, -0....</td>\n",
              "      <td>[0.4727, 0.168, -0.9023, -0.0547, -0.336, -0.1...</td>\n",
              "      <td>[1.453, 0.1641, -0.9805, 0.07324, -0.3965, -0....</td>\n",
              "      <td>[1.711, -0.7617, -0.4785, -0.04102, 0.1992, -0...</td>\n",
              "      <td>[2.344, -0.1992, -1.0625, 0.4727, -0.4414, 0.4...</td>\n",
              "      <td>[1.641, 0.289, -0.9297, -0.4668, -0.10205, -1....</td>\n",
              "      <td>[3.156, -0.2031, -2.281, -0.2734, -0.0537, -1....</td>\n",
              "      <td>[4.03, -1.93, -1.859, -0.371, 0.1113, -3.172, ...</td>\n",
              "      <td>[5.03, -2.156, -1.484, -1.047, 1.016, -2.156, ...</td>\n",
              "      <td>[5.72, -2.844, -2.484, -0.1113, -0.2471, -3.25...</td>\n",
              "      <td>[14.0, -5.312, -7.5, -2.875, 0.4922, -5.344, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13707</th>\n",
              "      <td>Horizon</td>\n",
              "      <td>599</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>[5.625, -1.055, 1.305, -0.7656, -1.094, 0.9062...</td>\n",
              "      <td>[-0.3633, -0.6836, 0.4062, -0.4355, -1.844, -0...</td>\n",
              "      <td>[-0.6094, -0.535, 0.5117, -0.711, -1.391, -0.8...</td>\n",
              "      <td>[0.1445, -0.332, 0.168, -0.8438, -1.594, -0.67...</td>\n",
              "      <td>[0.03125, -0.2969, -0.5703, -0.9688, -1.0625, ...</td>\n",
              "      <td>[0.4727, -1.133, 0.0332, -1.172, -1.484, -0.71...</td>\n",
              "      <td>[0.2695, -0.11523, -1.359, -0.953, -2.844, -0....</td>\n",
              "      <td>[-1.273, 0.2334, -2.11, -1.609, -2.469, 0.0, -...</td>\n",
              "      <td>[-0.4414, -0.5625, -2.938, -1.75, -2.203, -0.4...</td>\n",
              "      <td>[-1.32, -1.367, -2.562, -2.125, -2.656, -0.812...</td>\n",
              "      <td>[-0.2227, -1.336, -2.734, -3.062, -3.016, -0.5...</td>\n",
              "      <td>[-0.707, -1.57, -2.688, -2.375, -3.547, -1.187...</td>\n",
              "      <td>[-0.4727, -4.25, -7.72, -6.22, -6.5, -1.594, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13708</th>\n",
              "      <td>.</td>\n",
              "      <td>599</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>[0.3906, 0.1377, -0.09375, 1.672, -0.377, -2.6...</td>\n",
              "      <td>[-0.1914, 0.625, 0.0249, -0.1133, 0.09814, 0.2...</td>\n",
              "      <td>[-0.416, 0.248, 0.4941, -0.4727, 0.3145, -0.10...</td>\n",
              "      <td>[-0.0996, 0.3066, -0.06055, -0.2812, -0.09766,...</td>\n",
              "      <td>[0.2988, 0.2969, 0.4316, -0.2695, -0.1934, 0.2...</td>\n",
              "      <td>[-0.2617, -0.1299, 0.2432, -0.8438, -0.8438, -...</td>\n",
              "      <td>[-0.00586, 1.156, -0.11816, -1.422, -1.633, -0...</td>\n",
              "      <td>[-1.5625, -0.3203, -0.9375, -1.672, -1.172, -1...</td>\n",
              "      <td>[-0.6055, -2.25, -1.602, -2.344, -1.125, -1.62...</td>\n",
              "      <td>[-1.219, -1.125, -2.062, -2.688, -1.828, -3.61...</td>\n",
              "      <td>[0.4922, -1.195, -2.219, -3.281, -0.5312, -3.2...</td>\n",
              "      <td>[1.461, -1.3125, -0.9453, -4.125, -1.195, -5.1...</td>\n",
              "      <td>[4.562, -1.609, -2.812, -9.69, -0.9023, -6.938...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13709 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b84976f-3686-4886-a991-273f171a7ac1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b84976f-3686-4886-a991-273f171a7ac1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b84976f-3686-4886-a991-273f171a7ac1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-02eec48f-0ecf-449e-beaf-aec6ad1ebc32\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02eec48f-0ecf-449e-beaf-aec6ad1ebc32')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-02eec48f-0ecf-449e-beaf-aec6ad1ebc32 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2baf1130-5784-4e9f-bde7-362eee24db01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('token_ewt_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2baf1130-5784-4e9f-bde7-362eee24db01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('token_ewt_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "token_ewt_df",
              "summary": "{\n  \"name\": \"token_ewt_df\",\n  \"rows\": 13709,\n  \"fields\": [\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3439,\n        \"samples\": [\n          \"Secular\",\n          \"Comex\",\n          \"http://www.nsrl.ttu.edu/chernobyl/wildlifepreserve.htm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170,\n        \"min\": 0,\n        \"max\": 599,\n        \"num_unique_values\": 600,\n        \"samples\": [\n          110,\n          419,\n          565\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upos_tag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 16,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ct_upos_tag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 16,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          4,\n          15,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_4\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_5\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_6\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_7\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_8\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_9\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_10\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_11\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_12\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoder_layer_13\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "token_representation_df = get_word_representation_df(model_b, tokenizer_b, token_ewt_df, 32)\n",
        "token_ewt_df=pd.concat([token_ewt_df, token_representation_df], axis=1)\n",
        "token_ewt_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_activations_df(token_ewt_df, 'ewt', model_id_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64hLswQL-6NS",
        "outputId": "f010b379-4b99-4025-b37e-f8600f6e7b2b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ewt_t5gemma-b-b-ul2 to GDrive...\n",
            "Saved ewt_t5gemma-b-b-ul2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSmHCgrtRs8"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK5HwVd8tRs8"
      },
      "outputs": [],
      "source": [
        "token_representation_df_2b = get_word_representation_df(model_2b, tokenizer_2b, token_ewt_df, 8)\n",
        "token_ewt_df_2b=pd.concat([token_ewt_df, token_representation_df_2b], axis=1)\n",
        "token_ewt_df_2b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_activations_df(token_ewt_df_2b, 'ewt', model_id_2b)"
      ],
      "metadata": {
        "id": "Dec-n-72-8TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X_IWa5grjfQ"
      },
      "source": [
        "## MultiNLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Kt-BNFOPrkvG"
      },
      "outputs": [],
      "source": [
        "multinli_dataset = load_dataset(\"nyu-mll/multi_nli\", split='validation_matched') # one of ['train', 'validation_matched', 'validation_mismatched']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NDKt17QttRs-"
      },
      "outputs": [],
      "source": [
        "del multinli_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ek8VE5z3tRs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "4bbc554b-a6bd-4d1a-9f00-9b41b8861a5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                premise  \\\n",
              "0                        The new rights are nice enough   \n",
              "1     This site includes a list of all award winners...   \n",
              "2     uh i don't know i i have mixed emotions about ...   \n",
              "3     yeah i i think my favorite restaurant is alway...   \n",
              "4            i don't know um do you do a lot of camping   \n",
              "...                                                 ...   \n",
              "9810  Since 1998, LSC has initiated and overseen sig...   \n",
              "9811  Eighty percent of pagers in the United States ...   \n",
              "9812  Finally, the FDA will conduct workshops, issue...   \n",
              "9813  Cirque du Soleil's The latest from the acclaim...   \n",
              "9814  i'll listen  and agree with what i think sound...   \n",
              "\n",
              "                                             hypothesis  label  \n",
              "0            Everyone really likes the newest benefits       1  \n",
              "1     The Government Executive articles housed on th...      2  \n",
              "2     I like him for the most part, but would still ...      0  \n",
              "3     My favorite restaurants are always at least a ...      2  \n",
              "4                                       I know exactly.      2  \n",
              "...                                                 ...    ...  \n",
              "9810  LSC has been focusing on improving it's state ...      1  \n",
              "9811  Pagers in the United States were unaffected by...      2  \n",
              "9812              The FDA is set to conduct workshops.       0  \n",
              "9813       Cirque du Soleil is an international troupe.      0  \n",
              "9814                      I wont even bother listening.      2  \n",
              "\n",
              "[9815 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3d5ff6a-586b-43dd-ab1f-c6014ca58b44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The new rights are nice enough</td>\n",
              "      <td>Everyone really likes the newest benefits</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This site includes a list of all award winners...</td>\n",
              "      <td>The Government Executive articles housed on th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uh i don't know i i have mixed emotions about ...</td>\n",
              "      <td>I like him for the most part, but would still ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yeah i i think my favorite restaurant is alway...</td>\n",
              "      <td>My favorite restaurants are always at least a ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i don't know um do you do a lot of camping</td>\n",
              "      <td>I know exactly.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>Since 1998, LSC has initiated and overseen sig...</td>\n",
              "      <td>LSC has been focusing on improving it's state ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>Eighty percent of pagers in the United States ...</td>\n",
              "      <td>Pagers in the United States were unaffected by...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>Finally, the FDA will conduct workshops, issue...</td>\n",
              "      <td>The FDA is set to conduct workshops.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>Cirque du Soleil's The latest from the acclaim...</td>\n",
              "      <td>Cirque du Soleil is an international troupe.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>i'll listen  and agree with what i think sound...</td>\n",
              "      <td>I wont even bother listening.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3d5ff6a-586b-43dd-ab1f-c6014ca58b44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3d5ff6a-586b-43dd-ab1f-c6014ca58b44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3d5ff6a-586b-43dd-ab1f-c6014ca58b44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0c248f9-d7d5-4544-8a51-792b76ce394e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0c248f9-d7d5-4544-8a51-792b76ce394e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0c248f9-d7d5-4544-8a51-792b76ce394e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e525a46-4c9e-4cfc-a4a3-6fe24a365a5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('multinli_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e525a46-4c9e-4cfc-a4a3-6fe24a365a5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('multinli_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multinli_df",
              "summary": "{\n  \"name\": \"multinli_df\",\n  \"rows\": 9815,\n  \"fields\": [\n    {\n      \"column\": \"premise\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3334,\n        \"samples\": [\n          \"oh really yeah i've i've never seen either one of them\",\n          \"There are other reasons that wrecks cause fan excitement--e.g.\",\n          \"In fact, you're going to be rewarded.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypothesis\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9814,\n        \"samples\": [\n          \"The beaches in Chennai are very dirty.\",\n          \"The computer attacks on the Department of Defense are too powerful to handle.\",\n          \"Some of the best quotes will come from Barney Frank.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "multinli_df = multinli_dataset.to_pandas()\n",
        "multinli_df.drop(columns=['promptID', 'pairID', 'premise_binary_parse', 'premise_parse', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre'], inplace=True)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsNT_6ZtRs-"
      },
      "source": [
        "as shown by [Finetuned Language Models Are Zero-Shot Learners] the model give a better representation if natural language instruction are given\n",
        "\n",
        "that is why here we use the prompt: 'premise: \"{}\", hypothesis: \"{}\"' to get a single sentence, and then use the sentence extraction function as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "l4UA_ruvtRs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d41cfbc4-142d-49ea-cd04-46836952838e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "0     premise: \"The new rights are nice enough\", hyp...      1\n",
              "1     premise: \"This site includes a list of all awa...      2\n",
              "2     premise: \"uh i don't know i i have mixed emoti...      0\n",
              "3     premise: \"yeah i i think my favorite restauran...      2\n",
              "4     premise: \"i don't know um do you do a lot of c...      2\n",
              "...                                                 ...    ...\n",
              "9810  premise: \"Since 1998, LSC has initiated and ov...      1\n",
              "9811  premise: \"Eighty percent of pagers in the Unit...      2\n",
              "9812  premise: \"Finally, the FDA will conduct worksh...      0\n",
              "9813  premise: \"Cirque du Soleil's The latest from t...      0\n",
              "9814  premise: \"i'll listen  and agree with what i t...      2\n",
              "\n",
              "[9815 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77f8fd2c-ef24-44f2-ad6b-79a717aa3f80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>premise: \"The new rights are nice enough\", hyp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>premise: \"This site includes a list of all awa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>premise: \"uh i don't know i i have mixed emoti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>premise: \"yeah i i think my favorite restauran...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>premise: \"i don't know um do you do a lot of c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>premise: \"Since 1998, LSC has initiated and ov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>premise: \"Eighty percent of pagers in the Unit...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>premise: \"Finally, the FDA will conduct worksh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>premise: \"Cirque du Soleil's The latest from t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>premise: \"i'll listen  and agree with what i t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77f8fd2c-ef24-44f2-ad6b-79a717aa3f80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77f8fd2c-ef24-44f2-ad6b-79a717aa3f80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77f8fd2c-ef24-44f2-ad6b-79a717aa3f80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3fcad747-3d89-445e-aafd-5672d7a3a600\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fcad747-3d89-445e-aafd-5672d7a3a600')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3fcad747-3d89-445e-aafd-5672d7a3a600 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_da5ec563-c833-41e8-a0d9-b26980597a93\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('multinli_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_da5ec563-c833-41e8-a0d9-b26980597a93 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('multinli_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multinli_df",
              "summary": "{\n  \"name\": \"multinli_df\",\n  \"rows\": 9815,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9815,\n        \"samples\": [\n          \"premise: \\\"yeah well losing is i mean i'm i'm originally from Saint Louis and Saint Louis Cardinals when they were there were uh a mostly a losing team but\\\", hypothesis: \\\"The St. Louis Cardinals have always won.\\\"\",\n          \"premise: \\\"Beside the fortress lies an 18th-century caravanserai, or inn, which has been converted into a hotel, and now hosts regular folklore evenings of Turkish dance and music.\\\", hypothesis: \\\"The fortress was built a number of years after the caravanserai.\\\"\",\n          \"premise: \\\"The twenty mastic villages known collectively as mastihohoria were built by the Genoese in the 14 15th centuries.\\\", hypothesis: \\\"Mastihohoria is a collection of twenty mastic villages built be the genoese.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "multinli_df['sentence'] = multinli_df.apply(lambda row: 'premise: \"{}\", hypothesis: \"{}\"'.format(row['premise'], row['hypothesis']), axis=1)\n",
        "multinli_df.drop(columns=['premise', 'hypothesis'], inplace=True)\n",
        "multinli_df = multinli_df[['sentence', 'label']]\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxthbkR3tRs_"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BIafZWy-tRs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f47424c8-b395-4db6-8b3f-5e631a83c853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing 9815 sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/614 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 614/614 [02:02<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving in the DataFrame...\n",
            "Done! Columns added\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label  \\\n",
              "0     premise: \"The new rights are nice enough\", hyp...      1   \n",
              "1     premise: \"This site includes a list of all awa...      2   \n",
              "2     premise: \"uh i don't know i i have mixed emoti...      0   \n",
              "3     premise: \"yeah i i think my favorite restauran...      2   \n",
              "4     premise: \"i don't know um do you do a lot of c...      2   \n",
              "...                                                 ...    ...   \n",
              "9810  premise: \"Since 1998, LSC has initiated and ov...      1   \n",
              "9811  premise: \"Eighty percent of pagers in the Unit...      2   \n",
              "9812  premise: \"Finally, the FDA will conduct worksh...      0   \n",
              "9813  premise: \"Cirque du Soleil's The latest from t...      0   \n",
              "9814  premise: \"i'll listen  and agree with what i t...      2   \n",
              "\n",
              "                                        encoder_layer_1  \\\n",
              "0     [1.344, -0.483, 0.1812, 0.5337, -0.0769, -0.82...   \n",
              "1     [1.561, -0.2668, -0.0681, 0.1443, -0.02663, -0...   \n",
              "2     [1.163, -0.274, -0.2878, -0.183, -0.1095, -0.8...   \n",
              "3     [1.402, -0.49, 0.1664, 0.1311, -0.11487, -1.03...   \n",
              "4     [1.446, -0.555, 0.01454, 0.4224, 0.206, -0.643...   \n",
              "...                                                 ...   \n",
              "9810  [1.506, -0.2832, 0.04056, 0.5, -0.3447, -1.307...   \n",
              "9811  [1.759, -0.4187, -0.1697, 0.3447, -0.202, -0.5...   \n",
              "9812  [1.718, 0.04306, 0.0839, 0.5645, -0.1306, -1.3...   \n",
              "9813  [1.798, -0.3223, 0.1498, 0.6035, -0.12195, -0....   \n",
              "9814  [1.556, -0.1387, -0.1521, 0.5977, -0.03833, -0...   \n",
              "\n",
              "                                        encoder_layer_2  \\\n",
              "0     [-0.03864, -0.2808, -0.02979, -0.2181, -0.1816...   \n",
              "1     [0.0632, 0.105, -0.1414, -0.384, 0.116, 0.3003...   \n",
              "2     [-0.3027, -0.07764, -0.1505, -0.4653, -0.327, ...   \n",
              "3     [-0.1433, -0.1693, -0.005165, -0.404, -0.2578,...   \n",
              "4     [-0.07043, -0.1666, -0.01404, -0.4612, -0.1017...   \n",
              "...                                                 ...   \n",
              "9810  [0.04932, -0.0846, -0.2554, -0.2153, -0.2576, ...   \n",
              "9811  [-0.0734, 0.0743, -0.2362, -0.3215, -0.2666, 0...   \n",
              "9812  [-0.05685, 0.2372, -0.1681, -0.1083, -0.0483, ...   \n",
              "9813  [0.03108, -0.0797, 0.03198, -0.1942, -0.2507, ...   \n",
              "9814  [-0.2079, 0.12085, -0.05237, -0.05545, -0.1606...   \n",
              "\n",
              "                                        encoder_layer_3  \\\n",
              "0     [-0.0968, -0.46, 0.1799, 0.03778, 0.1947, 0.13...   \n",
              "1     [0.04077, -0.10565, 0.05594, -0.1918, 0.3145, ...   \n",
              "2     [-0.3066, -0.2512, 0.02707, -0.0818, 0.05295, ...   \n",
              "3     [0.0487, -0.3203, 0.1254, -0.1898, 0.0528, 0.1...   \n",
              "4     [-0.4087, -0.374, 0.03696, 0.04095, 0.2595, 0....   \n",
              "...                                                 ...   \n",
              "9810  [0.03845, -0.1837, 0.042, -0.1625, 0.114, 0.14...   \n",
              "9811  [-0.1722, -0.0607, 0.1453, -0.144, 0.2146, 0.3...   \n",
              "9812  [-0.0872, 0.1451, 0.1289, 0.05698, 0.338, -0.1...   \n",
              "9813  [-0.0639, -0.2905, 0.4587, -0.006374, 0.2905, ...   \n",
              "9814  [-0.5107, -0.01266, 0.02594, 0.1925, 0.1381, 0...   \n",
              "\n",
              "                                        encoder_layer_4  \\\n",
              "0     [-0.2079, -0.4624, -0.05103, 0.02681, 0.0646, ...   \n",
              "1     [-0.494, -0.1797, -0.2457, -0.1655, 0.0447, 0....   \n",
              "2     [-0.1126, -0.2654, 0.0888, -0.1608, 0.08185, 0...   \n",
              "3     [0.00803, -0.4504, 0.12195, -0.1405, -0.04428,...   \n",
              "4     [-0.299, -0.4531, 0.2932, -0.2054, 0.4106, -0....   \n",
              "...                                                 ...   \n",
              "9810  [-0.0235, -0.1436, -0.0553, -0.0601, -0.06805,...   \n",
              "9811  [-0.1992, -0.1039, -0.01227, -0.02316, 0.2424,...   \n",
              "9812  [-0.182, 0.02766, 0.03287, -0.1383, 0.201, -0....   \n",
              "9813  [-0.1958, -0.2751, 0.0891, 0.02525, 0.2637, 0....   \n",
              "9814  [-0.1798, -0.11456, -0.0368, 0.0846, 0.261, 0....   \n",
              "\n",
              "                                        encoder_layer_5  \\\n",
              "0     [-0.1687, -0.2612, -0.1926, 0.2134, 0.4412, 0....   \n",
              "1     [-0.2213, -0.0804, 0.02829, -0.245, 0.3538, 0....   \n",
              "2     [-0.4702, -0.3503, -0.001026, -0.2805, 0.507, ...   \n",
              "3     [-0.0972, -0.3352, -0.1434, -0.0467, 0.4023, 0...   \n",
              "4     [-0.4116, -0.4807, -0.08484, -0.1893, 0.8564, ...   \n",
              "...                                                 ...   \n",
              "9810  [-0.11865, -0.05368, -0.1266, -0.0887, 0.3015,...   \n",
              "9811  [-0.06854, -0.2786, -0.2017, -0.1204, 0.6406, ...   \n",
              "9812  [-0.2128, 0.1598, 0.05807, -0.2805, 0.58, 0.13...   \n",
              "9813  [-0.1653, -0.1857, -0.0406, -0.0867, 0.2412, 0...   \n",
              "9814  [-0.3088, -0.411, -0.3018, -0.0605, 0.4875, 0....   \n",
              "\n",
              "                                        encoder_layer_6  \\\n",
              "0     [-0.3135, -0.12476, -0.11707, 0.09, 0.2074, 0....   \n",
              "1     [-0.06604, -0.1796, -0.00826, -0.04938, 0.3613...   \n",
              "2     [-0.3132, -0.405, 0.2208, -0.374, 0.3657, 0.42...   \n",
              "3     [-0.00971, -0.4668, -0.012535, -0.0956, 0.2915...   \n",
              "4     [-0.05115, -0.545, 0.005085, -0.2761, 0.671, -...   \n",
              "...                                                 ...   \n",
              "9810  [0.01325, -0.3506, 0.06335, -0.03503, 0.1782, ...   \n",
              "9811  [0.11926, -0.154, -0.06946, 0.1306, 0.6772, 0....   \n",
              "9812  [-0.11383, -0.1799, 0.1243, -0.2686, 0.56, 0.0...   \n",
              "9813  [-0.02888, -0.1448, 0.0614, 0.07104, 0.3801, 0...   \n",
              "9814  [-0.4077, -0.312, -0.0448, -0.2114, 0.2302, 0....   \n",
              "\n",
              "                                        encoder_layer_7  \\\n",
              "0     [0.1288, -0.47, -0.2286, 0.0789, 0.03105, 0.12...   \n",
              "1     [0.6904, -0.409, 0.436, 0.148, 0.4436, -0.2218...   \n",
              "2     [-0.1027, -0.5273, 0.2502, 0.2164, 0.0921, 0.2...   \n",
              "3     [0.438, -0.7173, 0.0845, 0.182, 0.04935, 0.376...   \n",
              "4     [0.3135, -0.881, -0.545, 0.10284, 0.442, 0.116...   \n",
              "...                                                 ...   \n",
              "9810  [0.5894, -0.06238, 0.5283, -0.1141, 0.3916, 0....   \n",
              "9811  [0.721, -0.4841, -0.1459, 0.5635, 0.5723, 0.43...   \n",
              "9812  [0.3928, 0.01674, 0.351, -0.366, 0.5435, -0.00...   \n",
              "9813  [0.3428, 0.003273, -0.1865, 0.1659, 0.4243, 0....   \n",
              "9814  [-0.3765, -0.522, -0.0345, -0.03528, 0.00503, ...   \n",
              "\n",
              "                                        encoder_layer_8  ...  \\\n",
              "0     [-0.0889, -0.1234, -0.4497, 0.2122, -0.221, 0....  ...   \n",
              "1     [0.176, 0.05182, 0.1171, 0.1746, 0.1741, 0.258...  ...   \n",
              "2     [0.0967, -0.1975, -0.03513, -0.07874, 0.0703, ...  ...   \n",
              "3     [0.3896, -0.5376, -0.283, 0.1035, 0.1804, 0.55...  ...   \n",
              "4     [0.3914, -0.2188, -0.509, -0.0247, 0.3635, 0.4...  ...   \n",
              "...                                                 ...  ...   \n",
              "9810  [0.579, -0.3577, 0.552, 0.2429, 0.092, 0.5176,...  ...   \n",
              "9811  [0.659, -0.0172, -0.6035, 0.5107, 0.533, 0.651...  ...   \n",
              "9812  [0.4287, 0.2568, -0.04056, -0.2427, 0.4504, 0....  ...   \n",
              "9813  [0.3577, 0.00595, -0.2098, 0.05118, 0.3884, 0....  ...   \n",
              "9814  [-0.1458, -0.06097, -0.29, -0.03644, -0.2189, ...  ...   \n",
              "\n",
              "                                        decoder_layer_4  \\\n",
              "0     [-0.5, 0.3906, 0.3184, 0.5312, -0.4727, -0.048...   \n",
              "1     [-0.4883, 0.4062, 0.2734, 0.5, -0.459, -0.0196...   \n",
              "2     [-0.5, 0.3672, 0.2793, 0.539, -0.4785, -0.0581...   \n",
              "3     [-0.504, 0.3652, 0.2988, 0.5273, -0.4688, -0.0...   \n",
              "4     [-0.4805, 0.3848, 0.2988, 0.5234, -0.498, -0.0...   \n",
              "...                                                 ...   \n",
              "9810  [-0.5, 0.3848, 0.2773, 0.508, -0.4883, -0.0283...   \n",
              "9811  [-0.5, 0.3887, 0.3047, 0.504, -0.4941, -0.0296...   \n",
              "9812  [-0.4902, 0.3887, 0.2988, 0.5273, -0.463, -0.0...   \n",
              "9813  [-0.4902, 0.3906, 0.295, 0.5234, -0.4648, -0.0...   \n",
              "9814  [-0.4688, 0.377, 0.3047, 0.5273, -0.4805, -0.0...   \n",
              "\n",
              "                                        decoder_layer_5  \\\n",
              "0     [-0.961, 0.5117, -0.0371, 0.8047, -0.9375, -0....   \n",
              "1     [-0.9727, 0.5312, -0.0967, 0.7773, -0.957, -0....   \n",
              "2     [-0.949, 0.496, -0.0679, 0.8047, -0.9766, -0.4...   \n",
              "3     [-0.961, 0.5, -0.05762, 0.797, -0.957, -0.42, ...   \n",
              "4     [-0.9375, 0.5156, -0.05127, 0.785, -0.9688, -0...   \n",
              "...                                                 ...   \n",
              "9810  [-0.9688, 0.508, -0.0874, 0.7812, -0.961, -0.4...   \n",
              "9811  [-0.953, 0.5195, -0.05786, 0.789, -0.961, -0.4...   \n",
              "9812  [-0.961, 0.508, -0.0581, 0.801, -0.953, -0.433...   \n",
              "9813  [-0.949, 0.5117, -0.0742, 0.797, -0.957, -0.40...   \n",
              "9814  [-0.9375, 0.508, -0.05054, 0.797, -0.949, -0.4...   \n",
              "\n",
              "                                        decoder_layer_6  \\\n",
              "0     [-1.305, 0.03638, 0.1963, 0.6016, -1.641, -0.0...   \n",
              "1     [-1.32, 0.04346, 0.1367, 0.586, -1.633, -0.009...   \n",
              "2     [-1.281, -0.00757, 0.1846, 0.6055, -1.672, -0....   \n",
              "3     [-1.305, 0.004883, 0.1787, 0.5938, -1.672, -0....   \n",
              "4     [-1.281, 0.02393, 0.1982, 0.586, -1.656, -0.04...   \n",
              "...                                                 ...   \n",
              "9810  [-1.32, 0.02197, 0.1484, 0.574, -1.664, -0.029...   \n",
              "9811  [-1.297, 0.02124, 0.1895, 0.5977, -1.656, -0.0...   \n",
              "9812  [-1.328, 0.02368, 0.167, 0.6016, -1.648, -0.01...   \n",
              "9813  [-1.305, 0.03564, 0.166, 0.5977, -1.625, 0.003...   \n",
              "9814  [-1.273, 0.01514, 0.2041, 0.5938, -1.641, -0.0...   \n",
              "\n",
              "                                        decoder_layer_7  \\\n",
              "0     [-1.25, 0.551, -0.1465, 0.801, -1.5625, -0.386...   \n",
              "1     [-1.258, 0.5586, -0.2051, 0.7812, -1.547, -0.3...   \n",
              "2     [-1.242, 0.5156, -0.1543, 0.801, -1.586, -0.38...   \n",
              "3     [-1.258, 0.5234, -0.1846, 0.793, -1.578, -0.33...   \n",
              "4     [-1.227, 0.543, -0.1406, 0.7812, -1.578, -0.39...   \n",
              "...                                                 ...   \n",
              "9810  [-1.258, 0.543, -0.2012, 0.7773, -1.57, -0.359...   \n",
              "9811  [-1.242, 0.5234, -0.1543, 0.797, -1.5625, -0.3...   \n",
              "9812  [-1.258, 0.539, -0.1777, 0.8047, -1.5625, -0.3...   \n",
              "9813  [-1.242, 0.551, -0.1982, 0.797, -1.531, -0.328...   \n",
              "9814  [-1.234, 0.5312, -0.1309, 0.7812, -1.5625, -0....   \n",
              "\n",
              "                                        decoder_layer_8  \\\n",
              "0     [0.0, 0.08594, 0.0762, 0.879, -1.656, -0.00769...   \n",
              "1     [-0.00586, 0.0928, 0.03125, 0.867, -1.648, 0.0...   \n",
              "2     [0.01172, 0.0537, 0.0879, 0.8555, -1.68, 0.007...   \n",
              "3     [-0.007812, 0.06445, 0.04492, 0.8555, -1.672, ...   \n",
              "4     [0.01758, 0.0713, 0.084, 0.8516, -1.672, -0.00...   \n",
              "...                                                 ...   \n",
              "9810  [0.009766, 0.08594, 0.0547, 0.8477, -1.6875, 0...   \n",
              "9811  [0.02148, 0.0625, 0.07227, 0.8633, -1.656, 0.0...   \n",
              "9812  [0.0, 0.07227, 0.0664, 0.875, -1.664, 0.006836...   \n",
              "9813  [0.02148, 0.0742, 0.0293, 0.867, -1.641, 0.042...   \n",
              "9814  [0.00586, 0.0654, 0.10547, 0.84, -1.656, -0.00...   \n",
              "\n",
              "                                        decoder_layer_9  \\\n",
              "0     [-0.1328, -0.1094, -0.4258, 1.086, -1.953, 0.2...   \n",
              "1     [-0.1465, -0.08594, -0.4492, 1.078, -1.945, 0....   \n",
              "2     [-0.127, -0.1426, -0.4023, 1.07, -1.969, 0.233...   \n",
              "3     [-0.1504, -0.1318, -0.4336, 1.078, -1.961, 0.2...   \n",
              "4     [-0.1133, -0.1318, -0.3945, 1.0625, -1.953, 0....   \n",
              "...                                                 ...   \n",
              "9810  [-0.1348, -0.1035, -0.4336, 1.078, -1.992, 0.2...   \n",
              "9811  [-0.1367, -0.1348, -0.4102, 1.07, -1.961, 0.25...   \n",
              "9812  [-0.1484, -0.104, -0.4082, 1.086, -1.953, 0.21...   \n",
              "9813  [-0.12256, -0.1406, -0.457, 1.078, -1.93, 0.25...   \n",
              "9814  [-0.1318, -0.1387, -0.3828, 1.047, -1.945, 0.2...   \n",
              "\n",
              "                                       decoder_layer_10  \\\n",
              "0     [-0.4492, -0.2617, -0.9883, 0.5547, -1.703, 0....   \n",
              "1     [-0.4785, -0.2168, -0.9844, 0.547, -1.727, 0.4...   \n",
              "2     [-0.4512, -0.293, -0.9766, 0.543, -1.727, 0.45...   \n",
              "3     [-0.4922, -0.2773, -1.016, 0.5312, -1.719, 0.5...   \n",
              "4     [-0.4512, -0.2793, -0.957, 0.5312, -1.711, 0.4...   \n",
              "...                                                 ...   \n",
              "9810  [-0.463, -0.2422, -1.0, 0.5625, -1.734, 0.4707...   \n",
              "9811  [-0.4844, -0.2676, -0.965, 0.539, -1.727, 0.48...   \n",
              "9812  [-0.4883, -0.2266, -0.9453, 0.5547, -1.719, 0....   \n",
              "9813  [-0.455, -0.293, -1.016, 0.543, -1.6875, 0.490...   \n",
              "9814  [-0.4727, -0.2676, -0.9453, 0.5156, -1.703, 0....   \n",
              "\n",
              "                                       decoder_layer_11  \\\n",
              "0     [-1.25, -0.1924, -1.195, 0.377, -2.11, 0.3164,...   \n",
              "1     [-1.289, -0.1338, -1.195, 0.4297, -2.094, 0.30...   \n",
              "2     [-1.297, -0.208, -1.172, 0.3574, -2.11, 0.3184...   \n",
              "3     [-1.328, -0.2266, -1.219, 0.3848, -2.078, 0.40...   \n",
              "4     [-1.281, -0.1934, -1.18, 0.3398, -2.094, 0.289...   \n",
              "...                                                 ...   \n",
              "9810  [-1.273, -0.1396, -1.172, 0.3867, -2.125, 0.31...   \n",
              "9811  [-1.328, -0.2031, -1.148, 0.4082, -2.11, 0.343...   \n",
              "9812  [-1.297, -0.1514, -1.133, 0.3887, -2.094, 0.29...   \n",
              "9813  [-1.289, -0.2266, -1.227, 0.3887, -2.062, 0.31...   \n",
              "9814  [-1.289, -0.2051, -1.172, 0.3418, -2.078, 0.31...   \n",
              "\n",
              "                                       decoder_layer_12  \\\n",
              "0     [-1.289, 0.3965, -0.332, 0.0674, -1.055, -0.47...   \n",
              "1     [-1.359, 0.535, -0.418, 0.1162, -1.141, -0.523...   \n",
              "2     [-1.375, 0.3184, -0.3555, -0.1201, -1.047, -0....   \n",
              "3     [-1.359, 0.254, -0.3164, -0.02783, -1.18, -0.4...   \n",
              "4     [-1.297, 0.373, -0.332, 0.004883, -1.086, -0.3...   \n",
              "...                                                 ...   \n",
              "9810  [-1.32, 0.418, -0.3164, 0.03223, -1.148, -0.38...   \n",
              "9811  [-1.375, 0.3906, -0.293, 0.11084, -1.07, -0.31...   \n",
              "9812  [-1.3125, 0.6133, -0.371, -0.0481, -1.18, -0.4...   \n",
              "9813  [-1.359, 0.3594, -0.3594, 0.0762, -0.9844, -0....   \n",
              "9814  [-1.266, 0.293, -0.2656, 0.03564, -1.117, -0.5...   \n",
              "\n",
              "                                       decoder_layer_13  \n",
              "0     [-0.5625, -4.125, 0.3906, 0.633, -1.398, 0.091...  \n",
              "1     [14.31, -1.523, -7.25, 4.53, 0.08496, 1.344, 0...  \n",
              "2     [9.31, -4.188, -3.75, 3.969, -0.8125, 3.64, 0....  \n",
              "3     [6.75, -6.312, -1.406, 4.75, -2.844, 2.281, -0...  \n",
              "4     [4.156, -1.5, -4.03, 3.531, -0.742, 3.875, -0....  \n",
              "...                                                 ...  \n",
              "9810  [17.0, -1.977, -9.0, 2.86, 0.1562, 3.625, 1.85...  \n",
              "9811  [15.375, -3.703, -5.97, 4.188, 0.7305, 3.61, 0...  \n",
              "9812  [17.5, -2.125, -5.47, 1.141, -0.707, -0.6367, ...  \n",
              "9813  [11.625, -2.703, -2.5, 3.203, 0.758, 2.281, 3....  \n",
              "9814  [11.31, -3.234, -3.344, 4.562, -0.4707, 3.469,...  \n",
              "\n",
              "[9815 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-884d3b7f-a825-4bbc-bb7d-9a7f75366fbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>encoder_layer_1</th>\n",
              "      <th>encoder_layer_2</th>\n",
              "      <th>encoder_layer_3</th>\n",
              "      <th>encoder_layer_4</th>\n",
              "      <th>encoder_layer_5</th>\n",
              "      <th>encoder_layer_6</th>\n",
              "      <th>encoder_layer_7</th>\n",
              "      <th>encoder_layer_8</th>\n",
              "      <th>...</th>\n",
              "      <th>decoder_layer_4</th>\n",
              "      <th>decoder_layer_5</th>\n",
              "      <th>decoder_layer_6</th>\n",
              "      <th>decoder_layer_7</th>\n",
              "      <th>decoder_layer_8</th>\n",
              "      <th>decoder_layer_9</th>\n",
              "      <th>decoder_layer_10</th>\n",
              "      <th>decoder_layer_11</th>\n",
              "      <th>decoder_layer_12</th>\n",
              "      <th>decoder_layer_13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>premise: \"The new rights are nice enough\", hyp...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.344, -0.483, 0.1812, 0.5337, -0.0769, -0.82...</td>\n",
              "      <td>[-0.03864, -0.2808, -0.02979, -0.2181, -0.1816...</td>\n",
              "      <td>[-0.0968, -0.46, 0.1799, 0.03778, 0.1947, 0.13...</td>\n",
              "      <td>[-0.2079, -0.4624, -0.05103, 0.02681, 0.0646, ...</td>\n",
              "      <td>[-0.1687, -0.2612, -0.1926, 0.2134, 0.4412, 0....</td>\n",
              "      <td>[-0.3135, -0.12476, -0.11707, 0.09, 0.2074, 0....</td>\n",
              "      <td>[0.1288, -0.47, -0.2286, 0.0789, 0.03105, 0.12...</td>\n",
              "      <td>[-0.0889, -0.1234, -0.4497, 0.2122, -0.221, 0....</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3906, 0.3184, 0.5312, -0.4727, -0.048...</td>\n",
              "      <td>[-0.961, 0.5117, -0.0371, 0.8047, -0.9375, -0....</td>\n",
              "      <td>[-1.305, 0.03638, 0.1963, 0.6016, -1.641, -0.0...</td>\n",
              "      <td>[-1.25, 0.551, -0.1465, 0.801, -1.5625, -0.386...</td>\n",
              "      <td>[0.0, 0.08594, 0.0762, 0.879, -1.656, -0.00769...</td>\n",
              "      <td>[-0.1328, -0.1094, -0.4258, 1.086, -1.953, 0.2...</td>\n",
              "      <td>[-0.4492, -0.2617, -0.9883, 0.5547, -1.703, 0....</td>\n",
              "      <td>[-1.25, -0.1924, -1.195, 0.377, -2.11, 0.3164,...</td>\n",
              "      <td>[-1.289, 0.3965, -0.332, 0.0674, -1.055, -0.47...</td>\n",
              "      <td>[-0.5625, -4.125, 0.3906, 0.633, -1.398, 0.091...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>premise: \"This site includes a list of all awa...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.561, -0.2668, -0.0681, 0.1443, -0.02663, -0...</td>\n",
              "      <td>[0.0632, 0.105, -0.1414, -0.384, 0.116, 0.3003...</td>\n",
              "      <td>[0.04077, -0.10565, 0.05594, -0.1918, 0.3145, ...</td>\n",
              "      <td>[-0.494, -0.1797, -0.2457, -0.1655, 0.0447, 0....</td>\n",
              "      <td>[-0.2213, -0.0804, 0.02829, -0.245, 0.3538, 0....</td>\n",
              "      <td>[-0.06604, -0.1796, -0.00826, -0.04938, 0.3613...</td>\n",
              "      <td>[0.6904, -0.409, 0.436, 0.148, 0.4436, -0.2218...</td>\n",
              "      <td>[0.176, 0.05182, 0.1171, 0.1746, 0.1741, 0.258...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4883, 0.4062, 0.2734, 0.5, -0.459, -0.0196...</td>\n",
              "      <td>[-0.9727, 0.5312, -0.0967, 0.7773, -0.957, -0....</td>\n",
              "      <td>[-1.32, 0.04346, 0.1367, 0.586, -1.633, -0.009...</td>\n",
              "      <td>[-1.258, 0.5586, -0.2051, 0.7812, -1.547, -0.3...</td>\n",
              "      <td>[-0.00586, 0.0928, 0.03125, 0.867, -1.648, 0.0...</td>\n",
              "      <td>[-0.1465, -0.08594, -0.4492, 1.078, -1.945, 0....</td>\n",
              "      <td>[-0.4785, -0.2168, -0.9844, 0.547, -1.727, 0.4...</td>\n",
              "      <td>[-1.289, -0.1338, -1.195, 0.4297, -2.094, 0.30...</td>\n",
              "      <td>[-1.359, 0.535, -0.418, 0.1162, -1.141, -0.523...</td>\n",
              "      <td>[14.31, -1.523, -7.25, 4.53, 0.08496, 1.344, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>premise: \"uh i don't know i i have mixed emoti...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.163, -0.274, -0.2878, -0.183, -0.1095, -0.8...</td>\n",
              "      <td>[-0.3027, -0.07764, -0.1505, -0.4653, -0.327, ...</td>\n",
              "      <td>[-0.3066, -0.2512, 0.02707, -0.0818, 0.05295, ...</td>\n",
              "      <td>[-0.1126, -0.2654, 0.0888, -0.1608, 0.08185, 0...</td>\n",
              "      <td>[-0.4702, -0.3503, -0.001026, -0.2805, 0.507, ...</td>\n",
              "      <td>[-0.3132, -0.405, 0.2208, -0.374, 0.3657, 0.42...</td>\n",
              "      <td>[-0.1027, -0.5273, 0.2502, 0.2164, 0.0921, 0.2...</td>\n",
              "      <td>[0.0967, -0.1975, -0.03513, -0.07874, 0.0703, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3672, 0.2793, 0.539, -0.4785, -0.0581...</td>\n",
              "      <td>[-0.949, 0.496, -0.0679, 0.8047, -0.9766, -0.4...</td>\n",
              "      <td>[-1.281, -0.00757, 0.1846, 0.6055, -1.672, -0....</td>\n",
              "      <td>[-1.242, 0.5156, -0.1543, 0.801, -1.586, -0.38...</td>\n",
              "      <td>[0.01172, 0.0537, 0.0879, 0.8555, -1.68, 0.007...</td>\n",
              "      <td>[-0.127, -0.1426, -0.4023, 1.07, -1.969, 0.233...</td>\n",
              "      <td>[-0.4512, -0.293, -0.9766, 0.543, -1.727, 0.45...</td>\n",
              "      <td>[-1.297, -0.208, -1.172, 0.3574, -2.11, 0.3184...</td>\n",
              "      <td>[-1.375, 0.3184, -0.3555, -0.1201, -1.047, -0....</td>\n",
              "      <td>[9.31, -4.188, -3.75, 3.969, -0.8125, 3.64, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>premise: \"yeah i i think my favorite restauran...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.402, -0.49, 0.1664, 0.1311, -0.11487, -1.03...</td>\n",
              "      <td>[-0.1433, -0.1693, -0.005165, -0.404, -0.2578,...</td>\n",
              "      <td>[0.0487, -0.3203, 0.1254, -0.1898, 0.0528, 0.1...</td>\n",
              "      <td>[0.00803, -0.4504, 0.12195, -0.1405, -0.04428,...</td>\n",
              "      <td>[-0.0972, -0.3352, -0.1434, -0.0467, 0.4023, 0...</td>\n",
              "      <td>[-0.00971, -0.4668, -0.012535, -0.0956, 0.2915...</td>\n",
              "      <td>[0.438, -0.7173, 0.0845, 0.182, 0.04935, 0.376...</td>\n",
              "      <td>[0.3896, -0.5376, -0.283, 0.1035, 0.1804, 0.55...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.504, 0.3652, 0.2988, 0.5273, -0.4688, -0.0...</td>\n",
              "      <td>[-0.961, 0.5, -0.05762, 0.797, -0.957, -0.42, ...</td>\n",
              "      <td>[-1.305, 0.004883, 0.1787, 0.5938, -1.672, -0....</td>\n",
              "      <td>[-1.258, 0.5234, -0.1846, 0.793, -1.578, -0.33...</td>\n",
              "      <td>[-0.007812, 0.06445, 0.04492, 0.8555, -1.672, ...</td>\n",
              "      <td>[-0.1504, -0.1318, -0.4336, 1.078, -1.961, 0.2...</td>\n",
              "      <td>[-0.4922, -0.2773, -1.016, 0.5312, -1.719, 0.5...</td>\n",
              "      <td>[-1.328, -0.2266, -1.219, 0.3848, -2.078, 0.40...</td>\n",
              "      <td>[-1.359, 0.254, -0.3164, -0.02783, -1.18, -0.4...</td>\n",
              "      <td>[6.75, -6.312, -1.406, 4.75, -2.844, 2.281, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>premise: \"i don't know um do you do a lot of c...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.446, -0.555, 0.01454, 0.4224, 0.206, -0.643...</td>\n",
              "      <td>[-0.07043, -0.1666, -0.01404, -0.4612, -0.1017...</td>\n",
              "      <td>[-0.4087, -0.374, 0.03696, 0.04095, 0.2595, 0....</td>\n",
              "      <td>[-0.299, -0.4531, 0.2932, -0.2054, 0.4106, -0....</td>\n",
              "      <td>[-0.4116, -0.4807, -0.08484, -0.1893, 0.8564, ...</td>\n",
              "      <td>[-0.05115, -0.545, 0.005085, -0.2761, 0.671, -...</td>\n",
              "      <td>[0.3135, -0.881, -0.545, 0.10284, 0.442, 0.116...</td>\n",
              "      <td>[0.3914, -0.2188, -0.509, -0.0247, 0.3635, 0.4...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4805, 0.3848, 0.2988, 0.5234, -0.498, -0.0...</td>\n",
              "      <td>[-0.9375, 0.5156, -0.05127, 0.785, -0.9688, -0...</td>\n",
              "      <td>[-1.281, 0.02393, 0.1982, 0.586, -1.656, -0.04...</td>\n",
              "      <td>[-1.227, 0.543, -0.1406, 0.7812, -1.578, -0.39...</td>\n",
              "      <td>[0.01758, 0.0713, 0.084, 0.8516, -1.672, -0.00...</td>\n",
              "      <td>[-0.1133, -0.1318, -0.3945, 1.0625, -1.953, 0....</td>\n",
              "      <td>[-0.4512, -0.2793, -0.957, 0.5312, -1.711, 0.4...</td>\n",
              "      <td>[-1.281, -0.1934, -1.18, 0.3398, -2.094, 0.289...</td>\n",
              "      <td>[-1.297, 0.373, -0.332, 0.004883, -1.086, -0.3...</td>\n",
              "      <td>[4.156, -1.5, -4.03, 3.531, -0.742, 3.875, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9810</th>\n",
              "      <td>premise: \"Since 1998, LSC has initiated and ov...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.506, -0.2832, 0.04056, 0.5, -0.3447, -1.307...</td>\n",
              "      <td>[0.04932, -0.0846, -0.2554, -0.2153, -0.2576, ...</td>\n",
              "      <td>[0.03845, -0.1837, 0.042, -0.1625, 0.114, 0.14...</td>\n",
              "      <td>[-0.0235, -0.1436, -0.0553, -0.0601, -0.06805,...</td>\n",
              "      <td>[-0.11865, -0.05368, -0.1266, -0.0887, 0.3015,...</td>\n",
              "      <td>[0.01325, -0.3506, 0.06335, -0.03503, 0.1782, ...</td>\n",
              "      <td>[0.5894, -0.06238, 0.5283, -0.1141, 0.3916, 0....</td>\n",
              "      <td>[0.579, -0.3577, 0.552, 0.2429, 0.092, 0.5176,...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3848, 0.2773, 0.508, -0.4883, -0.0283...</td>\n",
              "      <td>[-0.9688, 0.508, -0.0874, 0.7812, -0.961, -0.4...</td>\n",
              "      <td>[-1.32, 0.02197, 0.1484, 0.574, -1.664, -0.029...</td>\n",
              "      <td>[-1.258, 0.543, -0.2012, 0.7773, -1.57, -0.359...</td>\n",
              "      <td>[0.009766, 0.08594, 0.0547, 0.8477, -1.6875, 0...</td>\n",
              "      <td>[-0.1348, -0.1035, -0.4336, 1.078, -1.992, 0.2...</td>\n",
              "      <td>[-0.463, -0.2422, -1.0, 0.5625, -1.734, 0.4707...</td>\n",
              "      <td>[-1.273, -0.1396, -1.172, 0.3867, -2.125, 0.31...</td>\n",
              "      <td>[-1.32, 0.418, -0.3164, 0.03223, -1.148, -0.38...</td>\n",
              "      <td>[17.0, -1.977, -9.0, 2.86, 0.1562, 3.625, 1.85...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9811</th>\n",
              "      <td>premise: \"Eighty percent of pagers in the Unit...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.759, -0.4187, -0.1697, 0.3447, -0.202, -0.5...</td>\n",
              "      <td>[-0.0734, 0.0743, -0.2362, -0.3215, -0.2666, 0...</td>\n",
              "      <td>[-0.1722, -0.0607, 0.1453, -0.144, 0.2146, 0.3...</td>\n",
              "      <td>[-0.1992, -0.1039, -0.01227, -0.02316, 0.2424,...</td>\n",
              "      <td>[-0.06854, -0.2786, -0.2017, -0.1204, 0.6406, ...</td>\n",
              "      <td>[0.11926, -0.154, -0.06946, 0.1306, 0.6772, 0....</td>\n",
              "      <td>[0.721, -0.4841, -0.1459, 0.5635, 0.5723, 0.43...</td>\n",
              "      <td>[0.659, -0.0172, -0.6035, 0.5107, 0.533, 0.651...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.5, 0.3887, 0.3047, 0.504, -0.4941, -0.0296...</td>\n",
              "      <td>[-0.953, 0.5195, -0.05786, 0.789, -0.961, -0.4...</td>\n",
              "      <td>[-1.297, 0.02124, 0.1895, 0.5977, -1.656, -0.0...</td>\n",
              "      <td>[-1.242, 0.5234, -0.1543, 0.797, -1.5625, -0.3...</td>\n",
              "      <td>[0.02148, 0.0625, 0.07227, 0.8633, -1.656, 0.0...</td>\n",
              "      <td>[-0.1367, -0.1348, -0.4102, 1.07, -1.961, 0.25...</td>\n",
              "      <td>[-0.4844, -0.2676, -0.965, 0.539, -1.727, 0.48...</td>\n",
              "      <td>[-1.328, -0.2031, -1.148, 0.4082, -2.11, 0.343...</td>\n",
              "      <td>[-1.375, 0.3906, -0.293, 0.11084, -1.07, -0.31...</td>\n",
              "      <td>[15.375, -3.703, -5.97, 4.188, 0.7305, 3.61, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9812</th>\n",
              "      <td>premise: \"Finally, the FDA will conduct worksh...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.718, 0.04306, 0.0839, 0.5645, -0.1306, -1.3...</td>\n",
              "      <td>[-0.05685, 0.2372, -0.1681, -0.1083, -0.0483, ...</td>\n",
              "      <td>[-0.0872, 0.1451, 0.1289, 0.05698, 0.338, -0.1...</td>\n",
              "      <td>[-0.182, 0.02766, 0.03287, -0.1383, 0.201, -0....</td>\n",
              "      <td>[-0.2128, 0.1598, 0.05807, -0.2805, 0.58, 0.13...</td>\n",
              "      <td>[-0.11383, -0.1799, 0.1243, -0.2686, 0.56, 0.0...</td>\n",
              "      <td>[0.3928, 0.01674, 0.351, -0.366, 0.5435, -0.00...</td>\n",
              "      <td>[0.4287, 0.2568, -0.04056, -0.2427, 0.4504, 0....</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4902, 0.3887, 0.2988, 0.5273, -0.463, -0.0...</td>\n",
              "      <td>[-0.961, 0.508, -0.0581, 0.801, -0.953, -0.433...</td>\n",
              "      <td>[-1.328, 0.02368, 0.167, 0.6016, -1.648, -0.01...</td>\n",
              "      <td>[-1.258, 0.539, -0.1777, 0.8047, -1.5625, -0.3...</td>\n",
              "      <td>[0.0, 0.07227, 0.0664, 0.875, -1.664, 0.006836...</td>\n",
              "      <td>[-0.1484, -0.104, -0.4082, 1.086, -1.953, 0.21...</td>\n",
              "      <td>[-0.4883, -0.2266, -0.9453, 0.5547, -1.719, 0....</td>\n",
              "      <td>[-1.297, -0.1514, -1.133, 0.3887, -2.094, 0.29...</td>\n",
              "      <td>[-1.3125, 0.6133, -0.371, -0.0481, -1.18, -0.4...</td>\n",
              "      <td>[17.5, -2.125, -5.47, 1.141, -0.707, -0.6367, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>premise: \"Cirque du Soleil's The latest from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.798, -0.3223, 0.1498, 0.6035, -0.12195, -0....</td>\n",
              "      <td>[0.03108, -0.0797, 0.03198, -0.1942, -0.2507, ...</td>\n",
              "      <td>[-0.0639, -0.2905, 0.4587, -0.006374, 0.2905, ...</td>\n",
              "      <td>[-0.1958, -0.2751, 0.0891, 0.02525, 0.2637, 0....</td>\n",
              "      <td>[-0.1653, -0.1857, -0.0406, -0.0867, 0.2412, 0...</td>\n",
              "      <td>[-0.02888, -0.1448, 0.0614, 0.07104, 0.3801, 0...</td>\n",
              "      <td>[0.3428, 0.003273, -0.1865, 0.1659, 0.4243, 0....</td>\n",
              "      <td>[0.3577, 0.00595, -0.2098, 0.05118, 0.3884, 0....</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4902, 0.3906, 0.295, 0.5234, -0.4648, -0.0...</td>\n",
              "      <td>[-0.949, 0.5117, -0.0742, 0.797, -0.957, -0.40...</td>\n",
              "      <td>[-1.305, 0.03564, 0.166, 0.5977, -1.625, 0.003...</td>\n",
              "      <td>[-1.242, 0.551, -0.1982, 0.797, -1.531, -0.328...</td>\n",
              "      <td>[0.02148, 0.0742, 0.0293, 0.867, -1.641, 0.042...</td>\n",
              "      <td>[-0.12256, -0.1406, -0.457, 1.078, -1.93, 0.25...</td>\n",
              "      <td>[-0.455, -0.293, -1.016, 0.543, -1.6875, 0.490...</td>\n",
              "      <td>[-1.289, -0.2266, -1.227, 0.3887, -2.062, 0.31...</td>\n",
              "      <td>[-1.359, 0.3594, -0.3594, 0.0762, -0.9844, -0....</td>\n",
              "      <td>[11.625, -2.703, -2.5, 3.203, 0.758, 2.281, 3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9814</th>\n",
              "      <td>premise: \"i'll listen  and agree with what i t...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.556, -0.1387, -0.1521, 0.5977, -0.03833, -0...</td>\n",
              "      <td>[-0.2079, 0.12085, -0.05237, -0.05545, -0.1606...</td>\n",
              "      <td>[-0.5107, -0.01266, 0.02594, 0.1925, 0.1381, 0...</td>\n",
              "      <td>[-0.1798, -0.11456, -0.0368, 0.0846, 0.261, 0....</td>\n",
              "      <td>[-0.3088, -0.411, -0.3018, -0.0605, 0.4875, 0....</td>\n",
              "      <td>[-0.4077, -0.312, -0.0448, -0.2114, 0.2302, 0....</td>\n",
              "      <td>[-0.3765, -0.522, -0.0345, -0.03528, 0.00503, ...</td>\n",
              "      <td>[-0.1458, -0.06097, -0.29, -0.03644, -0.2189, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4688, 0.377, 0.3047, 0.5273, -0.4805, -0.0...</td>\n",
              "      <td>[-0.9375, 0.508, -0.05054, 0.797, -0.949, -0.4...</td>\n",
              "      <td>[-1.273, 0.01514, 0.2041, 0.5938, -1.641, -0.0...</td>\n",
              "      <td>[-1.234, 0.5312, -0.1309, 0.7812, -1.5625, -0....</td>\n",
              "      <td>[0.00586, 0.0654, 0.10547, 0.84, -1.656, -0.00...</td>\n",
              "      <td>[-0.1318, -0.1387, -0.3828, 1.047, -1.945, 0.2...</td>\n",
              "      <td>[-0.4727, -0.2676, -0.9453, 0.5156, -1.703, 0....</td>\n",
              "      <td>[-1.289, -0.2051, -1.172, 0.3418, -2.078, 0.31...</td>\n",
              "      <td>[-1.266, 0.293, -0.2656, 0.03564, -1.117, -0.5...</td>\n",
              "      <td>[11.31, -3.234, -3.344, 4.562, -0.4707, 3.469,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9815 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-884d3b7f-a825-4bbc-bb7d-9a7f75366fbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-884d3b7f-a825-4bbc-bb7d-9a7f75366fbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-884d3b7f-a825-4bbc-bb7d-9a7f75366fbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-acb4f6fd-1eea-4596-aee7-b31a6e22a161\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acb4f6fd-1eea-4596-aee7-b31a6e22a161')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-acb4f6fd-1eea-4596-aee7-b31a6e22a161 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bbea8e5e-73f1-4126-a0c4-b36cedd83db6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('multinli_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bbea8e5e-73f1-4126-a0c4-b36cedd83db6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('multinli_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "multinli_df"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "multinli_df = extract_activations_df(multinli_df, model_b, tokenizer_b, 'sentence', BATCH_SIZE=16)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_activations_df(multinli_df, 'multinli', model_id_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKLPKLAfKXS0",
        "outputId": "41db51f8-94dc-49d7-9185-e2d82b379a95"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving multinli_t5gemma-b-b-ul2 to GDrive...\n",
            "Saved multinli_t5gemma-b-b-ul2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyu0z5SbKZp5"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mO7Cg1J3KZp7"
      },
      "outputs": [],
      "source": [
        "multinli_df = extract_activations_df(multinli_df, model_2b, tokenizer_2b, 'sentence', BATCH_SIZE=16)\n",
        "multinli_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_activations_df(multinli_df, 'multinli', model_id_2b)"
      ],
      "metadata": {
        "id": "3fj_fBv_KZp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ykdxjTrlYm"
      },
      "source": [
        "## ParaRel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6ic5Kh3dshrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb861c06-ac53-457c-a9df-ab5163b4335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pararel'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 239 (delta 24), reused 28 (delta 23), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 1.24 MiB | 4.42 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yanaiela/pararel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z46mi70tRs_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "objects_files = os.listdir('/content/pararel/data/trex_lms_vocab')\n",
        "relations_file = os.listdir('/content/pararel/data/pattern_data/graphs_json')\n",
        "\n",
        "# read the jsonl files in objects_files and create a dataframe for each file, then join them all into a single dataframe\n",
        "pararel_dfs = []\n",
        "for obj_file in relations_file:\n",
        "    obj_path = f'/content/pararel/data/trex_lms_vocab/{obj_file}'\n",
        "    obj_df = pd.read_json(obj_path, lines=True)\n",
        "\n",
        "    # read the relations file (same name as obj_file but different path) to get the relation name\n",
        "    relation_path = f'/content/pararel/data/pattern_data/graphs_json/{obj_file}'\n",
        "    with open(relation_path, 'r', encoding='utf-8') as f:\n",
        "        relation = json.loads(f.readline())['extended_lemma']\n",
        "\n",
        "    obj_df['relation'] = relation\n",
        "    pararel_dfs.append(obj_df)\n",
        "pararel_df = pd.concat(pararel_dfs, ignore_index=True)\n",
        "pararel_df.drop(columns=['uuid'], inplace=True)\n",
        "pararel_df.columns = ['first_entity', 'second_entity', 'relation']\n",
        "\n",
        "pararel_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxD1v1eKtRs_"
      },
      "outputs": [],
      "source": [
        "pararel_df['relation'].unique(), pararel_df['relation'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklURMe2tRs_"
      },
      "source": [
        "there are 38 relationships, we want to extract sentences in the form \"What {h1} is to {t1}, {h2} is to {t2}.\"\n",
        "- Random replacement (replace one of the second relation elements with something random)\n",
        "- Reverse direction (reverse the direction of a correct relation)\n",
        "- Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BSNuLeMtRs_"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"What {h1} is to {t1}, {h2} is to {t2}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4f4yn5vtRs_"
      },
      "outputs": [],
      "source": [
        "for i in pararel_df['relation'].unique():\n",
        "    sample = pararel_df[pararel_df['relation']==i].sample(1)\n",
        "    print(f'{sample[\"first_entity\"].values[0]} - {i} - {sample[\"second_entity\"].values[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9bKLNMbtRs_"
      },
      "outputs": [],
      "source": [
        "# ideally the dataset will be 6000 (correct) + 3 (random, reverse, type) * 2000 (wrong) = 12000 sentences\n",
        "total_dataset_len = 12000\n",
        "number_correct_relationships = total_dataset_len//2\n",
        "number_wrong_relationships = total_dataset_len//6\n",
        "\n",
        "number_relationships = pararel_df['relation'].nunique()\n",
        "relationships = pararel_df['relation'].unique()\n",
        "pararel_analogies_dict = {'sentences': [], 'type': []}\n",
        "\n",
        "# correct relationships\n",
        "for r in tqdm(relationships, desc='Extracting correct relationships'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(number_correct_relationships//number_relationships):\n",
        "        if len(rel_df) > 2:\n",
        "            sampled = rel_df.sample(n=2)\n",
        "            row1 = sampled.iloc[0]\n",
        "            row2 = sampled.iloc[1]\n",
        "            rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "            h1 = row1['first_entity']\n",
        "            t1 = row1['second_entity']\n",
        "            h2 = row2['first_entity']\n",
        "            t2 = row2['second_entity']\n",
        "            correct_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t2)\n",
        "            pararel_analogies_dict['sentences'].append(correct_sentence)\n",
        "            pararel_analogies_dict['type'].append(0) # 0 means correct relationship\n",
        "\n",
        "# random replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (random)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 3 and rel_df['first_entity'].nunique()>2 and rel_df['second_entity'].nunique()>2:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=3)\n",
        "\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "\n",
        "                if (h1!=h2 and h1!=h3 and t1!=t2 and t1!=t3 and t2!=t3):\n",
        "                    random_choice = np.random.randint(1,3)\n",
        "                    if random_choice == 1:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h2, t2=t3)\n",
        "                    else:\n",
        "                        random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=t2)\n",
        "\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(1) # 0 means random replacement\n",
        "\n",
        "                    sampled_done = True\n",
        "\n",
        "# reverse replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (reversed)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range(int(number_wrong_relationships/number_relationships)):\n",
        "        if len(rel_df) > 2 and rel_df['first_entity'].nunique()>1 and rel_df['second_entity'].nunique()>1:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=2)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                if (h1!=h2 and t1!=t2):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "                    random_replacement_sentence = PROMPT.format(h1=h1, t1=t1, h2=t2, t2=h2)\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence)\n",
        "                    pararel_analogies_dict['type'].append(2) # 2 means reverse replacement\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "# type replacement relationships\n",
        "for r in tqdm(relationships, desc='Extracting wrong relationships (type)'):\n",
        "    rel_df = pararel_df[pararel_df['relation']==r]\n",
        "    for i in range((number_wrong_relationships//2)//number_relationships):\n",
        "        if len(rel_df) > 4 and rel_df['first_entity'].nunique()>3 and rel_df['second_entity'].nunique()>3:\n",
        "            sampled_done = False\n",
        "            while not sampled_done:\n",
        "                sampled = rel_df.sample(n=4)\n",
        "                row1 = sampled.iloc[0]\n",
        "                row2 = sampled.iloc[1]\n",
        "                row3 = sampled.iloc[2]\n",
        "                row4 = sampled.iloc[3]\n",
        "\n",
        "                # correct\n",
        "                h1 = row1['first_entity']\n",
        "                t1 = row1['second_entity']\n",
        "                h2 = row2['first_entity']\n",
        "                t2 = row2['second_entity']\n",
        "\n",
        "                # to be replaced\n",
        "                h3 = row3['first_entity']\n",
        "                t3 = row3['second_entity']\n",
        "                h4 = row4['first_entity']\n",
        "                t4 = row4['second_entity']\n",
        "\n",
        "                if (h1!=h3 and h1!=h4 and h2!=h3 and h2!=h4 and t1!=t3 and t1!=t4 and t2!=t3 and t2!=t4 and h3!=h4 and t3!=t4):\n",
        "                    rel_df = rel_df.drop(sampled.index)\n",
        "\n",
        "                    random_replacement_sentence_1 = PROMPT.format(h1=h1, t1=t1, h2=h3, t2=h4)\n",
        "                    random_replacement_sentence_2 = PROMPT.format(h1=h2, t1=t2, h2=t3, t2=t4)\n",
        "\n",
        "                    # first wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_1)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "\n",
        "                    # second wrong sentence\n",
        "                    pararel_analogies_dict['sentences'].append(random_replacement_sentence_2)\n",
        "                    pararel_analogies_dict['type'].append(3) # 3 means wrong type relationship\n",
        "                    sampled_done = True\n",
        "\n",
        "\n",
        "\n",
        "pararel_analogies_df = pd.DataFrame(pararel_analogies_dict)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx-4ftA4tRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df.head()['sentences'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybj7KczntRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df['label'] = pararel_analogies_df['type'].apply(lambda x: 1 if x == 0 else 0)\n",
        "pararel_analogies_df = pararel_analogies_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_LMOTzktRtA"
      },
      "source": [
        "model_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ1LbGEitRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_b, tokenizer_b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2YUuDZdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfkiIbpttRtA"
      },
      "source": [
        "model_2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTo5yHPAtRtA"
      },
      "outputs": [],
      "source": [
        "pararel_analogies_df = extract_activations_df(pararel_analogies_df, model_2b, tokenizer_2b, 'sentences', BATCH_SIZE=128)\n",
        "pararel_analogies_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUKE82pdtRtA"
      },
      "outputs": [],
      "source": [
        "save_activations_df(pararel_analogies_df, 'pararel_analogies', model_id_2b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6a3H8citRtA"
      },
      "source": [
        "## Perturbations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV1boEqtRtA"
      },
      "source": [
        "here we consider the perturbations on the dataset\n",
        "\n",
        "we have to perturbe just the validation set, for being able to detect the model's strength\n",
        "\n",
        "we can use 2 different perturbation levels: semantic level and syntactic level\n",
        "- for semantic level we can use https://github.com/makcedward/nlpaug (sinonimi)\n",
        "- for syntactic level we can use again nlpaug\n",
        "\n",
        "https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb\n",
        "\n",
        "for datasets\n",
        "- true/false: both\n",
        "- CoLA: semantic (syntactic would change the label)\n",
        "- EWT: both\n",
        "- ParaRel: none\n",
        "- MultiNLI: both (with carefuleness about syntactic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq2ymKU_tRtA"
      },
      "source": [
        "# Probe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the probes"
      ],
      "metadata": {
        "id": "OkIGEhXvJ9Zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YCjfsHlk0Pmp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "MOYYlmAszNzg"
      },
      "outputs": [],
      "source": [
        "class Probe(nn.Module):\n",
        "  def fit(self, train_loader, epochs=10, lr=0.001, device=None):\n",
        "    total_losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    if device is None:\n",
        "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    criterion = nn.CrossEntropyLoss() # standard\n",
        "    optimizer = optim.Adam(self.parameters(), lr=lr) # to be defined with hyperparams\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      self.train()\n",
        "      total_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "      # Statistiche di fine epoca\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      acc = correct / total\n",
        "      total_losses.append(avg_loss)\n",
        "      accuracies.append(acc)\n",
        "      #print(f\"Epoca [{epoch+1}/{epochs}] \\t Loss: {avg_loss:.4f} \\t Acc: {acc:.4f}\")\n",
        "\n",
        "    return total_losses, accuracies\n",
        "\n",
        "  def evaluate(self, test_loader, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    self.to(device)\n",
        "    self.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # torch.no_grad() risparmia memoria e calcoli perché non traccia i gradienti\n",
        "    with torch.no_grad():\n",
        "      for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        outputs = self(batch_x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "class NonLinearProbe(Probe): # architecture from CS2\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(NonLinearProbe, self).__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "  '''\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(NonLinearProbe, self).__init__()\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "      nn.Linear(input_dim, 256),\n",
        "      nn.SELU(),\n",
        "      nn.AlphaDropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "      nn.Linear(256, 128),\n",
        "      nn.SELU(),\n",
        "      nn.AlphaDropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "      nn.Linear(128, 64),\n",
        "      nn.SELU(),\n",
        "      nn.AlphaDropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "    for m in self.modules(): # LeCun Normal initialization\n",
        "      if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, mode=\"fan_in\", nonlinearity=\"linear\")\n",
        "        if m.bias is not None:\n",
        "          nn.init.zeros_(m.bias)\n",
        "  '''\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "class LinearProbe(Probe):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearProbe, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_dim, 256)\n",
        "    self.linear2 = nn.Linear(256,128)\n",
        "    self.linear3 = nn.Linear(128,64)\n",
        "    self.out = nn.Linear(64, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.linear3(x)\n",
        "    x = self.out(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kvgWaCJyRvin"
      },
      "outputs": [],
      "source": [
        "def iterate_training_layers(model_size, df, num_layers, encdec, probe, probe_args={}, split_index=75, label='label'):\n",
        "  train_accuracy = []\n",
        "  test_accuracy = []\n",
        "\n",
        "  print(f'Training on model {model_size}, considering {encdec}')\n",
        "  for layer in trange(num_layers):\n",
        "    col_name = f'{encdec}_layer_{layer+1}'\n",
        "    num_train_instances = len(df) * split_index // 100\n",
        "    num_test_instances = len(df) - num_train_instances\n",
        "\n",
        "    # shuffle the df\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    train_df = df[:num_train_instances]\n",
        "    test_df = df[num_train_instances:]\n",
        "\n",
        "    X_train_tensor = torch.stack([torch.from_numpy(t) for t in train_df[col_name].tolist()]).to(torch.float32)\n",
        "    y_train_tensor = torch.tensor(train_df[label].tolist())\n",
        "\n",
        "    X_test_tensor = torch.stack([torch.from_numpy(t) for t in test_df[col_name].tolist()]).to(torch.float32)\n",
        "    y_test_tensor = torch.tensor(test_df[label].tolist())\n",
        "\n",
        "    # training of the probe\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "    if probe=='linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = LinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim)\n",
        "    elif probe == 'non_linear':\n",
        "      output_dim = y_train_tensor.max().item()+1\n",
        "      probe_instance = NonLinearProbe(input_dim=X_train_tensor.shape[1], output_dim=output_dim, **probe_args)\n",
        "    else:\n",
        "      raise ValueError('Probe must be either linear or non_linear')\n",
        "\n",
        "    results = probe_instance.fit(train_loader, epochs=25, lr=0.001)\n",
        "    train_accuracy.append(results[1][-1])\n",
        "\n",
        "    # evaluating test accuracy\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "    test_acc = probe_instance.evaluate(test_loader)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n",
        "  return train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WRHoApyrGUzO"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(train_accuracy, test_accuracy, model, probe, knowledge, encdec):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(train_accuracy, label='Train Accuracy')\n",
        "  plt.plot(test_accuracy, label='Test Accuracy')\n",
        "  plt.xlabel('Layer')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(f'{knowledge}, model {model}, linearity {probe}, encdec {encdec}')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Factual knowledge"
      ],
      "metadata": {
        "id": "GgQhoikRKAzf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGRKft-YUGP8"
      },
      "source": [
        "model b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Nrdisnnm0diE"
      },
      "outputs": [],
      "source": [
        "tf_b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-b-b-ul2'\n",
        "tf_b_df = pd.read_pickle(tf_b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SleK9ZLCUia_"
      },
      "outputs": [],
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : tf_b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'non_linear', 'factual', 'decoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : tf_b_df,\n",
        "    'probe' : 'linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'linear', 'factual', 'decoder')\n"
      ],
      "metadata": {
        "id": "wik1m6FnjxiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89_0OnHUfPX"
      },
      "source": [
        "model 2b on factual knowledge, nonlinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkL8QH37MUVD"
      },
      "outputs": [],
      "source": [
        "tf_2b_path = '/content/drive/MyDrive/DTCS_datasets/true-false_t5gemma-2b-2b-ul2'\n",
        "tf_2b_df = pd.read_pickle(tf_2b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXbhQ9XRU_SI"
      },
      "outputs": [],
      "source": [
        "config2b = {\n",
        "    'model_size' : '2b',\n",
        "    'df' : tf_2b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'non_linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'non_linear', 'factual', 'decoder')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config2b = {\n",
        "    'model_size' : '2b',\n",
        "    'df' : tf_2b_df,\n",
        "    'probe' : 'linear',\n",
        "    'num_layers' :27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'linear', 'factual', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'linear', 'factual', 'decoder')\n"
      ],
      "metadata": {
        "id": "5mCSPkVtlhad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linguistic knowledge"
      ],
      "metadata": {
        "id": "FJ0rlNIylpae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoLA"
      ],
      "metadata": {
        "id": "3nyo0xZHKK8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cola_b_path = '/content/drive/MyDrive/DTCS_datasets/cola_t5gemma-b-b-ul2.pkl'\n",
        "cola_b_df = pd.read_pickle(cola_b_path)"
      ],
      "metadata": {
        "id": "MUu4AeBblyqG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : cola_b_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**configb, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'linguistic (cola)', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**configb, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], 'b', 'non_linear', 'linguistic (cola)', 'decoder')\n"
      ],
      "metadata": {
        "id": "qWE_2HaFmg6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 2b"
      ],
      "metadata": {
        "id": "c6q3-UHNElZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cola_2b_path = '/content/drive/MyDrive/DTCS_datasets/cola_t5gemma-2b-2b-ul2'\n",
        "cola_2b_df = pd.read_pickle(cola_b_path)"
      ],
      "metadata": {
        "id": "NiunZRGmqa_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config2b = {\n",
        "    'model_size':'2b',\n",
        "    'df':cola_2b_df,\n",
        "    'probe':'non_linear',\n",
        "    'num_layers':27\n",
        "}\n",
        "\n",
        "# encoder\n",
        "encoder_results = iterate_training_layers(**config2b, encdec='encoder')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], '2b', 'non_linear', 'linguistic (cola)', 'encoder')\n",
        "\n",
        "# decoder\n",
        "decoder_results = iterate_training_layers(**config2b, encdec='decoder')\n",
        "plot_accuracies(decoder_results[0], decoder_results[1], '2b', 'non_linear', 'linguistic (cola)', 'decoder')\n"
      ],
      "metadata": {
        "id": "w6XDRgN_qa_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EWT"
      ],
      "metadata": {
        "id": "4Bhk8ZqRKMyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ewt model b"
      ],
      "metadata": {
        "id": "hLJAfYQ_EpSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configb = {\n",
        "    'model_size' : 'b',\n",
        "    'df' : token_ewt_df,\n",
        "    'probe' : 'non_linear',\n",
        "    'num_layers' :13\n",
        "}"
      ],
      "metadata": {
        "id": "Meu4vPV4Eqef"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_results = iterate_training_layers(**configb, encdec='encoder', label='upos_tag')\n",
        "plot_accuracies(encoder_results[0], encoder_results[1], 'b', 'non_linear', 'linguistic (ewt)', 'encoder')"
      ],
      "metadata": {
        "id": "lIF-jmgXLfGm",
        "outputId": "8cefe0aa-8259-4891-b958-c5266a9891a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on model b, considering encoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [03:06<00:00, 14.36s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "control_task_results = iterate_training_layers(**configb, encdec='encoder', label='ct_upos_tag')\n",
        "plot_accuracies(control_task_results[0], control_task_results[1], 'b', 'non_linear', 'linguistic (ewt - control task)', 'encoder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "otG-N6ybFk7M",
        "outputId": "1ed850d5-e951-467b-fcf7-28ccbeff939f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on model b, considering encoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [03:05<00:00, 14.29s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}